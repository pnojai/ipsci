<!doctype html>
<html lang="en">
  <head>
    <title>US8139892B2 - Spatial standard observer 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US8139892B2/en">
    <meta name="description" content="
     The present invention relates to devices and methods for the measurement and/or for the specification of the perceptual intensity of a visual image, or the perceptual distance between a pair of images. Grayscale test and reference images are processed to produce test and reference luminance images. A luminance filter function is convolved with the reference luminance image to produce a local mean luminance reference image. Test and reference contrast images are produced from the local mean luminance reference image and the test and reference luminance images respectively, followed by application of a contrast sensitivity filter. The resulting images are combined according to mathematical prescriptions to produce a Just Noticeable Difference, JND value, indicative of a Spatial Standard Observer, SSO. Some embodiments include masking functions, window functions, special treatment for images lying on or near borders and pre-processing of test images. 
   
   ">
    
    <meta name="DC.type" content="patent">
    
    <meta name="DC.title" content="Spatial standard observer 
       ">
    
    <meta name="DC.date" content="2010-08-09" scheme="dateSubmitted">
    
    <meta name="DC.description" content="
     The present invention relates to devices and methods for the measurement and/or for the specification of the perceptual intensity of a visual image, or the perceptual distance between a pair of images. Grayscale test and reference images are processed to produce test and reference luminance images. A luminance filter function is convolved with the reference luminance image to produce a local mean luminance reference image. Test and reference contrast images are produced from the local mean luminance reference image and the test and reference luminance images respectively, followed by application of a contrast sensitivity filter. The resulting images are combined according to mathematical prescriptions to produce a Just Noticeable Difference, JND value, indicative of a Spatial Standard Observer, SSO. Some embodiments include masking functions, window functions, special treatment for images lying on or near borders and pre-processing of test images. 
   
   ">
    
    <meta name="citation_patent_application_number" content="US:12/807,375">
    
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/3f/ab/bd/ae5a336788a0b9/US8139892.pdf">
    
    <meta name="citation_patent_number" content="US:8139892">
    
    <meta name="DC.date" content="2012-03-20" scheme="issue">
    
    <meta name="DC.contributor" content="Andrew B. Watson" scheme="inventor">
    
    <meta name="DC.contributor" content="National Aeronautics and Space Administration (NASA)" scheme="assignee">
    
    <meta name="DC.relation" content="US:5781665" scheme="references">
    
    <meta name="DC.relation" content="US:5694491" scheme="references">
    
    <meta name="DC.relation" content="US:5719966" scheme="references">
    
    <meta name="DC.relation" content="US:5974159" scheme="references">
    
    <meta name="DC.relation" content="US:6148117" scheme="references">
    
    <meta name="DC.relation" content="US:20020031277:A1" scheme="references">
    
    <meta name="DC.relation" content="US:20030197867:A1" scheme="references">
    
    <meta name="DC.relation" content="US:6977664" scheme="references">
    
    <meta name="DC.relation" content="WO:2002006851:A1" scheme="references">
    
    <meta name="DC.relation" content="US:20020145757:A1" scheme="references">
    
    <meta name="DC.relation" content="US:20020150304:A1" scheme="references">
    
    <meta name="DC.relation" content="US:6799515" scheme="references">
    
    <meta name="DC.relation" content="WO:2004086751:A2" scheme="references">
    
    <meta name="citation_reference" content="Ahumada, Computational Image Quality Metrics: A Review, Society for Information Display International Symposium Digest of Technical Papers 24, 1993, 305-308." scheme="references">
    
    <meta name="citation_reference" content="Barten, The SQRI Method: A New Method for the Evaluation of Visible Resolution on a Display, Proceedings of the SID, 1987, 253-262, 28-3." scheme="references">
    
    <meta name="citation_reference" content="Chen, et al., Detection of Chromoluminance Patterns on Chromoluminance Pedestals I: Threshold Measurements, Vision Research 40, 2000. 773-778." scheme="references">
    
    <meta name="citation_reference" content="Chen, et al., Detection of Chromoluminance Patterns on Chromoluminance Pedestals II: Model, Vision Research 40, 2000, 789-803." scheme="references">
    
    <meta name="citation_reference" content="Lubin, A Human Vision System Model for Objective Picture Quality Measurements, International Broadcasting Convention, Sep. 12-16, 1997, 498-503, Conference publication No. 447." scheme="references">
    
    <meta name="citation_reference" content="Rohaly, et al., A Comparison of Image Quality Models and Metrics Predicting Object Detection, Society for Information display International Symposium Digest of Technical Papers 26, 1995, 45-48." scheme="references">
    
    <meta name="citation_reference" content="Watson, et al., A Standard Observer for Spatial Vision, Investigative Ophthalmology and Visual Science, 2000, S713, 41-4." scheme="references">
    
    <meta name="citation_reference" content="Watson, et al., Video Quality Measures Based on the Standard Spatial Observer, 2002 IEEE International Conference on Image Processing, Sep. 25, 2002, WA-L2.2." scheme="references">
    
    <meta name="citation_reference" content="Watson, Visual Detection of Spatial Contrast Patterns: Evaluation of Five Simple Models, Optics Express, Jan. 3, 2000, 12-33, 6-1." scheme="references">
    
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <style>
      body { transition: none; }
    </style>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-27188110-4', 'auto');

      version = 'patent-search.search_20191120_RC00';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.profilePicture = "";

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.html">
    
  </head>
  <body unresolved>
    
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.js"></script>
    
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US8139892B2 - Spatial standard observer 
        - Google Patents</h1>
  <span itemprop="title">Spatial standard observer 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/3f/ab/bd/ae5a336788a0b9/US8139892.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US8139892B2</dd>
    <meta itemprop="numberWithoutCodes" content="8139892">
    <meta itemprop="kindCode" content="B2">
    <meta itemprop="publicationDescription" content="Patent ( having previously published pre-grant publication)">
    
    <span>US8139892B2</span>
    
    <span>US12/807,375</span>
    
    <span>US80737510A</span>
    
    <span>US8139892B2</span>
    
    <span>US 8139892 B2</span>
    
    <span>US8139892 B2</span>
    
    <span>US 8139892B2</span>
    
    <span>  </span>
    
    <span> </span>
    
    <span> </span>
    
    <span>US 80737510 A</span>
    
    <span>US80737510 A</span>
    
    <span>US 80737510A</span>
    
    <span>US 8139892 B2</span>
    
    <span>US8139892 B2</span>
    
    <span>US 8139892B2</span>
    

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    
    <dd itemprop="priorArtKeywords" repeat>image</dd>
    <dd itemprop="priorArtKeywords" repeat>reference</dd>
    <dd itemprop="priorArtKeywords" repeat>test</dd>
    <dd itemprop="priorArtKeywords" repeat>producing</dd>
    <dd itemprop="priorArtKeywords" repeat>method</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2005-01-24">2005-01-24</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Active</span>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US12/807,375</dd>

  

  <dt>Other versions</dt>
  <dd itemprop="directAssociations" itemscope repeat>
    
    <a href="/patent/US20100329585A1/en">
      <span itemprop="publicationNumber">US20100329585A1</span>
      (<span itemprop="primaryLanguage">en</span>
    </a>
  </dd>

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>Andrew B. Watson</dd>
  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    National Aeronautics and Space Administration (NASA)
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>National Aeronautics and Space Administration (NASA)</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2005-01-24">2005-01-24</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2010-08-09">2010-08-09</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2012-03-20">2012-03-20</time></dd>

  

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2005-01-24">2005-01-24</time>
    <span itemprop="title">Priority to US11/045,041</span>
    <span itemprop="type">priority</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US7783130B2/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2010-08-09">2010-08-09</time>
    <span itemprop="title">Application filed by National Aeronautics and Space Administration (NASA)</span>
    <span itemprop="type">filed</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    <span itemprop="assigneeSearch">National Aeronautics and Space Administration (NASA)</span>
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2010-08-09">2010-08-09</time>
    <span itemprop="title">Priority to US12/807,375</span>
    <span itemprop="type">priority</span>
    
    
    
    <span itemprop="documentId">patent/US8139892B2/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2010-12-30">2010-12-30</time>
    <span itemprop="title">Publication of US20100329585A1</span>
    <span itemprop="type">publication</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US20100329585A1/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2012-03-20">2012-03-20</time>
    <span itemprop="title">Application granted</span>
    <span itemprop="type">granted</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2012-03-20">2012-03-20</time>
    <span itemprop="title">Publication of US8139892B2</span>
    <span itemprop="type">publication</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US8139892B2/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
<<<<<<< HEAD
    <time itemprop="date" datetime="2019-11-25">2019-11-25</time>
=======
    <time itemprop="date" datetime="2019-11-26">2019-11-26</time>
>>>>>>> nc_dev
    <span itemprop="title">Application status is Active</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2025-01-24">2025-01-24</time>
    <span itemprop="title">Anticipated expiration</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  

  <h2>Links</h2>

  <ul>
    
          <li itemprop="links" itemscope repeat>
            <meta itemprop="id" content="usptoLink">
            <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PALL&s1=8139892.PN." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
          </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=8139892" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="http://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=8139892B2&amp;KC=B2&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="globalDossierLink">
          <a href="http://globaldossier.uspto.gov/#/result/patent/US/8139892/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
        </li>
      

      

      

      

      <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="stackexchangeLink">
          <a href="https://patents.stackexchange.com/questions/tagged/US8139892" itemprop="url"><span itemprop="text">Discuss</span></a>
        </li>
      
  </ul>

  
  <ul itemprop="concept" itemscope>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000873</span>
      <span itemprop="name">masking</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">11</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007781</span>
      <span itemprop="name">pre-processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">10</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000035945</span>
      <span itemprop="name">sensitivity</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">9</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">23</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000007</span>
      <span itemprop="name">visual effect</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">16</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000203</span>
      <span itemprop="name">mixtures</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">15</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000011388</span>
      <span itemprop="name">polymer cement concrete</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">12</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001914</span>
      <span itemprop="name">filtration</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">7</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009740</span>
      <span itemprop="name">moulding (composite fabrication)</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002123</span>
      <span itemprop="name">temporal effects</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">235000019557</span>
      <span itemprop="name">luminance</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">20</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">241000282414</span>
      <span itemprop="name">Homo sapiens</span>
      <span itemprop="domain">Species</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">11</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000694</span>
      <span itemprop="name">effects</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">7</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000005259</span>
      <span itemprop="name">measurements</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">4</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001131</span>
      <span itemprop="name">transforming</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">4</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004438</span>
      <span itemprop="name">eyesight</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000015654</span>
      <span itemprop="name">memory</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004458</span>
      <span itemprop="name">analytical methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006243</span>
      <span itemprop="name">chemical reaction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">235000019571</span>
      <span itemprop="name">color</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000004567</span>
      <span itemprop="name">concrete</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010276</span>
      <span itemprop="name">construction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000875</span>
      <span itemprop="name">corresponding</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009499</span>
      <span itemprop="name">grossing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010191</span>
      <span itemprop="name">image analysis</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003384</span>
      <span itemprop="name">imaging method</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000000047</span>
      <span itemprop="name">products</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002829</span>
      <span itemprop="name">reduced</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001603</span>
      <span itemprop="name">reducing</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">241000282412</span>
      <span itemprop="name">Homo</span>
      <span itemprop="domain">Species</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003190</span>
      <span itemprop="name">augmentative</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">235000020127</span>
      <span itemprop="name">ayran</span>
      <span itemprop="domain">Nutrition</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001721</span>
      <span itemprop="name">combination</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007906</span>
      <span itemprop="name">compression</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002708</span>
      <span itemprop="name">enhancing</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003203</span>
      <span itemprop="name">everyday</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000014509</span>
      <span itemprop="name">gene expression</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001965</span>
      <span itemprop="name">increased</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000002372</span>
      <span itemprop="name">labelling</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000670</span>
      <span itemprop="name">limiting</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000004973</span>
      <span itemprop="name">liquid crystal related substances</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004519</span>
      <span itemprop="name">manufacturing process</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004297</span>
      <span itemprop="name">night vision</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000003287</span>
      <span itemprop="name">optical</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003908</span>
      <span itemprop="name">quality control methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006722</span>
      <span itemprop="name">reduction reaction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000009877</span>
      <span itemprop="name">rendering</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000004065</span>
      <span itemprop="name">semiconductor</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000003860</span>
      <span itemprop="name">storage</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000001356</span>
      <span itemprop="name">surgical procedure</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
  </ul>
  

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/e3/d0/50/30e443214a0455/US08139892-20120320-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/56/8e/b3/2e20f98663adfb/US08139892-20120320-D00000.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100">
            <meta itemprop="label" content="images">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="374">
              <meta itemprop="top" content="120">
              <meta itemprop="right" content="478">
              <meta itemprop="bottom" content="173">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100a">
            <meta itemprop="label" content="test image">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="495">
              <meta itemprop="top" content="384">
              <meta itemprop="right" content="623">
              <meta itemprop="bottom" content="440">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="100b">
            <meta itemprop="label" content="reference image">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="448">
              <meta itemprop="top" content="1398">
              <meta itemprop="right" content="576">
              <meta itemprop="bottom" content="1453">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="102">
            <meta itemprop="label" content="CSF">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1169">
              <meta itemprop="top" content="534">
              <meta itemprop="right" content="1266">
              <meta itemprop="bottom" content="588">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="0">
            <meta itemprop="id" content="103">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1576">
              <meta itemprop="top" content="512">
              <meta itemprop="right" content="1674">
              <meta itemprop="bottom" content="578">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/d5/3a/57/a32b0b7d0553e1/US08139892-20120320-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/f2/36/6a/fc76edc1ac10eb/US08139892-20120320-D00001.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="100a">
            <meta itemprop="label" content="test image">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="386">
              <meta itemprop="top" content="2368">
              <meta itemprop="right" content="440">
              <meta itemprop="bottom" content="2477">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="102">
            <meta itemprop="label" content="CSF">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="540">
              <meta itemprop="top" content="1723">
              <meta itemprop="right" content="595">
              <meta itemprop="bottom" content="1808">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="1">
            <meta itemprop="id" content="103">
            <meta itemprop="label" content="operation">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="536">
              <meta itemprop="top" content="1308">
              <meta itemprop="right" content="587">
              <meta itemprop="bottom" content="1385">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/81/22/ea/6e2b4af54dce1b/US08139892-20120320-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/6b/79/b1/6016fb6cad09c4/US08139892-20120320-D00002.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="2">
<<<<<<< HEAD
            <meta itemprop="label" content="lscale">
=======
            <meta itemprop="label" content="pscale">
>>>>>>> nc_dev
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="495">
              <meta itemprop="top" content="1064">
              <meta itemprop="right" content="557">
              <meta itemprop="bottom" content="1185">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="2">
            <meta itemprop="id" content="201">
            <meta itemprop="label" content="target">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1226">
              <meta itemprop="top" content="1546">
              <meta itemprop="right" content="1279">
              <meta itemprop="bottom" content="1631">
            </span>
          </li>
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/35/00/d1/1a15b080050283/US08139892-20120320-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/74/0d/46/6cfb0a0bee8704/US08139892-20120320-D00003.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/b6/29/27/19c1572d0efbdb/US08139892-20120320-D00004.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/1c/d7/0f/e4317ce12446d9/US08139892-20120320-D00004.png">
        <ul>
          <li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="250">
            <meta itemprop="label" content="illustrative computer system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="389">
              <meta itemprop="top" content="1868">
              <meta itemprop="right" content="443">
              <meta itemprop="bottom" content="1967">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="252">
            <meta itemprop="label" content="processor">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="525">
              <meta itemprop="top" content="1633">
              <meta itemprop="right" content="585">
              <meta itemprop="bottom" content="1738">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="254">
            <meta itemprop="label" content="display">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="467">
              <meta itemprop="top" content="1216">
              <meta itemprop="right" content="524">
              <meta itemprop="bottom" content="1310">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="258">
            <meta itemprop="label" content="communications interface">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1086">
              <meta itemprop="top" content="251">
              <meta itemprop="right" content="1142">
              <meta itemprop="bottom" content="357">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="262">
            <meta itemprop="label" content="output interfaces">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="427">
              <meta itemprop="top" content="165">
              <meta itemprop="right" content="497">
              <meta itemprop="bottom" content="272">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="266">
            <meta itemprop="label" content="keyboard">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="530">
              <meta itemprop="top" content="778">
              <meta itemprop="right" content="592">
              <meta itemprop="bottom" content="878">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="268">
            <meta itemprop="label" content="similar device">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="836">
              <meta itemprop="top" content="666">
              <meta itemprop="right" content="890">
              <meta itemprop="bottom" content="754">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="272">
            <meta itemprop="label" content="printer">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="531">
              <meta itemprop="top" content="197">
              <meta itemprop="right" content="607">
              <meta itemprop="bottom" content="292">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="274">
            <meta itemprop="label" content="generation devices">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1496">
              <meta itemprop="top" content="319">
              <meta itemprop="right" content="1549">
              <meta itemprop="bottom" content="405">
            </span>
          </li><li itemprop="callouts" itemscope repeat>
            <meta itemprop="figurePage" content="4">
            <meta itemprop="id" content="280">
            <meta itemprop="label" content="operating system">
            
            <span itemprop="bounds" itemscope>
              <meta itemprop="left" content="1179">
              <meta itemprop="top" content="671">
              <meta itemprop="right" content="1234">
              <meta itemprop="bottom" content="772">
            </span>
          </li>
        </ul>
      </li>
      </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    
    <ul>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/0002</span>&mdash;<span itemprop="Description">Inspection of images, e.g. flaw detection</span>
            <meta itemprop="Leaf" content="true">
            
            <meta itemprop="FirstCode" content="true">
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H</span>&mdash;<span itemprop="Description">ELECTRICITY</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04</span>&mdash;<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N</span>&mdash;<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N19/00</span>&mdash;<span itemprop="Description">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N19/60</span>&mdash;<span itemprop="Description">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using transform coding</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H</span>&mdash;<span itemprop="Description">ELECTRICITY</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04</span>&mdash;<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N</span>&mdash;<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N19/00</span>&mdash;<span itemprop="Description">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N19/85</span>&mdash;<span itemprop="Description">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N19/86</span>&mdash;<span itemprop="Description">Methods or arrangements for coding, decoding, compressing or decompressing digital video signals using pre-processing or post-processing specially adapted for video compression involving reduction of coding artifacts, e.g. of blockiness</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/30</span>&mdash;<span itemprop="Description">Subject of image; Context of image processing</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/30168</span>&mdash;<span itemprop="Description">Image quality inspection</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H</span>&mdash;<span itemprop="Description">ELECTRICITY</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04</span>&mdash;<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N</span>&mdash;<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N17/00</span>&mdash;<span itemprop="Description">Diagnosis, testing or measuring for television systems or their details</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N17/04</span>&mdash;<span itemprop="Description">Diagnosis, testing or measuring for television systems or their details for receivers</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      </ul>
  </section>

  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA93488647" lang="EN" load-source="patent-office">
    <div num="p-0001" class="abstract">The present invention relates to devices and methods for the measurement and/or for the specification of the perceptual intensity of a visual image, or the perceptual distance between a pair of images. Grayscale test and reference images are processed to produce test and reference luminance images. A luminance filter function is convolved with the reference luminance image to produce a local mean luminance reference image. Test and reference contrast images are produced from the local mean luminance reference image and the test and reference luminance images respectively, followed by application of a contrast sensitivity filter. The resulting images are combined according to mathematical prescriptions to produce a Just Noticeable Difference, JND value, indicative of a Spatial Standard Observer, SSO. Some embodiments include masking functions, window functions, special treatment for images lying on or near borders and pre-processing of test images.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><div mxw-id="PDES45393274" lang="EN" load-source="patent-office" class="description">
    
    <p num="p-0002">This application is a continuation of prior application Ser. No. 11/045,041 filed Jan. 24, 2005 now U.S. Pat. No. 7,783,130.</p>
    
    
    <heading>ORIGIN OF INVENTION</heading>
    <p num="p-0003">The invention described herein was made by employees of the United States Government and may be manufactured and used by or for the Government for governmental purposes without payment of any royalties thereon or therefor.</p>
    
    
    <heading>BACKGROUND OF INVENTION</heading>
    <p num="p-0004">3.a Technical Field of the Invention</p>
    <p num="p-0005">This invention relates generally to the field of devices and methods for the specification and measurement of the perceptual intensity of one or more visual images and, more particularly, to the rapid and efficient determination of a visibility metric for such images.</p>
    <p num="p-0006">3.b. Description of the Prior Art</p>
    <p num="p-0007">Vision is the means by which most people acquire and process information about the world around them. Numerous objects intended for human use include a component of information to be identified visually by a human observer. Some everyday examples include information displayed on a screen or page, keys or buttons to be pressed on a keyboard, telephone, calculator, remote control unit, among many other examples. Therefore, it is reasonable that the design of such objects include specifications to insure that the visual information is accessible to typical human observers, that is, that the information is visible. Providing a means for measuring and specifying visibility, a visibility metric, is an objective of the present invention.</p>
    <p num="p-0008">A significant challenge in designing standards for visibility is that such standards are based upon models of the human visual sense. However, vision is a complex and only partially understood process. Previous standards for visibility have thus tended to be complex, difficult to use and not sufficiently general to serve as a standard method or methods for the specification and measurement of visibility. The performance of various visibility metrics has been reviewed by Ahumada and coworkers in two publications: <i>Society for Information Display, International Symposium, Digest of Technical Papers </i>Vol. 24, pp. 305-308 (1993) and Vol. 26. pp. 45-48 (1995), the contents of both publications are incorporated herein by reference.</p>
    <p num="p-0009">Other examples of visibility metrics include the work of Lubin and co-workers U.S. Pat. No. 6,654,504, US Patent Application Publication 2002/0031277 and A Human System Model for Objective Picture Quality Measurements, <i>Proceedings, International Broadcasters&#39; Convention</i>, Amsterdam, The Netherlands, pp. 498-503 (1997). These methods developed by Lubin and co-workers require extensive calibration for each application in addition to suffering from the disadvantage of complexity. These methods are chiefly intended for image quality evaluation.</p>
    <p num="p-0010">Other methods for estimating visibility include those of Barten, The SQRI Method: A New Method for the Evaluation of Visible Resolution on a Display, <i>Proceedings of the Society for Information Display</i>, Vol. 28, pp. 253-262 (1987). In addition to complexity, the Barten method suffers from the further disadvantage of being appropriate primarily for the specification of displays such as television monitors.</p>
    <p num="p-0011">Standards for the measurement and specification of color are known in the art and widely used. However, such color standards typically do not address the spatial pattern employed in a visual signal (for example, the shape of a letter). Consequently, such methods are not appropriate for specifying or measuring visibility.</p>
    <p num="p-0012">Thus, a need exists in the art for a standard specification and measurement of visibility, sufficiently general to be applicable to large classes of visual information but sufficiently simple for widespread implementation and use, including embedding into inexpensive systems.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="p-0013">Accordingly and advantageously, the present invention relates to systems and techniques for processing visual information to produce a single numerical value for the visibility metric indicative of a Spatial Standard Observer (SSO). Advantages of the SSO include a simple and efficient design that produces an accurate visibility metric with a relatively few calculations.</p>
    <p num="p-0014">Some embodiments of the present invention use a Minkowski sum directly over filtered image pixels. This technique avoids the need for complicated spatial frequency filter banks, with a corresponding gain in simplicity and computational efficiency.</p>
    <p num="p-0015">A particular form of Contrast Sensitivity Filter (CSF) is used in some embodiments of the present invention which combines radial- and oblique-effect filters. This permits accurate visibility predictions of the visibility of oblique patterns such as half-toning and rasterizing artifacts.</p>
    <p num="p-0016">Viewing distance and image resolution are jointly treated in an advantageous manner in some embodiments of the present invention. The use of this feature causes the computed value of image visibility to be substantially independent of image resolution (except to the extent that the resolution actually alters the visibility of the information in the image).</p>
    <p num="p-0017">A window function is advantageously employed in some embodiments of the present invention in such a manner as to represent the reduction in visibility with distance from the observer&#39;s region of fixation.</p>
    <p num="p-0018">It is advantageous in some embodiments of the present invention to use convolution operations along with the window function. In this manner it is feasible to simulate the scanning of an image by the eye of the observer.</p>
    <p num="p-0019">Pooling the data accumulates the visibility over the scan and is advantageously employed in some embodiments of the present invention.</p>
    <p num="p-0020">When images are located near a border region, it may occur that the border has a markedly different intensity (typically darker) than that of the image and the general image background. In such cases, it is advantageous in some embodiments of the present invention to introduce special procedures for handling border effects. Two examples are presented. One includes at least a portion of the border into the definition of image leading to a enhanced image that is then processed by the SSO. Another approach is to attenuate the image contrast near the border.</p>
    <p num="p-0021">The SSO provides a standardized measure of visibility, allowing comparisons to be made of visibility measurements taken in a wide variety of applications, locations and times. Manufacturing and engineering specifications of visibility in standardized units can then be made.</p>
    <p num="p-0022">Furthermore, SSO visibility measurements are not limited by target size. Thus, very large or very small displays can use SSO.</p>
    <p num="p-0023">The SSO further provides the feasibility of making simple, automated measurements of the visibility of visual information, not requiring the use of human observers to estimate visibility. Simplicity of measurement is an important feature of SSO in order to allow SSO to be adopted in a wide variety of applications and at low cost.</p>
    <p num="p-0024">SSO has numerous potential areas of application. We note a few applications as illustrative of the utility of SSO, not thereby limiting the scope of SSO to only those enumerated. Many other applications are apparent to those with ordinary skill in the art, within the scope of the present invention. Possible applications include:
</p> <ul> <li id="ul0001-0001" num="0000"> <ul> <li id="ul0002-0001" num="0024">Photometric Instruments incorporating SSO to produce a spatial photometer for the measurement of the visibility of spatial patterns.</li> <li id="ul0002-0002" num="0025">Imaging Devices and Systems employing SSO to calculate the visibility of targets as viewed through those systems such as infrared viewing systems and remote viewing systems (e.g., as in unmanned aerial vehicles).</li> <li id="ul0002-0003" num="0026">Copier Manufacturing employing SSO to measure the visibility of defects produced by copiers and thus test the copier and/or improve copier design.</li> <li id="ul0002-0004" num="0027">Video Codecs employing SSO in testing and/or design to measure the visibility of image compression artifacts with a view towards reducing visible defects and increasing bitrate.</li> <li id="ul0002-0005" num="0028">Display Manufacturing employing SSO to detect and measure visible artifacts with a view towards improving and automating product quality control and output by only rejecting devices having visible artifacts.</li> <li id="ul0002-0006" num="0029">Graphics Software employing SSO to estimate the visibility of graphic elements and/or to estimate the visibility of artifacts due to the rendering process.</li> <li id="ul0002-0007" num="0030">Predicting Visual Performance of Humans Following Vision Correction using SSO and thereby pre-evaluate the relative efficacy of various correction procedures before surgery.</li> <li id="ul0002-0008" num="0031">Digital Watermarking employing SSO to calculate the visibility of a recoverable signature labeling an image that is intended to be invisible to a human viewer.</li> </ul> </li> </ul>

    <p num="p-0025">These are among the advantages achieved in accordance with various embodiments of the present invention as described in detail below.</p>
    
    
    <description-of-drawings>
      <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
      <p num="p-0026">To facilitate understanding, identical reference numerals have been used, where possible, to designate identical elements that are common to the figures.</p>
      <p num="p-0027">The techniques of the present invention can readily be understood by considering the following detailed description in conjunction with the following drawings, in which:</p>
      <p num="p-0028"> <figref idrefs="DRAWINGS">FIG. 1</figref> depicts a high-level block diagram of a typical embodiment of a Spatial Standard Observer used to compute a visibility metric.</p>
      <p num="p-0029"> <figref idrefs="DRAWINGS">FIG. 2</figref> depicts a typical target adjacent to a dark border surrounding the image.</p>
      <p num="p-0030"> <figref idrefs="DRAWINGS">FIG. 3</figref> depicts a typical border aperture function that, in this example, has 240 columns, 180 rows, each pixel is ( 1/60) degree in height and width. The value of the parameter bscale is 0.50 deg., and bgain is 1.</p>
      <p num="p-0031"> <figref idrefs="DRAWINGS">FIG. 4</figref> depicts a high-level block diagram of an exemplary computer system that can be used for implementation of techniques of the Spatial Standard Observer.</p>
    </description-of-drawings>
    
    
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="p-0032">After considering the following description, those skilled in the art will clearly realize that the teachings of the invention can be readily utilized for determining the probable visibility of various graphical or visual depictions and displays as viewed by a typical human observer. In particular, the present invention relates generally to systems and techniques for processing one or more images to produce a single numerical value, or visibility metric, indicative of a Spatial Standard Observer (SSO). Advantages of the present invention include techniques for the rapid evaluation of the SSO.</p>
    <p num="p-0033">The present invention relates generally to devices and methods for the measurement and/or for the specification of the perceptual intensity of a visual image. Other embodiments relate generally to devices and methods for the measurement and/or for the specification of differences in perception or perceptual distance between two or more visual images. Such devices and methods can be advantageously used in situations in which it is desired to measure or to specify visibility or visual intensity. Examples include the determination of visibility and/or discriminability of text, graphic elements, labels, icons, among other visual images. Examples also include the determination of visibility and/or discriminability between images, such as an original image and a compressed digital form of that image. Some embodiments of the present invention can also be advantageously used to quantify the visibility of blemishes on a display as might be useful, for example, in providing objective determinations of pass/fail criteria in the manufacture of displays.</p>
    <p num="p-0034">In essence, various embodiments of the present invention operate on a digital image (or an analog image following digitization) or on a pair of digital images. An arbitrary number of images can be compared by repeated pairwise comparisons. Thus, for economy of language we will describe applications of the present invention to a single digital image or to the comparison of two digital images, understanding that this is by way of illustration and not limitation since multiple images can be handled by multiple applications of such pairwise comparisons. Analogue images can be handled within the scope of the present invention following digitization by any of numerous digitization techniques well-known in the art, such as use of a digital camera, a scanner, among other devices and digitization techniques known in the field.</p>
    <p num="p-0035">In the comparison of two digital images, it is advantageous in some embodiments of the present invention to pre-process the images to erase any inessential difference before presenting them as input to the SSO. Such pre-processing removal of inessential differences can improve the speed to SSO processing, further enhancing the range of potential applications amenable to SSO processing.</p>
    <p num="p-0036">Also, by way of illustration and not limitation, it will be presumed in our descriptions that the images are viewed on a particular display called the reference display, and viewed at a particular viewing distance. Techniques are well-known in the art for translating an image on a non-reference display into a digital representation as it would appear on the reference display, and for translating from an arbitrary viewing distance and angle to a standard viewing distance and angle.</p>
    <p num="p-0037">Typical inputs in the construction of a Spatial Standard Observer (SSO) are two digital images having (or scaled so as to have) the same size, called herein a test image and a reference image. G(x,y) is defined to be the grayscale of the pixel at column x and row y; G<sub>test</sub>(x,y), G<sub>reference</sub>(x,y) for the test and reference images respectively. We take the dimension of the image to be n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height). Typical values are n<sub>x</sub>=640 and n<sub>y</sub>=480.</p>
    <p num="p-0038">Letting s<sub>x </sub>and s<sub>y </sub>be the viewing angles subtended by the image in the x and y directions respectively, the viewing angles s<sub>x</sub>, s<sub>y </sub>can be derived from the viewing distance and the image size in the plane of the display by the use of Eq. 1 twice, once to compute s<sub>x </sub>and once to compute s<sub>y</sub>.</p>
    <p num="p-0039"> <maths id="MATH-US-00001" num="00001"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mi>tan</mi> <mo></mo> <mrow> <mo>{</mo> <mrow> <mrow> <mo>(</mo> <mrow> <mi></mi> <mo>*</mo> <mi>size</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mrow> <mo>(</mo> <mi>degrees</mi> <mo>)</mo> </mrow> <mo>/</mo> <mn>360</mn> </mrow> </mrow> <mo>}</mo> </mrow> <mo>=</mo> <mrow> <mrow> <mrow> <mo>(</mo> <mrow> <mn>0.5</mn> <mo>*</mo> <mi>size</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mi>cm</mi> <mo>)</mo> </mrow> </mrow> <mo>)</mo> </mrow> <mo>/</mo> <mi>viewing</mi> </mrow> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mi>distance</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mi>cm</mi> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>1</mn> </mrow> <mo></mo> <mi>a</mi> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <mi>size</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mi>degrees</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mfrac> <mn>360</mn> <mrow> <mn>2</mn> <mo></mo> <mi></mi> </mrow> </mfrac> <mo></mo> <mfrac> <mrow> <mi>size</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mi>cm</mi> <mo>)</mo> </mrow> </mrow> <mrow> <mi>viewing</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mi>distance</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mi>cm</mi> <mo>)</mo> </mrow> </mrow> </mfrac> </mrow> </mrow> </mtd> <mtd> <mrow> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>1</mn> </mrow> <mo></mo> <mi>b</mi> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
Eq. 1b follows from Eq. 1a only when the ratio (size/(viewing distance)) is much less than one. But this is true in virtually all cases of practical interest so we use Eq. 1b hereinafter. Also, the designation of cm in Eq. 1a and 1b is for convenience, since it is only necessary that size and viewing distance be expressed in the same units of length.
</p>
    <p num="p-0040">The width and height of each pixel, p<sub>x </sub>and P<sub>y </sub>respectively, are given by Eq. 2 with p<sub>x</sub>, p<sub>y </sub>in degrees if s<sub>x </sub>and s<sub>y </sub>are in degrees. Typical values are s<sub>x</sub>=8 deg. and s<sub>y</sub>=6 deg. yielding typical values for p<sub>x</sub>=p<sub>y</sub>=( 1/80) deg.</p>
    <p num="p-0041">
      <maths id="MATH-US-00002" num="00002">
        <math overflow="scroll">
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <msub>
                      <mi>p</mi>
                      <mi>x</mi>
                    </msub>
                    <mo>=</mo>
                    <mfrac>
                      <msub>
                        <mi>s</mi>
                        <mi>x</mi>
                      </msub>
                      <msub>
                        <mi>n</mi>
                        <mi>x</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                  <mo>,</mo>
                  <mrow>
                    <msub>
                      <mi>p</mi>
                      <mi>y</mi>
                    </msub>
                    <mo>=</mo>
                    <mfrac>
                      <msub>
                        <mi>s</mi>
                        <mi>y</mi>
                      </msub>
                      <msub>
                        <mi>n</mi>
                        <mi>y</mi>
                      </msub>
                    </mfrac>
                  </mrow>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mi>Eq</mi>
                  <mo>.</mo>
                  <mstyle>
                    <mspace width="0.8em" height="0.8ex"> </mspace>
                  </mstyle>
                  <mo></mo>
                  <mn>2</mn>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </math>
      </maths>
    </p>
    <p num="p-0042">The test and reference images, G<sub>test</sub>(x,y) and G<sub>reference</sub>(x,y) respectively, may contain noise, or may differ in those image components having high spatial frequencies whose visibilities are not of interest for the particular image analysis under consideration. In addition, the images may be captured at a higher resolution or larger area than is necessary for the particular image analysis. For these and other reasons, it may be useful to pre-process the test and reference images to remove noise, remove high frequency components and other components not significantly affecting the visibility analysis, to reduce image resolution, and/or to crop the image to a rectangle of interest (or other convenient shape). Such operations can be performed by filtering, downsampling and cropping, pursuant to some embodiments of the present invention. Such operations are optional and, when employed, can be employed in any combination, sequence or number. That is, multiple steps of each operation can be performed whenever advantageous to do so, and the sequence of various operations or combinations can also be adjusted for the particular image processing task at hand. To be concrete in our description, we describe typical pre-processing operations, individually and in a particular sequence, understanding thereby that the present invention is not limited to the particular steps, sequence, number or type of operations described.</p>
    <p num="p-0043">It is convenient in some, embodiments to pre-filter the test and reference images by convolution with a pre-filter function PF(x,y) pursuant to Eq. 2.1
<br/>
<i>G</i>(<i>x,y</i>)=<i>PF</i>(<i>x,y</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00001" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <i>G</i>(<i>x,y</i>)Eq. 2.1
<br/>
for G<sub>test</sub>(x,y) and G<sub>reference</sub>(x,y) respectively. The G function of Eq. 2.1, the pre-processed image, is then used in place of G in subsequent image processing, including in Eqs. 3, 4 and following.
</p>
    <p num="p-0044">In some embodiments of the present invention, it is convenient to use a pre-filter function PF(x,y) given by Eq. 2.2.</p>
    <p num="p-0045"> <maths id="MATH-US-00003" num="00003"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mrow> <mi>PF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mrow> <mi>PF</mi> <mo></mo> <mrow> <mo>(</mo> <mi>r</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mfrac> <mn>1</mn> <msup> <mi>pscale</mi> <mn>2</mn> </msup> </mfrac> <mo></mo> <mrow> <mi>Exp</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mo>-</mo> <msup> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mfrac> <mi>r</mi> <mi>pscale</mi> </mfrac> <mo>)</mo> </mrow> </mrow> <mn>2</mn> </msup> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> <mo></mo> <mstyle> <mtext>
</mtext> </mstyle> <mo></mo> <mrow> <mi>r</mi> <mo>=</mo> <msqrt> <mrow> <msup> <mrow> <mo>(</mo> <msub> <mi>xp</mi> <mi>x</mi> </msub> <mo>)</mo> </mrow> <mn>2</mn> </msup> <mo>+</mo> <msup> <mrow> <mo>(</mo> <msub> <mi>yp</mi> <mi>y</mi> </msub> <mo>)</mo> </mrow> <mn>2</mn> </msup> </mrow> </msqrt> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>2.2</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which pscale is a parameter, conveniently taken to be 0.125 degree in some embodiments.
</p>
    <p num="p-0046">The test and reference images can be downsampled by integer factors in the x and y directions {d<sub>x</sub>, d<sub>y</sub>} respectively, by selecting every d<sub>x</sub>-th column and d<sub>y</sub>-th row from the original image to create a new, downsampled image G(x,y). This operation is conveniently expressed in terms of a downsampling operator DS as
<br/>
<i>G</i>(<i>x,y</i>)=<i>DS</i>(<i>G</i>(<i>x,y</i>),<i>d</i> <sub>x</sub> <i>d</i> <sub>y</sub>)Eq. 2.3
</p>
    <p num="p-0047">The new dimensions of the test and reference images in the x and y directions are thus given as n<sub>x</sub> and n<sub>y</sub> as in Eq. 2.4.</p>
    <p num="p-0048"> <maths id="MATH-US-00004" num="00004"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <msubsup> <mi>n</mi> <mi>x</mi> <mi></mi> </msubsup> <mo>=</mo> <mrow> <mi>Floor</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mfrac> <msub> <mi>n</mi> <mi>x</mi> </msub> <msub> <mi>d</mi> <mi>x</mi> </msub> </mfrac> <mo>)</mo> </mrow> </mrow> </mrow> <mo></mo> <mstyle> <mtext>
</mtext> </mstyle> <mo></mo> <mrow> <msubsup> <mi>n</mi> <mi>y</mi> <mi></mi> </msubsup> <mo>=</mo> <mrow> <mi>Floor</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mo>(</mo> <mfrac> <msub> <mi>n</mi> <mi>y</mi> </msub> <msub> <mi>d</mi> <mi>y</mi> </msub> </mfrac> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>2.4</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which the function Floor[ ] returns the nearest integer less than or equal to its argument. Typical values for d<sub>x </sub>and d<sub>y </sub>are d<sub>x</sub>=d<sub>y</sub>=4.
</p>
    <p num="p-0049">Eq. 2.3 uses the pre-processed image G from Eq. 2.1 as the image from which the downsampled image G is derived. This is a particular example presented to be concrete in our description and not intending to limit the scope of the present invention. Although downsampling is almost always preceded by filtering to avoid aliasing, downsampling can be performed on an image with or without pre-filtering.</p>
    <p num="p-0050">The image G, G or G can be cropped to a rectangle of interest ROI. For definiteness, we describe cropping the G image having dimensions n<sub>x</sub> and n<sub>y</sub>. It is convenient to describe the ROI by the pixel coordinates of its lower left corner {x<sub>LL</sub>, y<sub>LL</sub>} and upper right corner {x<sub>UR</sub>, y<sub>UR</sub>} respectively. Cropping is conveniently performed by deleting from the image rows <b>1</b> through(y<sub>LL</sub>1) inclusive, and rows (y<sub>UR</sub>+1) through n<sub>y</sub> inclusive, as well as columns <b>1</b> through (x<sub>LL</sub>1) inclusive, and columns (x<sub>UR</sub>+1) through n<sub>x</sub> inclusive. The dimensions of the new, cropped image are thus
<br/>
<i>n</i> <sub>x</sub> <i>=x</i> <sub>UR</sub> <i>x</i> <sub>LL</sub>+1
<br/>
<i>n</i> <sub>y</sub> <i>=y</i> <sub>UR</sub> <i>y</i> <sub>LL</sub>+1Eq. 2.5
</p>
    <p num="p-0051">If the pre-processing techniques are used, singly or in combination, the resulting output images (test and reference) are considered the input images to the other image processing procedures described herein. New image dimensions (if present) should also be used.</p>
    <p num="p-0052">If a reference image is not readily available, it is convenient in some embodiments of the present invention to create one by deleting the target or structural component from a copy of the test image. If the target is confined to a local region on an otherwise uniform image with graylevel G<sub>0</sub>, then it is convenient in some embodiments of the present invention to create a reference image as a uniform image having the same size as the test image with a graylevel also equal to G<sub>0</sub>. Typical images are depicted as <b>100</b> in <figref idrefs="DRAWINGS">FIG. 1</figref> with test image <b>100</b> <i>a </i>and reference image <b>100</b> <i>b</i>. The structural component of the test image <b>100</b> <i>a </i>is shown adjacent to the image field merely for clarity of depiction, understanding that the images are actually superimposed.</p>
    <p num="p-0053">If a reference image is not available, some embodiments of the present invention obtain a reference image by processing the test image, for example, convolving the test image with a reference filter, RF(x,y). It is advantageous in some embodiments to pre-process the test image pursuant to one or more of the pre-processing techniques described herein (or others known in the field) before application of the reference filter, that is, convolve RF with G, G, G or equivalents, among others.</p>
    <p num="p-0054">In some embodiments, it is convenient to create a reference image by smoothing the test image and thereby suppress from the test image the signals whose visibility is of interest. For example, smoothing can conveniently be carried out with a Gaussian reference filter having the form given by Eq. 2.6.</p>
    <p num="p-0055"> <maths id="MATH-US-00005" num="00005"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mrow> <mi>RF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mrow> <mi>RF</mi> <mo></mo> <mrow> <mo>(</mo> <mi>r</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mfrac> <mn>1</mn> <msup> <mi>rscale</mi> <mn>2</mn> </msup> </mfrac> <mo></mo> <mrow> <mi>Exp</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mo>-</mo> <msup> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mfrac> <mi>r</mi> <mi>rscale</mi> </mfrac> <mo>)</mo> </mrow> </mrow> <mn>2</mn> </msup> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> <mo></mo> <mstyle> <mtext>
</mtext> </mstyle> <mo></mo> <mrow> <mi>r</mi> <mo>=</mo> <msqrt> <mrow> <msup> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo></mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo></mo> <msub> <mi>p</mi> <mi>x</mi> </msub> </mrow> <mo>)</mo> </mrow> <mn>2</mn> </msup> <mo>+</mo> <msup> <mrow> <mo>(</mo> <mrow> <mi>y</mi> <mo></mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo></mo> <msub> <mi>p</mi> <mi>y</mi> </msub> </mrow> <mo>)</mo> </mrow> <mn>2</mn> </msup> </mrow> </msqrt> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>2.6</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
rscale is a parameter conveniently chosen to be 2 degree.
</p>
    <p num="p-0056">The reference image is then created by convolving the test image with the reference filter, Eq. 2.6, either by employing conventional convolution (e.g., Eq. 5a, 5b, 5c) or, advantageously according to some embodiments of the present invention, using confined convolution, denoted by a confined convolution operator <div class="patent-image"><a href="https://patentimages.storage.googleapis.com/2b/2c/48/82da6e388ce648/US08139892-20120320-P00002.png"><img id="CUSTOM-CHARACTER-00002" he="4.23mm" wi="8.81mm" file="US08139892-20120320-P00002.TIF" alt="Figure US08139892-20120320-P00002" img-content="character" img-format="tif" orientation="portrait" inline="no" width="35" height="17" alt="Figure US08139892-20120320-P00002" class="patent-full-image" src="https://patentimages.storage.googleapis.com/2b/2c/48/82da6e388ce648/US08139892-20120320-P00002.png"/></a></div> as applied in Eq. 2.7.
<br/>
<i>G</i>(<i>x,y</i>)=<i>RF</i>(<i>x,y</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00003" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <sub>C</sub> <i>G</i>(<i>x,y</i>)Eq. 2.7
</p>
    <p num="p-0057">Eq. 2.7 depicts the example in which the pre-processed image G is convolved by confined convolution to produce a reference image G, understanding that pre-processing the test image is optional and conventional or other forms of convolution can be employed.</p>
    <p num="p-0058">Confined convolution offers some advantages in image processing. In standard cyclic convolution, the edges of the image are considered to be connected. Thus, image content close to one edge of the image may be spread over to the opposite edge, which is sometimes called the wrap-around problem. Confined convolution is a form of convolution which avoids the wrap-around problem by, in effect, disconnecting the opposing edges of the image.</p>
    <p num="p-0059">Confined convolution makes use of a Pad-Convolve-Crop (PCC) operator. The operands of the PCC operator are a general image function, I(x,y), and a kernel K(x,y) in which the kernel has k<sub>x </sub>columns and k<sub>y </sub>rows. The image I(x,y) is augmented or padded with rows and columns containing entries having a value of 0, such that the padded image has k<sub>x </sub>additional columns (of all 0&#39;s) and k<sub>y </sub>additional rows (of all 0&#39;s) in comparison with I(x,y). This padded I(x,y) is convolved with the kernel K(x,y). The image resulting from this convolution is then restored to the original image size by removing the added k<sub>y </sub>rows and k<sub>x </sub>columns. This sequence of operations defines the PCC operator operating on K and I, denoted as PCC(K(x,y),I(x,y)).</p>
    <p num="p-0060">The confined convolution of K(x,y) with I(x,y) is then given by Eq. 2.8.</p>
    <p num="p-0061"> <maths id="MATH-US-00006" num="00006"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mrow> <mi>K</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo></mo> <msub> <mo></mo> <mi>C</mi> </msub> <mo></mo> <mrow> <mi>I</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo>=</mo> <mfrac> <mrow> <mi>PCC</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mrow> <mi>K</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>,</mo> <mrow> <mi>I</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo>)</mo> </mrow> </mrow> <mrow> <mi>PCC</mi> <mo>(</mo> <mrow> <mfrac> <mrow> <mi>K</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mrow> <munder> <mo></mo> <mi>y</mi> </munder> <mo></mo> <mrow> <munder> <mo></mo> <mi>x</mi> </munder> <mo></mo> <mrow> <mi>K</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mfrac> <mo>,</mo> <mrow> <mn>1</mn> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo>)</mo> </mrow> </mfrac> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>2.8</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which 1(x,y) is an image (array) all of whose entries=1 and which has the same number of rows and columns as the (unpadded) image I(x,y).
</p>
    <p num="p-0062">The reference and test images (optionally, following pre-processing) are converted from a grayscale format to local luminance contrast image. This conversion is depicted schematically as Contrast <b>101</b> in <figref idrefs="DRAWINGS">FIG. 1</figref>. The first step in this conversion or image transformation is the computation of a luminance image L(x,y) from the grayscales of each image, test and reference, denoted generally as G(x,y) to indicate either G<sub>test</sub>(x,y) or G<sub>reference</sub>(x,y) respectively. For economy of language we frequently omit subscripts test and reference using a single unsubscripted letter to indicate two equations or two variables, one each for test and reference.</p>
    <p num="p-0063">This transformation from grayscale G(x,y) to a luminance image or luminance L(x,y) is advantageously performed by a gamma function Gamma as in Eq. 3.
<br/>
<i>L</i>(<i>x,y</i>)=Gamma[<i>G</i>(<i>x,y</i>)]Eq. 3
</p>
    <p num="p-0064">The particular form and parameters used for the Gamma function will depend on the particular characteristics of the device displaying the test and reference images. A typical version is Eq. 4 in which the luminance L(x,y) is given by:
<br/>
<i>L</i>(<i>x,y</i>)=<i>L</i> <sub>max</sub>(<i>G</i>(<i>x,y</i>)/<i>G</i> <sub>max</sub>)<sup></sup>Eq. 4
<br/>
in which L<sub>max </sub>is the maximum possible luminance in the image, G<sub>max </sub>is the corresponding maximum grayscale value.  is the gamma exponent of the display, approximately correcting for nonlinearities in the luminance characteristics of the display. A typical value for  is =2.2. Eq.s 3 and 4 are applied to both test and reference images.
</p>
    <p num="p-0065">A local luminance filter is employed having a luminance filter function LF(x,y). It is then convenient to introduce a local mean luminance reference image LL(x,y) obtained by the convolution of the reference luminance image L<sub>reference</sub>(x,y) with the luminance filter function by Eq. 5a
<br/>
<i>LL</i>(<i>x,y</i>)=<i>LF</i>(<i>x,y</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00004" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <i>L</i> <sub>reference</sub>(<i>x,y</i>)Eq. 5a
<br/>
in which <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00005" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> denotes convolution of the two functions defined in known texts in the field, for example Fourier Analysis and Imaging by Roger N. Bracewell, (Kluwer Academic/Plenum Publishers, 2003), pp. 174-179, incorporated herein by reference. The convolution can be expressed in discrete and continuous forms as in Eq. 5b and 5c respectively.
<br/>
<i>LF</i>(<i>x,y</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00006" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <i>L</i> <sub>reference</sub>(<i>x,y</i>)=<i>LF</i>(<i>x,y</i>)<i>L</i> <sub>reference</sub>(<i>x,y</i>)<i>dd</i>Eq. 5b
<br/>
where the integrals extend over the domain in which LF(,) is not zero. In discrete form the convolution is given by Eq. 5c.
</p>
    <p num="p-0066">
      <maths id="MATH-US-00007" num="00007">
        <math overflow="scroll">
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mrow>
                      <mrow>
                        <mi>LF</mi>
                        <mo></mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>x</mi>
                            <mo>,</mo>
                            <mi>y</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo></mo>
                      <mrow>
                        <msub>
                          <mi>L</mi>
                          <mi>reference</mi>
                        </msub>
                        <mo></mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>x</mi>
                            <mo>,</mo>
                            <mi>y</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                    <mo>=</mo>
                    <mrow>
                      <mo></mo>
                      <mo></mo>
                      <mrow>
                        <mi>LF</mi>
                        <mo></mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mrow>
                              <mi>Mod</mi>
                              <mo></mo>
                              <mrow>
                                <mo>(</mo>
                                <mrow>
                                  <mrow>
                                    <mi>x</mi>
                                    <mo>-</mo>
                                    <mi>j</mi>
                                  </mrow>
                                  <mo>,</mo>
                                  <msub>
                                    <mi>n</mi>
                                    <mi>x</mi>
                                  </msub>
                                </mrow>
                                <mo>)</mo>
                              </mrow>
                            </mrow>
                            <mo>,</mo>
                            <mrow>
                              <mi>Mod</mi>
                              <mo></mo>
                              <mrow>
                                <mo>(</mo>
                                <mrow>
                                  <mrow>
                                    <mi>y</mi>
                                    <mo>-</mo>
                                    <mi>k</mi>
                                  </mrow>
                                  <mo>,</mo>
                                  <msub>
                                    <mi>n</mi>
                                    <mi>y</mi>
                                  </msub>
                                </mrow>
                                <mo>)</mo>
                              </mrow>
                            </mrow>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mo></mo>
                      <mrow>
                        <msub>
                          <mi>L</mi>
                          <mi>reference</mi>
                        </msub>
                        <mo></mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>j</mi>
                            <mo>,</mo>
                            <mi>k</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mrow>
                  </mrow>
                  <mo></mo>
                  <mstyle>
                    <mtext>
</mtext>
                  </mstyle>
                  <mo></mo>
                  <mrow>
                    <mi>where</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mrow>
                      <mi>Mod</mi>
                      <mo></mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>a</mi>
                          <mo>,</mo>
                          <mi>b</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>is</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>the</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>remainder</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>when</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>a</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>is</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>divided</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mi>by</mi>
                    <mo></mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mrow>
                      <mi>b</mi>
                      <mo>.</mo>
                    </mrow>
                  </mrow>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>Eq</mi>
                    <mo>.</mo>
                    <mstyle>
                      <mspace width="0.8em" height="0.8ex"> </mspace>
                    </mstyle>
                    <mo></mo>
                    <mn>5</mn>
                  </mrow>
                  <mo></mo>
                  <mi>c</mi>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </math>
      </maths>
    </p>
    <p num="p-0067">In some embodiments of the present invention, it is convenient to use the luminance filter function LF(x,y) given by Eq, 6.</p>
    <p num="p-0068"> <maths id="MATH-US-00008" num="00008"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mrow> <mi>LF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mrow> <mi>LF</mi> <mo></mo> <mrow> <mo>(</mo> <mi>r</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mfrac> <mn>1</mn> <msup> <mi>lscale</mi> <mn>2</mn> </msup> </mfrac> <mo></mo> <mrow> <mi>Exp</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mo>-</mo> <msup> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mfrac> <mi>r</mi> <mi>lscale</mi> </mfrac> <mo>)</mo> </mrow> </mrow> <mn>2</mn> </msup> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> <mo></mo> <mstyle> <mtext>
</mtext> </mstyle> <mo></mo> <mrow> <mi>r</mi> <mo>=</mo> <msqrt> <mrow> <msup> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo></mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo></mo> <msub> <mi>p</mi> <mi>x</mi> </msub> </mrow> <mo>)</mo> </mrow> <mn>2</mn> </msup> <mo>+</mo> <msup> <mrow> <mo>(</mo> <mrow> <mi>y</mi> <mo></mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo></mo> <msub> <mi>p</mi> <mi>y</mi> </msub> </mrow> <mo>)</mo> </mrow> <mn>2</mn> </msup> </mrow> </msqrt> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>6</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which lscale is a parameter to be chosen. If lscale+, this corresponds to an LL that is constant and equal to the average luminance over the image.
</p>
    <p num="p-0069">The average (MEAN) luminance, L<sub>mean </sub>is given by a numerical average of the luminance over all pixels in the x and y directions, Eq. 7.</p>
    <p num="p-0070"> <maths id="MATH-US-00009" num="00009"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <msub> <mi>L</mi> <mi>mean</mi> </msub> <mo>=</mo> <mrow> <mfrac> <mn>1</mn> <mrow> <msub> <mi>n</mi> <mi>x</mi> </msub> <mo></mo> <msub> <mi>n</mi> <mi>y</mi> </msub> </mrow> </mfrac> <mo></mo> <mrow> <munderover> <mo></mo> <mi>y</mi> <msub> <mi>n</mi> <mi>y</mi> </msub> </munderover> <mo></mo> <mrow> <munderover> <mo></mo> <mi>x</mi> <msub> <mi>n</mi> <mi>x</mi> </msub> </munderover> <mo></mo> <mrow> <msub> <mi>L</mi> <mi>reference</mi> </msub> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>7</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
A typical value for L<sub>mean </sub>is 40 candelas per sq. meter (40 cd/m<sup>2</sup>).
</p>
    <p num="p-0071">The contrast or contrast image of each pixel, C(x,y) is then given by Eq. 8 applied to both test and reference luminance images L<sub>test</sub>(x, y) and L<sub>reference</sub>(x, y) respectively.</p>
    <p num="p-0072">
      <maths id="MATH-US-00010" num="00010">
        <math overflow="scroll">
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>C</mi>
                    <mo></mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <mrow>
                    <mfrac>
                      <mrow>
                        <mi>L</mi>
                        <mo></mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>x</mi>
                            <mo>,</mo>
                            <mi>y</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                      <mrow>
                        <mi>LL</mi>
                        <mo></mo>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <mi>x</mi>
                            <mo>,</mo>
                            <mi>y</mi>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                      </mrow>
                    </mfrac>
                    <mo>-</mo>
                    <mn>1</mn>
                  </mrow>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mi>Eq</mi>
                  <mo>.</mo>
                  <mstyle>
                    <mspace width="0.8em" height="0.8ex"> </mspace>
                  </mstyle>
                  <mo></mo>
                  <mn>8</mn>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </math>
      </maths>
    </p>
    <p num="p-0073">For the particular embodiments described thus far, L<sub>max </sub>plays no apparent role since it appears as a multiplicative factor in both L (Eq. 4), and LL (through L<sub>reference </sub>(Eq.s 4 and 5)) hence canceling from Eq. 8. (Under the typically reasonable presumption that both test and reference images have the same maximum possible luminances, L<sub>max</sub>). However, it is convenient to retain L<sub>max </sub>in the equations since it simplifies the application of the equations in other embodiments of the present invention in which L<sub>max </sub>and/or L<sub>mean </sub>may play a role in determining parameters of the process. A typical value for L<sub>max </sub>is 100 cd/m<sup>2</sup>.</p>
    <p num="p-0074">Following the construction of test and reference contrast functions via Eq. 8, both test and reference images are typically passed through a Contrast Sensitivity Filter (CSF), <b>102</b> in <figref idrefs="DRAWINGS">FIG. 1</figref>. While various embodiments of CSF are feasible and can be used in connection with the present invention, it is advantageous in connection with some embodiments of the present invention to work in the frequency domain following application of a Discrete Fourier Transform, DFT, and its inverse DFT<sup>1</sup>. In such cases, the filtering can be described by Eq. 9 as
<br/>
<i>F</i>(<i>x,y</i>)=<i>DFT</i> <sup>1</sup> <i>[CSF</i>(<i>u,v</i>)*<i>DFT[C</i>(<i>x,y</i>)]]Eq. 9
<br/>
in which C(x,y) is the contrast function of the image from Eq. 8 and F(x,y) is the filtered image.
</p>
    <p num="p-0075">The Discrete Fourier Transform and the Inverse Discrete Fourier Transform, DFT[ ] and DFT<sup>1</sup>[ ], are conventional operations in the field of digital signal processing and described in many texts, for example, the text by Bracewell, supra at pp. 167-168, incorporated herein by reference.</p>
    <p num="p-0076">CSF(u,v) is the discrete version of a Contrast Sensitivity Filter in the frequency domain, and u and v are horizontal and vertical frequency indices respectively in units of cycles/width and cycles/height.</p>
    <p num="p-0077">The discrete, frequency domain version of the Contrast Sensitivity filter, CSF(u,v) is conveniently given by the product of a radial contrast sensitivity function, RCSF(u,v), and an oblique effect contrast sensitivity filter, OEF(u,v), as expressed in Eq. 10.
<br/>
<i>CSF</i>(<i>u,v</i>)=<i>RCSF</i>(<i>u,v</i>)<i>OEF</i>(<i>u,v</i>)Eq. 10
</p>
    <p num="p-0078">In some embodiments of the present invention it is convenient to choose a radial function RCSF having the form given in Eq. 11.</p>
    <p num="p-0079"> <maths id="MATH-US-00011" num="00011"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>RCSF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>u</mi> <mo>,</mo> <mi>v</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mi>RCSF</mi> <mo></mo> <mrow> <mo>(</mo> <mi>f</mi> <mo>)</mo> </mrow> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>=</mo> <mrow> <mrow> <mi>gain</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mi>sech</mi> <mo></mo> <mrow> <mo>(</mo> <msup> <mrow> <mo>(</mo> <mfrac> <mi>f</mi> <msub> <mi>f</mi> <mn>0</mn> </msub> </mfrac> <mo>)</mo> </mrow> <mi>p</mi> </msup> <mo>)</mo> </mrow> </mrow> </mrow> <mo>-</mo> <mrow> <mi>loss</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mrow> <mi>sech</mi> <mo></mo> <mrow> <mo>(</mo> <mfrac> <mi>f</mi> <msub> <mi>f</mi> <mn>1</mn> </msub> </mfrac> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> </mtd> </mtr> </mtable> <mo></mo> <mstyle> <mtext>
</mtext> </mstyle> <mo></mo> <mrow> <mi>f</mi> <mo>=</mo> <msqrt> <mrow> <msup> <mrow> <mo>(</mo> <mfrac> <mi>u</mi> <msub> <mi>s</mi> <mi>x</mi> </msub> </mfrac> <mo>)</mo> </mrow> <mn>2</mn> </msup> <mo>+</mo> <msup> <mrow> <mo>(</mo> <mfrac> <mi>v</mi> <msub> <mi>s</mi> <mi>y</mi> </msub> </mfrac> <mo>)</mo> </mrow> <mn>2</mn> </msup> </mrow> </msqrt> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>11</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which sech is the hyperbolic secant function, gain, loss, f<sub>0</sub>, f<sub>1 </sub>and p are parameters. Typical values for these parameters are as follows:
</p> <ul> <li id="ul0003-0001" num="0000"> <ul> <li id="ul0004-0001" num="0087">f<sub>0</sub>=4.173</li> <li id="ul0004-0002" num="0088">f<sub>1</sub>=1.362</li> <li id="ul0004-0003" num="0089">loss=0.8493</li> <li id="ul0004-0004" num="0090">gain=373.1</li> <li id="ul0004-0005" num="0091">p=0.7786.</li> </ul> </li> </ul>

    <p num="p-0080">In some embodiments of the present invention, it is convenient to choose an oblique filter, OEF having the form given in Eq. 12.</p>
    <p num="p-0081"> <maths id="MATH-US-00012" num="00012"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>OEF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>u</mi> <mo>,</mo> <mi>v</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mi> </mi> <mo></mo> <mrow> <mi>OEF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>f</mi> <mo>,</mo> <mi></mi> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>=</mo> <mi> </mi> <mo></mo> <mrow> <mn>1</mn> <mo>-</mo> <mrow> <mo>(</mo> <mrow> <mn>1</mn> <mo>-</mo> <mrow> <mi>Exp</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mo>-</mo> <mfrac> <mrow> <mi>f</mi> <mo>-</mo> <mi>corner</mi> </mrow> <mi>slope</mi> </mfrac> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mi> </mi> <mo></mo> <mrow> <mrow> <mrow> <msup> <mi>Sin</mi> <mn>2</mn> </msup> <mo></mo> <mrow> <mo>(</mo> <mrow> <mn>2</mn> <mo></mo> <mi></mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mi>if</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mi>f</mi> </mrow> <mo>&gt;</mo> <mi>corner</mi> </mrow> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mo>=</mo> <mi> </mi> <mo></mo> <mrow> <mrow> <mn>1</mn> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mi>if</mi> <mo></mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mi>f</mi> </mrow> <mo></mo> <mi>corner</mi> </mrow> </mrow> </mtd> </mtr> </mtable> <mo></mo> <mstyle> <mtext>
</mtext> </mstyle> <mo></mo> <mrow> <mi></mi> <mo>=</mo> <mrow> <mi>ArcTan</mi> <mo>(</mo> <mrow> <mfrac> <mi>u</mi> <msub> <mi>s</mi> <mi>x</mi> </msub> </mfrac> <mo>,</mo> <mfrac> <mi>v</mi> <msub> <mi>s</mi> <mi>y</mi> </msub> </mfrac> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>12</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which corner and slope are parameters. Typical values for corner and slope are corner=3.481 and slope=13.57149.
</p>
    <p num="p-0082">Following processing of both the test image and the reference image by CSF, <b>102</b>, the resulting filtered images are subtracted pixel-by-pixel, <b>103</b>. The result is the difference image D(x,y) of Eq. 13.
<br/>
<i>D</i>(<i>x,y</i>)=<i>F</i> <sub>test</sub>(<i>x,y</i>)<i>F</i> <sub>reference</sub>(<i>x,y</i>)Eq. 13
</p>
    <p num="p-0083">In some embodiments of the present invention, it is advantageous to create a mask image, M(x,y), from the filtered reference image F<sub>reference</sub>(x,y). In such embodiments, the absolute value of the filtered reference image is raised to a power a, convolved with a masking filter MF(x,y), added to the constant l and the b&#39;th root of the resulting expression is computed as in Eq. 14.</p>
    <p num="p-0084"> <maths id="MATH-US-00013" num="00013"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>M</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <msup> <mrow> <mo>[</mo> <mrow> <mn>1</mn> <mo>+</mo> <mrow> <mrow> <mi>MF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo></mo> <msup> <mrow> <mo></mo> <mrow> <msub> <mi>F</mi> <mi>reference</mi> </msub> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo></mo> </mrow> <mi>a</mi> </msup> </mrow> </mrow> <mo>]</mo> </mrow> <mfrac> <mn>1</mn> <mi>b</mi> </mfrac> </msup> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>14</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which the convolution operator <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00007" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> indicates discrete convolution.
</p>
    <p num="p-0085">In some embodiments, it is advantageous to choose a=b=2 in Eq. 14, resulting in a mask image M(x,y) given by Eq. 15.
<br/>
<i>M</i>(<i>x,y</i>)={square root over (1<i>+MF</i>(<i>x,y</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00008" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <i>F</i> <sub>refrence</sub> <sup>2</sup>(<i>x,y</i>))}{square root over (1<i>+MF</i>(<i>x,y</i>)<div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00009" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <i>F</i> <sub>refrence</sub> <sup>2</sup>(<i>x,y</i>))}Eq. 15
</p>
    <p num="p-0086">Furthermore, it is advantageous in some embodiments of the present invention to choose the masking filter MF(x,y) to have the form of Eq. 16</p>
    <p num="p-0087"> <maths id="MATH-US-00014" num="00014"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>MF</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mrow> <mi>MF</mi> <mo></mo> <mrow> <mo>(</mo> <mi>r</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mi>mgain</mi> <mo></mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo></mo> <mrow> <mi>Exp</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mo>-</mo> <msup> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mfrac> <mi>r</mi> <mi>mscale</mi> </mfrac> <mo>)</mo> </mrow> </mrow> <mn>2</mn> </msup> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>16</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which mgain and mscale are parameters. Typical choices for mgain and mscale are mgain=0.2 and mscale=0.1.
</p>
    <p num="p-0088">In some embodiments of the present invention, the difference image D(x,y) is divided by the masking image to yield a masked difference image MD(x,y) according to Eq. 17.</p>
    <p num="p-0089">
      <maths id="MATH-US-00015" num="00015">
        <math overflow="scroll">
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>MD</mi>
                    <mo></mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <mfrac>
                    <mrow>
                      <mi>D</mi>
                      <mo></mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>x</mi>
                          <mo>,</mo>
                          <mi>y</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                    <mrow>
                      <mi>M</mi>
                      <mo></mo>
                      <mrow>
                        <mo>(</mo>
                        <mrow>
                          <mi>x</mi>
                          <mo>,</mo>
                          <mi>y</mi>
                        </mrow>
                        <mo>)</mo>
                      </mrow>
                    </mrow>
                  </mfrac>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mi>Eq</mi>
                  <mo>.</mo>
                  <mstyle>
                    <mspace width="0.8em" height="0.8ex"> </mspace>
                  </mstyle>
                  <mo></mo>
                  <mn>17</mn>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </math>
      </maths>
    </p>
    <p num="p-0090">For those embodiments in which a mask image is not employed, the masked difference image is simply the difference image. Also, when a mask image is not employed, the subtract operation <b>103</b> can optionally precede the CSF <b>102</b>.</p>
    <p num="p-0091">At this boost stage, <b>106</b> in <figref idrefs="DRAWINGS">FIG. 1</figref>, the absolute value of the masked difference image is computed, raised to a power , and convolved with a window function W(x,y). The result of these operations is a function that is then raised to the power 1/ and multiplied by the factor (p<sub>x</sub>p<sub>y</sub>)<sup>1/</sup> to produce a Just Noticeable Difference Image JND(x,y) as in Eq. 18. A typical value for  is =2.408</p>
    <p num="p-0092">
      <maths id="MATH-US-00016" num="00016">
        <math overflow="scroll">
          <mtable>
            <mtr>
              <mtd>
                <mrow>
                  <mrow>
                    <mi>JND</mi>
                    <mo></mo>
                    <mrow>
                      <mo>(</mo>
                      <mrow>
                        <mi>x</mi>
                        <mo>,</mo>
                        <mi>y</mi>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>=</mo>
                  <msup>
                    <mrow>
                      <msup>
                        <mrow>
                          <mo>(</mo>
                          <mrow>
                            <msub>
                              <mi>p</mi>
                              <mi>x</mi>
                            </msub>
                            <mo></mo>
                            <msub>
                              <mi>p</mi>
                              <mi>y</mi>
                            </msub>
                          </mrow>
                          <mo>)</mo>
                        </mrow>
                        <mfrac>
                          <mn>1</mn>
                          <mi></mi>
                        </mfrac>
                      </msup>
                      <mo></mo>
                      <mrow>
                        <mo>[</mo>
                        <mrow>
                          <mrow>
                            <mi>W</mi>
                            <mo></mo>
                            <mrow>
                              <mo>(</mo>
                              <mrow>
                                <mi>x</mi>
                                <mo>,</mo>
                                <mi>y</mi>
                              </mrow>
                              <mo>)</mo>
                            </mrow>
                          </mrow>
                          <mo></mo>
                          <msup>
                            <mrow>
                              <mo></mo>
                              <mrow>
                                <mi>MD</mi>
                                <mo></mo>
                                <mrow>
                                  <mo>(</mo>
                                  <mrow>
                                    <mi>x</mi>
                                    <mo>,</mo>
                                    <mi>y</mi>
                                  </mrow>
                                  <mo>)</mo>
                                </mrow>
                              </mrow>
                              <mo></mo>
                            </mrow>
                            <mi></mi>
                          </msup>
                        </mrow>
                        <mo>]</mo>
                      </mrow>
                    </mrow>
                    <mfrac>
                      <mn>1</mn>
                      <mi></mi>
                    </mfrac>
                  </msup>
                </mrow>
              </mtd>
              <mtd>
                <mrow>
                  <mi>Eq</mi>
                  <mo>.</mo>
                  <mstyle>
                    <mspace width="0.8em" height="0.8ex"> </mspace>
                  </mstyle>
                  <mo></mo>
                  <mn>18</mn>
                </mrow>
              </mtd>
            </mtr>
          </mtable>
        </math>
      </maths>
    </p>
    <p num="p-0093">In some embodiments, it is advantageous to use a window function W(x,y) as given by Eq. 19</p>
    <p num="p-0094"> <maths id="MATH-US-00017" num="00017"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>W</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mrow> <mi>W</mi> <mo></mo> <mrow> <mo>(</mo> <mi>r</mi> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mi>Exp</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mo>-</mo> <msup> <mrow> <mi></mi> <mo></mo> <mrow> <mo>(</mo> <mfrac> <mi>r</mi> <mi>wscale</mi> </mfrac> <mo>)</mo> </mrow> </mrow> <mn>2</mn> </msup> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>19</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which wscale is a parameter, advantageously chosen to be approximately 1.013 in some embodiments.
</p>
    <p num="p-0095">It is advantageous in some embodiments of the present invention to display the complete JND(x,y) image, <b>107</b> in <figref idrefs="DRAWINGS">FIG. 1</figref>. While optional, such a display can provide a useful visual indication of the location and magnitude of visual signals. The JND(x,y) image can be thresholded (setting to zero values less than a threshold, T), reduced in size (or otherwise scaled), and/or converted to a portable format to provide a compact record of the information.</p>
    <p num="p-0096">The next stage in the process combines or pools the values of JND(x,y) of the pixels in the x and y directions to produce a single value of JND. It is convenient to use a Minkowski summation to effect this pooling with a parameter  as exponent, as given in Eq. 20.</p>
    <p num="p-0097"> <maths id="MATH-US-00018" num="00018"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mi>JND</mi> <mo>=</mo> <mrow> <msup> <mrow> <mo>(</mo> <mrow> <msub> <mi>p</mi> <mi>x</mi> </msub> <mo></mo> <msub> <mi>p</mi> <mi>y</mi> </msub> </mrow> <mo>)</mo> </mrow> <mfrac> <mn>1</mn> <mi></mi> </mfrac> </msup> <mo></mo> <msup> <mrow> <mo>(</mo> <mrow> <munderover> <mo></mo> <mi>y</mi> <msub> <mi>n</mi> <mi>y</mi> </msub> </munderover> <mo></mo> <mrow> <munderover> <mo></mo> <mi>x</mi> <msub> <mi>n</mi> <mi>x</mi> </msub> </munderover> <mo></mo> <msup> <mrow> <mo></mo> <mrow> <mi>JND</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo></mo> </mrow> <mi></mi> </msup> </mrow> </mrow> <mo>)</mo> </mrow> <mfrac> <mn>1</mn> <mi></mi> </mfrac> </msup> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>20</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
The number, JND of Eq. 20 is the desired numerical value characterizing the Spatial Standard Observer.
</p>
    <p num="p-0098">In some embodiments, it is advantageous to let , in which case Eq. 20 reduces to Eq. 21.
<br/>
<i>JND</i>=Max[<i>JND</i>(<i>x,y</i>)]Eq. 21
</p>
    <p num="p-0099">In some embodiments of the present invention, it is advantageous to apply a non-linear transformation (for example, a power function) to the JND computed from either Eq. 20 or Eq. 21. Thus, whether or not a non-linear transformation is applied to JND, and whether or not border effects are relevant for the particular image(s) under consideration, the Spatial Standard Observer, as characterized by the value of JND, provides an effective visibility metric, able to be computed relatively rapidly.</p>
    <p num="p-0100">In some applications, the target or test image (<b>201</b> in <figref idrefs="DRAWINGS">FIG. 2</figref>) may be located adjacent to a border <b>200</b> of the image region <b>202</b>, as depicted in <figref idrefs="DRAWINGS">FIG. 2</figref>. If the region of the display outside the image, <b>200</b>, is darker than the display, <b>202</b>, for example, the dark region of a Liquid Crystal Display (LCD) panel, then the visibility of the target <b>201</b> in the region will typically be reduced. An example of this situation is depicted in <figref idrefs="DRAWINGS">FIG. 2</figref>. Thus, it is advantageous in some embodiments of the present invention to use special techniques for the treatment of border areas in order to produce correct visibility estimates for such targets.</p>
    <p num="p-0101">In some embodiments of the present invention it is advantageous to multiply the contrast images by a spatial border aperture function BA(x,y) between the Contrast and CSF steps, that is, at <b>120</b> in the process flow diagram of <figref idrefs="DRAWINGS">FIG. 1</figref>. The resulting Contrast Border Aperture Function, CBA(x,y) is thus
<br/>
<i>CBA</i>(<i>x,y</i>)=<i>C</i>(<i>x,y</i>)<i>BA</i>(<i>x,y</i>)Eq. 22
<br/>
Then CBA(x,y) is used in place of C(x,y) at the CSF step, Eq. 9.
</p>
    <p num="p-0102">In some embodiments of the present invention, the border aperture function is advantageously chosen to be:</p>
    <p num="p-0103"> <maths id="MATH-US-00019" num="00019"> <math overflow="scroll"> <mtable> <mtr> <mtd> <mrow> <mrow> <mi>BA</mi> <mo></mo> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>,</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> </mrow> <mo>=</mo> <mrow> <mn>1</mn> <mo>-</mo> <mrow> <mi>bgain</mi> <mo></mo> <mstyle> <mspace width="0.3em" height="0.3ex"> </mspace> </mstyle> <mo></mo> <mrow> <mi>Exp</mi> <mo>(</mo> <mrow> <mrow> <mo>-</mo> <mi></mi> </mrow> <mo></mo> <mfrac> <msup> <mrow> <mi>Min</mi> <mo></mo> <mrow> <mo>[</mo> <mtable> <mtr> <mtd> <mtable> <mtr> <mtd> <mrow> <mrow> <mrow> <mo>(</mo> <mrow> <mi>x</mi> <mo>-</mo> <mn>1</mn> </mrow> <mo>)</mo> </mrow> <mo></mo> <msub> <mi>p</mi> <mi>x</mi> </msub> </mrow> <mo>,</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <mrow> <mo>(</mo> <mrow> <mi>y</mi> <mo>-</mo> <mn>1</mn> </mrow> <mo>)</mo> </mrow> <mo></mo> <msub> <mi>p</mi> <mi>y</mi> </msub> </mrow> <mo>,</mo> </mrow> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <mrow> <mo>(</mo> <mrow> <msub> <mi>n</mi> <mi>x</mi> </msub> <mo>-</mo> <mi>x</mi> </mrow> <mo>)</mo> </mrow> <mo></mo> <msub> <mi>p</mi> <mi>x</mi> </msub> </mrow> <mo>,</mo> </mrow> </mtd> </mtr> </mtable> </mtd> </mtr> <mtr> <mtd> <mrow> <mrow> <mo>(</mo> <mrow> <msub> <mi>n</mi> <mi>y</mi> </msub> <mo>-</mo> <mi>y</mi> </mrow> <mo>)</mo> </mrow> <mo></mo> <msub> <mi>p</mi> <mi>y</mi> </msub> </mrow> </mtd> </mtr> </mtable> <mo>]</mo> </mrow> </mrow> <mn>2</mn> </msup> <msup> <mi>bscale</mi> <mn>2</mn> </msup> </mfrac> </mrow> <mo>)</mo> </mrow> </mrow> </mrow> </mrow> </mtd> <mtd> <mrow> <mi>Eq</mi> <mo>.</mo> <mstyle> <mspace width="0.8em" height="0.8ex"> </mspace> </mstyle> <mo></mo> <mn>23</mn> </mrow> </mtd> </mtr> </mtable> </math> </maths> <br/>
in which bgain and bscale are parameters. An example of this function is given in <figref idrefs="DRAWINGS">FIG. 3</figref> in which the image is taken to have 240 columns (x-coordinate) and 180 rows (y-coordinate). Each pixel in this example is taken to be ( 1/60) degree in both height and width. The parameters are chosen in this example as bscale=0.5 degree and bgain=1.
</p>
    <p num="p-0104">The use of a border aperture function, BA(x,y) as in Eq. 23, has the advantage of simplicity, but as an approximation, it may not be as accurate as alternative methods. In other embodiments, it is advantageous for the parameters bscale and bgain to depend upon the luminance contrast between the image and the border. Typically, a margin is added to the image such that the enlarged image, image+margin, contains a portion of the border. This enlarged image is then processed as the image pursuant to the image processing techniques described herein, typically including the masking component of the processing, <b>105</b>. The presence of a portion of the border in the enlarged image will tend to produce the appropriate masking effect, tending to reduce visibility of targets or portions of targets near the border.</p>
    <p num="p-0105">There are various ways the use of an enlarged image can be implemented to treat border effects. For example, it is convenient to take the width of the border region to be Round[2*mscale/p<sub>x</sub>] and the height to be Round[2*mscale/p<sub>y</sub>], in which mscale is the masking parameter (Eq. 16). Round[ ] is a function that generates as the value of the function that integer nearest to the value of the function&#39;s argument. The dimensions of the enlarged image are then given by Eq. 24 as:
<br/>
width=<i>n</i> <sub>x</sub>+Round[2<i>*m</i>scale/<i>p</i> <sub>x</sub>]
<br/>
height=<i>n</i> <sub>y</sub>+Round[2<i>*m</i>scale/<i>p</i> <sub>y</sub>]Eq. 24
</p>
    <p num="p-0106">An advantage of treating border effects with an enlarged image is that it more correctly deals with the dependence of the border masking effect upon the luminance contrast between the border and the (original, unenlarged) image. A possible disadvantage is that this approach requires somewhat more processing to include the masking step.</p>
    <p num="p-0107">JND from Eq. 20 (or Eq. 21 for ) relates to the percentage of human observers who will notice a difference. For example, images leading to JND having a value around 1 will typically present noticeable differences to about 75% of typical human observers. Images resulting in larger JND values will present noticeable difference to a correspondingly larger percentage of typical human observers, although the precise functional relationship between JND and the percentage of viewers observing differences may not be readily known.</p>
    <p num="p-0108">It is advantageous in some embodiments of the present invention to use JND as a measure of different levels of perceptual intensity. That is, larger JND values indicate that a larger percentage of observers will notice a difference. But also larger values of JND typically indicate that a given observer will be more likely to observe more detailed differences. By way of illustration and not limitation, we consider the example of observing a scene through some form of optical instrument, such as a remote viewing device, night vision goggles, among others. A given observer may require an image value of JND<sub>1 </sub>in order to conclude that some object is present other than natural background. However a value of JND<sub>2</sub>&gt;JND<sub>1 </sub>would be required for the observer to conclude that the object is a military vehicle. And a value of JND<sub>3</sub>&gt;JND<sub>2 </sub>would be required to conclude that it is a hostile military vehicle. Thus JND values as determined by the SSO can be a useful measure of not only minimal levels of visibility but, when more stringently applied, also estimate the probable level of perceptual information obtainable from a given image.</p>
    <p num="p-0109"> <figref idrefs="DRAWINGS">FIG. 4</figref> depicts an illustrative computer system <b>250</b> that utilizes the teachings of the present invention. The computer system <b>250</b> comprises a processor <b>252</b>, a display <b>254</b>, input interfaces <b>256</b>, communications interface <b>258</b>, memory <b>260</b>, and output interfaces <b>262</b>, all conventionally coupled by one or more busses <b>264</b>. The input interfaces <b>256</b> comprise a keyboard <b>266</b>, mouse, trackball or similar device <b>268</b>, as well as mass-storage input devices such as CDs, DVDs, magnetic discs of various designs among others. The output interface <b>262</b> is a printer <b>272</b>. The communications interface <b>258</b> is a network interface card (NIC) that allows the computer <b>250</b> to communicate via a network, such as the Internet. Image acquisition/generation devices <b>274</b> provide the images <b>100</b> for the generation of the SSO and are also coupled to the processor <b>252</b>. The units <b>274</b> can supply either stored or realtime input data, or both.</p>
    <p num="p-0110">The memory <b>260</b> typically comprises different modalities, illustratively semiconductor memory, such as random access memory (RAM), and disk drives. Depending on the embodiment, the memory <b>260</b> typically includes an operating system, <b>280</b>. The operating system <b>280</b> may be implemented by any conventional operating system such as UNIX, WINDOWS, and LINUX, among others.</p>
    <p num="p-0111">Although various embodiments which incorporate the teachings of the present invention have been shown and described in detail herein, those skilled in the art can readily devise many other varied embodiments that still incorporate these teachings.</p>
    
  </div>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">29</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM57495390" lang="EN" load-source="patent-office" class="claims">
    <claim-statement>What is claimed is:</claim-statement>
    <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
      <div class="claim-text">1. A method of processing an image, the method comprising:
<div class="claim-text">producing a test image;</div>
<div class="claim-text">producing a test luminance image from the test image;</div>
<div class="claim-text">producing a reference image;</div>
<div class="claim-text">producing a reference luminance image from the reference image;</div>
<div class="claim-text">producing a local mean luminance reference image as a convolution of the reference luminance image and a luminance filter function;</div>
<div class="claim-text">producing a test contrast image in the absence of temporal filtering;</div>
<div class="claim-text">producing a reference contrast image;</div>
<div class="claim-text">producing a difference image; and</div>
<div class="claim-text">producing a just noticeable difference image as a mathematical combination of the difference image,</div>
<div class="claim-text">wherein the convolution is defined as confined convolution, which comprises:</div>
<div class="claim-text">receiving an image;</div>
<div class="claim-text">padding the image with zeros to provide a first intermediate image;</div>
<div class="claim-text">convolving the first intermediate image with a selected non-negative kernel function to obtain a second intermediate image;</div>
<div class="claim-text">cropping the second intermediate image to obtain a third intermediate image;</div>
<div class="claim-text">receiving said third intermediate image, I<b>3</b>(x,y)=PCC{K(x,y),I(x,y)}; and</div>
<div class="claim-text">forming a fourth intermediate image,</div>
<div class="claim-text">defined as I<b>4</b>(x,y)=K(x,y <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00010" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <sub>c </sub>I(x,y)=PCC{K(x,y), I(x,y)}/PCC {K(x,y)/xyK(x,y),I(x,y)}.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00002" num="00002" class="claim">
      <div class="claim-text">2. A method of spatially processing an image, the method comprising:
<div class="claim-text">spatially producing a test image with a test image dimension of n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height) having G<sub>test </sub>(x,y) which is defined to be the grayscale of the pixel at column x and row y;</div>
<div class="claim-text">spatially producing a reference image with a reference image dimension of n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height) having G<sub>reference </sub>(x,y) which is defined to be the grayscale of the pixel at column x and row y;</div>
<div class="claim-text">wherein spatially producing the test and reference images includes:</div>
<div class="claim-text">providing viewing angles subtended in each image in the x and y directions defined by s<sub>x </sub>and s<sub>y </sub>respectively, the viewing angles s<sub>x</sub>, s<sub>y </sub>can be derived from a viewing distance and an image size in a display by the equation as follows, once to compute s<sub>x </sub>and once to compute s<sub>y</sub>:
<div class="claim-text"> <br/>tan {(*size(degrees)/360}=(0.5*size)/viewing distance
</div>
</div>
<div class="claim-text">and</div>
<div class="claim-text">providing a width and height for each pixel, p<sub>x </sub>and p<sub>y </sub>as follows:</div>
</div>
      <div class="claim-text">
        <maths id="MATH-US-00020" num="00020">
          <math overflow="scroll">
            <mrow>
              <mrow>
                <msub>
                  <mi>p</mi>
                  <mi>x</mi>
                </msub>
                <mo>=</mo>
                <mfrac>
                  <msub>
                    <mi>s</mi>
                    <mi>x</mi>
                  </msub>
                  <msub>
                    <mi>n</mi>
                    <mi>x</mi>
                  </msub>
                </mfrac>
              </mrow>
              <mo>,</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"> </mspace>
              </mstyle>
              <mo></mo>
              <mrow>
                <mrow>
                  <msub>
                    <mi>p</mi>
                    <mi>y</mi>
                  </msub>
                  <mo>=</mo>
                  <mfrac>
                    <msub>
                      <mi>s</mi>
                      <mi>y</mi>
                    </msub>
                    <msub>
                      <mi>n</mi>
                      <mi>y</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>;</mo>
              </mrow>
            </mrow>
          </math>
        </maths>
        <div class="claim-text">producing a test contrast image;</div>
        <div class="claim-text">producing a reference contrast image;</div>
        <div class="claim-text">producing a difference image; and</div>
        <div class="claim-text">producing a just noticeable difference image as a mathematical combination of the difference image.</div>
      </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
      <div class="claim-text">3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein a reference luminance image is produced from the reference image and a test luminance image is produced from the test image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
      <div class="claim-text">4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein a local mean luminance reference image is produced as a convolution of the reference luminance image and a luminance filter function.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
      <div class="claim-text">5. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the test contrast image is produced by a mathematical combination of the test luminance image and the local mean luminance reference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
      <div class="claim-text">6. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the test contrast image is produced by a mathematical combination of the test luminance image, the local mean luminance reference image and a border aperture function.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
      <div class="claim-text">7. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the test contrast image is produced by a mathematical combination of a test luminance image, the local mean luminance reference image and an image of a border surrounding the reference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00008" num="00008" class="claim">
      <div class="claim-text">8. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the reference contrast image is produced by a mathematical combination of the reference luminance image and the local mean luminance reference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
      <div class="claim-text">9. The method of <claim-ref idref="CLM-00004">claim 4</claim-ref>, wherein the reference contrast image is produced by a mathematical combination of the reference luminance image, the local mean luminance reference image and a border aperture function.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
      <div class="claim-text">10. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the just noticeable difference image is produced as a mathematical combination of the difference image with a window function.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
      <div class="claim-text">11. The method of <claim-ref idref="CLM-00010">claim 10</claim-ref>, wherein the window function is convolved with the difference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00012" num="00012" class="claim">
      <div class="claim-text">12. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the difference image is produced by subtracting the reference image from the test image to produce the difference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
      <div class="claim-text">13. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein a contrast sensitivity filter is applied to the test contrast image to produce a filtered test image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
      <div class="claim-text">14. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the contrast sensitivity filter is applied to the reference contrast image to produce a filtered reference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
      <div class="claim-text">15. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the difference image is produced by subtracting the filtered reference image from the filtered test image to produce the difference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00016" num="00016" class="claim">
      <div class="claim-text">16. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the test contrast image is produced by producing a mask image as a mathematical combination of the reference image with a masking filter, and producing a difference image as a ratio of the difference image and the mask image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00017" num="00017" class="claim">
      <div class="claim-text">17. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein the test contrast image is produced by producing a mask image as a mathematical combination of the filtered reference image with a masking filter, and producing a difference image as a ratio of the difference image and the mask image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00018" num="00018" class="claim">
      <div class="claim-text">18. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein a visibility metric is produced by pooling the just noticeable difference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00019" num="00019" class="claim">
      <div class="claim-text">19. The method of <claim-ref idref="CLM-00018">claim 18</claim-ref>, wherein the process of pooling combines the values of the pixels in the x and y directions of the just noticeable difference image to produce a single just noticeable difference value.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00020" num="00020" class="claim">
      <div class="claim-text">20. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising preprocessing at least one of the test image and the reference image by downsampling.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00021" num="00021" class="claim">
      <div class="claim-text">21. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising preprocessing at least one of the test image and the reference image by convolution with a selected pre-filtering function.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00022" num="00022" class="claim">
      <div class="claim-text">22. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising preprocessing, by cropping, at least one of the test image and the reference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00023" num="00023" class="claim">
      <div class="claim-text">23. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, further comprising:
<div class="claim-text">the test image having first and second opposing sides; and</div>
<div class="claim-text">performing a convolution of the test image with a selected filter that isolates the first and second opposing sides of the test image from each other, to thereby form the reference image.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00024" num="00024" class="claim">
      <div class="claim-text">24. A method of performing confined convolution, the method comprising:
<div class="claim-text">receiving an image;</div>
<div class="claim-text">padding the image with zeros to provide a first intermediate image;</div>
<div class="claim-text">convolving the first intermediate image with a selected non-negative kernel function to obtain a second intermediate image;</div>
<div class="claim-text">cropping the second intermediate image to obtain a third intermediate image;</div>
<div class="claim-text">receiving said third intermediate image, I<b>3</b>(x,y)=PCC{K(x,y),I(x,y)}; and</div>
<div class="claim-text">forming a fourth intermediate image,</div>
<div class="claim-text">defined as I<b>4</b>(x,y)=K(x,y <div class="patent-image small-patent-image"><a href="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"><img id="CUSTOM-CHARACTER-00011" he="3.13mm" wi="2.79mm" file="US08139892-20120320-P00001.TIF" alt="Figure US08139892-20120320-P00001" img-content="character" img-format="tif" orientation="portrait" inline="no" width="11" height="13" alt="Figure US08139892-20120320-P00001" class="patent-full-image" src="https://patentimages.storage.googleapis.com/61/dd/32/365a9e58ecba51/US08139892-20120320-P00001.png"/></a></div> <sub>c </sub>I(x,y)=PCC{K(x,y), I(x,y)}/PCC {K(x,y)/xyK(x,y),I(x,y)}.</div>
</div>
    </div>
    </div> <div class="claim"> <div id="CLM-00025" num="00025" class="claim">
      <div class="claim-text">25. A method of processing a spatial image, the method comprising:
<div class="claim-text">producing a spatial test image with a test image dimension of n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height) having G<sub>test </sub>(x,y) which is defined to be the grayscale of the pixel at column x and row y;
<div class="claim-text">producing a spatial reference image from the spatial test image with a reference image dimension of n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height) having G<sub>reference </sub>(x,y) which is defined to be the grayscale of the pixel at column x and row y;</div>
<div class="claim-text">wherein spatially producing the test and reference images includes:</div>
<div class="claim-text">providing viewing angles subtended in each image in the x and y directions defined by s<sub>x </sub>and s<sub>y </sub>respectively, the viewing angles s<sub>x</sub>, s<sub>y </sub>can be derived from a viewing distance and an image size in a display by the equation as follows, once to compute s<sub>x </sub>and once to compute s<sub>y</sub>:
<div class="claim-text"> <br/>tan {(*size(degrees)/360}=(0.5*size)/viewing distance
</div>
</div>
<div class="claim-text">and</div>
<div class="claim-text">providing a width and height for each pixel, p<sub>x </sub>and p<sub>y </sub>as follows:</div>
</div>
</div>
      <div class="claim-text">
        <maths id="MATH-US-00021" num="00021">
          <math overflow="scroll">
            <mrow>
              <mrow>
                <msub>
                  <mi>p</mi>
                  <mi>x</mi>
                </msub>
                <mo>=</mo>
                <mfrac>
                  <msub>
                    <mi>s</mi>
                    <mi>x</mi>
                  </msub>
                  <msub>
                    <mi>n</mi>
                    <mi>x</mi>
                  </msub>
                </mfrac>
              </mrow>
              <mo>,</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"> </mspace>
              </mstyle>
              <mo></mo>
              <mrow>
                <mrow>
                  <msub>
                    <mi>p</mi>
                    <mi>y</mi>
                  </msub>
                  <mo>=</mo>
                  <mfrac>
                    <msub>
                      <mi>s</mi>
                      <mi>y</mi>
                    </msub>
                    <msub>
                      <mi>n</mi>
                      <mi>y</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>;</mo>
              </mrow>
            </mrow>
          </math>
        </maths>
        <div class="claim-text">producing a test contrast image;</div>
        <div class="claim-text">producing a reference contrast image;</div>
        <div class="claim-text">producing a difference image; and</div>
        <div class="claim-text">producing a just noticeable difference image as a mathematical combination of the difference image.</div>
      </div>
    </div>
    </div> <div class="claim"> <div id="CLM-00026" num="00026" class="claim">
      <div class="claim-text">26. A method of spatially processing an image, the method comprising:
<div class="claim-text">producing a spatial test image with a test image dimension of n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height) having G<sub>test </sub>(x,y) which is defined to be the grayscale of the pixel at column x and row y;
<div class="claim-text">producing a spatial reference image with a reference image dimension of n<sub>x </sub>pixels in the x direction (width) and n<sub>y </sub>pixels in the y direction (height) having G<sub>reference </sub>(x,y) which is defined to be the grayscale of the pixel at column x and row y;</div>
<div class="claim-text">wherein spatially producing the test and reference images includes:</div>
<div class="claim-text">providing viewing angles subtended in each image in the x and y directions defined by s<sub>x </sub>and s<sub>y </sub>respectively, the viewing angles s<sub>x</sub>, s<sub>y </sub>can be derived from a viewing distance and an image size in a display by the equation as follows, once to compute s<sub>x </sub>and once to compute s<sub>y</sub>:
<div class="claim-text"> <br/>tan {(size(degrees)/360}=(0.5*size)/viewing distance
</div>
</div>
<div class="claim-text">and</div>
<div class="claim-text">providing a width and height for each pixel, p<sub>x </sub>and p<sub>y </sub>as follows:</div>
</div>
</div>
      <div class="claim-text">
        <maths id="MATH-US-00022" num="00022">
          <math overflow="scroll">
            <mrow>
              <mrow>
                <msub>
                  <mi>p</mi>
                  <mi>x</mi>
                </msub>
                <mo>=</mo>
                <mfrac>
                  <msub>
                    <mi>s</mi>
                    <mi>x</mi>
                  </msub>
                  <msub>
                    <mi>n</mi>
                    <mi>x</mi>
                  </msub>
                </mfrac>
              </mrow>
              <mo>,</mo>
              <mstyle>
                <mspace width="0.3em" height="0.3ex"> </mspace>
              </mstyle>
              <mo></mo>
              <mrow>
                <mrow>
                  <msub>
                    <mi>p</mi>
                    <mi>y</mi>
                  </msub>
                  <mo>=</mo>
                  <mfrac>
                    <msub>
                      <mi>s</mi>
                      <mi>y</mi>
                    </msub>
                    <msub>
                      <mi>n</mi>
                      <mi>y</mi>
                    </msub>
                  </mfrac>
                </mrow>
                <mo>;</mo>
              </mrow>
            </mrow>
          </math>
        </maths>
        <div class="claim-text">producing a test contrast image;</div>
        <div class="claim-text">producing a reference contrast image;</div>
        <div class="claim-text">producing a difference image; and</div>
        <div class="claim-text">producing a just noticeable difference image as a mathematical combination of the difference image with a window function.</div>
      </div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00027" num="00027" class="claim">
      <div class="claim-text">27. The method of <claim-ref idref="CLM-00026">claim 26</claim-ref>, wherein the window function is convolved with the difference image.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00028" num="00028" class="claim">
      <div class="claim-text">28. The method of <claim-ref idref="CLM-00027">claim 27</claim-ref>, wherein the convolution is defined as confined convolution.</div>
    </div>
    </div> <div class="claim-dependent"> <div id="CLM-00029" num="00029" class="claim">
      <div class="claim-text">29. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the test contrast image is produced in the absence of temporal filtering.</div>
    </div>
  </div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
        <span itemprop="applicationNumber">US12/807,375</span>
        <span itemprop="priorityDate">2005-01-24</span>
        <span itemprop="filingDate">2010-08-09</span>
        <span itemprop="title">Spatial standard observer 
       </span>
        <span itemprop="ifiStatus">Active</span>
        
        <a href="/patent/US8139892B2/en">
            <span itemprop="representativePublication">US8139892B2</span>
            (<span itemprop="primaryLanguage">en</span>)
        </a>
    </section>

    <h2>Priority Applications (2)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="priorityApps" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US11/045,041</span>
                   
                   <a href="/patent/US7783130B2/en">
                        <span itemprop="representativePublication">US7783130B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2005-01-24</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr><tr itemprop="priorityApps" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US12/807,375</span>
                   
                   <a href="/patent/US8139892B2/en">
                        <span itemprop="representativePublication">US8139892B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2010-08-09</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr>
           </tbody>
       </table>

    <h2>Applications Claiming Priority (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="appsClaimingPriority" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US12/807,375</span>
                   <a href="/patent/US8139892B2/en">
                        <span itemprop="representativePublication">US8139892B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2010-08-09</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr>
           </tbody>
       </table>

    <h2>Related Parent Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Title</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="parentApps" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">US11/045,041</span>
                    <span itemprop="relationType">Continuation</span>
                    <a href="/patent/US7783130B2/en">
                        <span itemprop="representativePublication">US7783130B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>

                <td itemprop="">
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2005-01-24</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr>
           </tbody>
        </table>

    

    <h2>Publications (2)</h2>
        <table>
            <thead>
                <tr>
                    <th>Publication Number</th>
                    <th>Publication Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="pubs" itemscope repeat>
                <td>
                   <span itemprop="publicationNumber">US20100329585A1</span>
                   
                   <a href="/patent/US20100329585A1/en">US20100329585A1
                       (<span itemprop="primaryLanguage">en</span>)
                   </a>
                </td>
                <td itemprop="publicationDate">2010-12-30</td>
              </tr><tr itemprop="pubs" itemscope repeat>
                <td>
                   <span itemprop="publicationNumber">US8139892B2</span>
                   
                   <span itemprop="thisPatent">true</span>
                   <a href="/patent/US8139892B2/en">US8139892B2
                       (<span itemprop="primaryLanguage">en</span>)
                   </a>
                </td>
                <td itemprop="publicationDate">2012-03-20</td>
              </tr>
           </tbody>
        </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=36693029</h2>

    <h2>Family Applications (2)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Title</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="applications" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">US11/045,041</span>
                    <span itemprop="ifiStatus">Active</span>
                    <span itemprop="ifiExpiration">2028-03-26</span>
                    <a href="/patent/US7783130B2/en">
                        <span itemprop="representativePublication">US7783130B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                </td>
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2005-01-24</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr><tr itemprop="applications" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">US12/807,375</span>
                    <span itemprop="ifiStatus">Active</span>
                    
                    <a href="/patent/US8139892B2/en">
                        <span itemprop="representativePublication">US8139892B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                </td>
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2010-08-09</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr>
           </tbody>
        </table>

    <h2>Family Applications Before (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Title</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="beforeApplications" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">US11/045,041</span>
                    <span itemprop="ifiStatus">Active</span>
                    <span itemprop="ifiExpiration">2028-03-26</span>
                    <a href="/patent/US7783130B2/en">
                        <span itemprop="representativePublication">US7783130B2</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                </td>
                <td itemprop="priorityDate">2005-01-24</td>
                <td itemprop="filingDate">2005-01-24</td>
                <td itemprop="title">Spatial standard observer 
       </td>
              </tr>
           </tbody>
        </table>

    

    <h2>Country Status (3)</h2>
      <table>
        <thead>
          <tr>
            <th>Country</th>
            <th>Link</th>
          </tr>
        </thead>
        <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">US</span>
                (<span itemprop="num">2</span>)
              <meta itemprop="thisCountry" content="true">
            </td>
            <td>
              <a href="/patent/US7783130B2/en">
                <span itemprop="representativePublication">US7783130B2</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr><tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">TW</span>
                (<span itemprop="num">1</span>)
              
            </td>
            <td>
              <a href="/patent/TW200802134A/en">
                <span itemprop="representativePublication">TW200802134A</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr><tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">WO</span>
                (<span itemprop="num">1</span>)
              
            </td>
            <td>
              <a href="/patent/WO2006079115A2/en">
                <span itemprop="representativePublication">WO2006079115A2</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr>
      </tbody>
    </table>

    

    <h2>Families Citing this family (33)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/KR20040096472A/en">
              <span itemprop="publicationNumber">KR20040096472A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2004-09-20</td>
          <td itemprop="publicationDate">2004-11-16</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Vehicle display controlling the playback equipment 
     </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8402317B1/en">
              <span itemprop="publicationNumber">US8402317B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2005-12-22</td>
          <td itemprop="publicationDate">2013-03-19</td>
          <td><span itemprop="assigneeOriginal">The Math Works, Inc.</span></td>
          <td itemprop="title">Viewing multi-dimensional metric data from multiple test cases 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8279204B1/en">
              <span itemprop="publicationNumber">US8279204B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2005-12-22</td>
          <td itemprop="publicationDate">2012-10-02</td>
          <td><span itemprop="assigneeOriginal">The Mathworks, Inc.</span></td>
          <td itemprop="title">Viewer for multi-dimensional data from a test environment 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20080012856A1/en">
              <span itemprop="publicationNumber">US20080012856A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2006-07-14</td>
          <td itemprop="publicationDate">2008-01-17</td>
          <td><span itemprop="assigneeOriginal">Daphne Yu</span></td>
          <td itemprop="title">Perception-based quality metrics for volume rendering 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/JP4799329B2/en">
              <span itemprop="publicationNumber">JP4799329B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2006-09-07</td>
          <td itemprop="publicationDate">2011-10-26</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Unevenness inspection method, display panel manufacturing method, and unevenness inspection apparatus 
     </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/KR101213205B1/en">
              <span itemprop="publicationNumber">KR101213205B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2006-11-23</td>
          <td itemprop="publicationDate">2012-12-17</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Apparatus and method for color reproduction 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/KR101319341B1/en">
              <span itemprop="publicationNumber">KR101319341B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2008-08-26</td>
          <td itemprop="publicationDate">2013-10-16</td>
          <td><span itemprop="assigneeOriginal"> </span></td>
          <td itemprop="title">Method of generating compensation region for compensating defect of image display device 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/JP2010060638A/en">
              <span itemprop="publicationNumber">JP2010060638A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2008-09-01</td>
          <td itemprop="publicationDate">2010-03-18</td>
          <td><span itemprop="assigneeOriginal">Toshiba Corp</span></td>
          <td itemprop="title">Image display device and method 
     </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/JP5469911B2/en">
              <span itemprop="publicationNumber">JP5469911B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2009-04-22</td>
          <td itemprop="publicationDate">2014-04-16</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Transmitting apparatus and stereoscopic image data transmitting method 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8559511B2/en">
              <span itemprop="publicationNumber">US8559511B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2010-03-30</td>
          <td itemprop="publicationDate">2013-10-15</td>
          <td><span itemprop="assigneeOriginal">Hong Kong Applied Science and Technology Research Institute Company Limited</span></td>
          <td itemprop="title">Method and apparatus for video coding by ABT-based just noticeable difference model 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US8675922B1/en">
              <span itemprop="publicationNumber">US8675922B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2011-05-24</td>
          <td itemprop="publicationDate">2014-03-18</td>
          <td><span itemprop="assigneeOriginal">The United States of America as represented by the Administrator of the National Aeronautics &amp; Space Administration (NASA)</span></td>
          <td itemprop="title">Visible motion blur 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9396509B1/en">
              <span itemprop="publicationNumber">US9396509B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2011-10-30</td>
          <td itemprop="publicationDate">2016-07-19</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Closed form non-iterative watermark embedding 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9380186B2/en">
              <span itemprop="publicationNumber">US9380186B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2012-08-24</td>
          <td itemprop="publicationDate">2016-06-28</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Data hiding for spot colors in product packaging 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9667829B2/en">
              <span itemprop="publicationNumber">US9667829B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2014-08-12</td>
          <td itemprop="publicationDate">2017-05-30</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">System and methods for encoding information for printed articles 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9449357B1/en">
              <span itemprop="publicationNumber">US9449357B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2012-08-24</td>
          <td itemprop="publicationDate">2016-09-20</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Geometric enumerated watermark embedding for spot colors 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN102881010B/en">
              <span itemprop="publicationNumber">CN102881010B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2012-08-28</td>
          <td itemprop="publicationDate">2015-03-11</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Method for evaluating perception sharpness of fused image based on human visual characteristics 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20140254897A1/en">
              <span itemprop="publicationNumber">US20140254897A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2013-03-06</td>
          <td itemprop="publicationDate">2014-09-11</td>
          <td><span itemprop="assigneeOriginal">Tektronix, Inc.</span></td>
          <td itemprop="title">Design verification and diagnostics for image devices 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20140327737A1/en">
              <span itemprop="publicationNumber">US20140327737A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2013-05-01</td>
          <td itemprop="publicationDate">2014-11-06</td>
          <td><span itemprop="assigneeOriginal">Raymond John Westwater</span></td>
          <td itemprop="title">Method and Apparatus to Perform Optimal Visually-Weighed Quantization of Time-Varying Visual Sequences in Transform Space 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN103325084B/en">
              <span itemprop="publicationNumber">CN103325084B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2013-06-27</td>
          <td itemprop="publicationDate">2016-03-16</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">  Based on just noticeable distortion combined stereoscopic image fragile watermarking method  </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9565335B2/en">
              <span itemprop="publicationNumber">US9565335B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2014-01-02</td>
          <td itemprop="publicationDate">2017-02-07</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Full color visibility model using CSF which varies spatially with local luminance 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9401001B2/en">
              <span itemprop="publicationNumber">US9401001B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2014-01-02</td>
          <td itemprop="publicationDate">2016-07-26</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Full-color visibility model using CSF which varies spatially with local luminance 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN103955689A/en">
              <span itemprop="publicationNumber">CN103955689A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-04-14</td>
          <td itemprop="publicationDate">2014-07-30</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">Image vision area-of-interest extraction method through frequency screening 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/EP3195164A4/en">
              <span itemprop="publicationNumber">EP3195164A4</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2014-07-28</td>
          <td itemprop="publicationDate">2018-04-11</td>
          <td><span itemprop="assigneeOriginal">National Ict Australia Pty Ltd</span></td>
          <td itemprop="title">Determination of parameter values for sensory substitution devices 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9747656B2/en">
              <span itemprop="publicationNumber">US9747656B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-01-22</td>
          <td itemprop="publicationDate">2017-08-29</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Differential modulation for robust signaling and synchronization 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/CN104657996B/en">
              <span itemprop="publicationNumber">CN104657996B</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2015-02-26</td>
          <td itemprop="publicationDate">2018-01-19</td>
          <td><span itemprop="assigneeOriginal"></span></td>
          <td itemprop="title">The image quality evaluating method of Laplce&#39;s gaussian signal based on non-linear normalizing 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9892478B2/en">
              <span itemprop="publicationNumber">US9892478B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-03-06</td>
          <td itemprop="publicationDate">2018-02-13</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Digital watermarking applications 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US9635378B2/en">
              <span itemprop="publicationNumber">US9635378B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-03-20</td>
          <td itemprop="publicationDate">2017-04-25</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Sparse modulation for robust signaling and synchronization 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2016153936A1/en">
              <span itemprop="publicationNumber">WO2016153936A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-03-20</td>
          <td itemprop="publicationDate">2016-09-29</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Digital watermarking and data hiding with narrow-band absorption materials 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US10424038B2/en">
              <span itemprop="publicationNumber">US10424038B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2015-03-20</td>
          <td itemprop="publicationDate">2019-09-24</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Signal encoding outside of guard band region surrounding text characters, including varying encoding strength 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US10304149B2/en">
              <span itemprop="publicationNumber">US10304149B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-08-15</td>
          <td itemprop="publicationDate">2019-05-28</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Signal encoding for difficult environments 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US10255649B2/en">
              <span itemprop="publicationNumber">US10255649B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-08-15</td>
          <td itemprop="publicationDate">2019-04-09</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Signal encoding for difficult environments 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US10445849B1/en">
              <span itemprop="publicationNumber">US10445849B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2016-08-15</td>
          <td itemprop="publicationDate">2019-10-15</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Signal encoding based on spectral requirements 
       </td>
        </tr><tr itemprop="forwardReferencesFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2018165667A1/en">
              <span itemprop="publicationNumber">WO2018165667A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2017-03-10</td>
          <td itemprop="publicationDate">2018-09-13</td>
          <td><span itemprop="assigneeOriginal">Digimarc Corporation</span></td>
          <td itemprop="title">Predicting detectability and grading prior to printing 
       </td>
        </tr>
      </tbody>
    </table>

    <h2>Citations (13)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5694491A/en">
              <span itemprop="publicationNumber">US5694491A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1996-03-29</td>
          <td itemprop="publicationDate">1997-12-02</td>
          <td><span itemprop="assigneeOriginal">David Sarnoff Research Center, Inc.</span></td>
          <td itemprop="title">Methods and apparatus for assessing the visibility of differences between two image sequences 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5719966A/en">
              <span itemprop="publicationNumber">US5719966A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1996-03-29</td>
          <td itemprop="publicationDate">1998-02-17</td>
          <td><span itemprop="assigneeOriginal">David Sarnoff Research Center, Inc.</span></td>
          <td itemprop="title">Apparatus for assessing the visiblity of differences between two image sequences 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5781665A/en">
              <span itemprop="publicationNumber">US5781665A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1995-08-28</td>
          <td itemprop="publicationDate">1998-07-14</td>
          <td><span itemprop="assigneeOriginal">Pitney Bowes Inc.</span></td>
          <td itemprop="title">Apparatus and method for cropping an image 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5974159A/en">
              <span itemprop="publicationNumber">US5974159A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1996-03-29</td>
          <td itemprop="publicationDate">1999-10-26</td>
          <td><span itemprop="assigneeOriginal">Sarnoff Corporation</span></td>
          <td itemprop="title">Method and apparatus for assessing the visibility of differences between two image sequences 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6148117A/en">
              <span itemprop="publicationNumber">US6148117A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1996-12-27</td>
          <td itemprop="publicationDate">2000-11-14</td>
          <td><span itemprop="assigneeOriginal">Hewlett-Packard Company</span></td>
          <td itemprop="title">Image processing system with alterable local convolution kernel 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2002006851A1/en">
              <span itemprop="publicationNumber">WO2002006851A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2000-07-15</td>
          <td itemprop="publicationDate">2002-01-24</td>
          <td><span itemprop="assigneeOriginal">Robert Bosch Gmbh</span></td>
          <td itemprop="title">Method for determining visibility 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20020031277A1/en">
              <span itemprop="publicationNumber">US20020031277A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1997-04-04</td>
          <td itemprop="publicationDate">2002-03-14</td>
          <td><span itemprop="assigneeOriginal">Jeffrey Lubin</span></td>
          <td itemprop="title">Method and apparatus for assessing the visibility of differences between two signal sequences 
     </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20020145757A1/en">
              <span itemprop="publicationNumber">US20020145757A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2001-02-13</td>
          <td itemprop="publicationDate">2002-10-10</td>
          <td><span itemprop="assigneeOriginal">Eastman Kodak Company</span></td>
          <td itemprop="title">Image specific perceived overall contrast predition 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20020150304A1/en">
              <span itemprop="publicationNumber">US20020150304A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2001-04-12</td>
          <td itemprop="publicationDate">2002-10-17</td>
          <td><span itemprop="assigneeOriginal">Norman Ockman</span></td>
          <td itemprop="title">System for morphological image fusion and change detection 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20030197867A1/en">
              <span itemprop="publicationNumber">US20030197867A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1999-03-12</td>
          <td itemprop="publicationDate">2003-10-23</td>
          <td><span itemprop="assigneeOriginal">Kwon Taek Mu</span></td>
          <td itemprop="title">Video camera-based visibility measurement system 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6799515B2/en">
              <span itemprop="publicationNumber">US6799515B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2002-03-11</td>
          <td itemprop="publicationDate">2004-10-05</td>
          <td><span itemprop="assigneeOriginal">Jerry K Lynn</span></td>
          <td itemprop="title">Luminous double faced picture display 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2004086751A2/en">
              <span itemprop="publicationNumber">WO2004086751A2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2003-03-27</td>
          <td itemprop="publicationDate">2004-10-07</td>
          <td><span itemprop="assigneeOriginal">Sergei Startchik</span></td>
          <td itemprop="title">Method for estimating logo visibility and exposure in video 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6977664B1/en">
              <span itemprop="publicationNumber">US6977664B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1999-09-24</td>
          <td itemprop="publicationDate">2005-12-20</td>
          <td><span itemprop="assigneeOriginal">Nippon Telegraph And Telephone Corporation</span></td>
          <td itemprop="title">Method for separating background sprite and foreground object and method for extracting segmentation mask and the apparatus 
       </td>
        </tr>
      </tbody>
    </table>

    

    
    <ul>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2005</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2005-01-24</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US11/045,041</span>
            <a href="/patent/US7783130B2/en"><span itemprop="documentId">patent/US7783130B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
          </li>
          
        </ul>
      </li>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2006</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2006-01-24</span>
            <span itemprop="countryCode">WO</span>
            <span itemprop="applicationNumber">PCT/US2006/002662</span>
            <a href="/patent/WO2006079115A2/en"><span itemprop="documentId">patent/WO2006079115A2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Application Filing</span>
            
          </li>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2006-06-07</span>
            <span itemprop="countryCode">TW</span>
            <span itemprop="applicationNumber">TW95120184A</span>
            <a href="/patent/TW200802134A/en"><span itemprop="documentId">patent/TW200802134A/en</span></a>
            <span itemprop="legalStatusCat">unknown</span>
            <span itemprop="legalStatus"></span>
            
          </li>
          
        </ul>
      </li>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2010</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2010-08-09</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US12/807,375</span>
            <a href="/patent/US8139892B2/en"><span itemprop="documentId">patent/US8139892B2/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
            <span itemprop="thisApp" content="true" bool></span>
            
          </li>
          
        </ul>
      </li>
      
    </ul>
    

    </section>

  <section>
    <h2>Patent Citations (13)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5781665A/en">
              <span itemprop="publicationNumber">US5781665A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1995-08-28</td>
          <td itemprop="publicationDate">1998-07-14</td>
          <td><span itemprop="assigneeOriginal">Pitney Bowes Inc.</span></td>
          <td itemprop="title">Apparatus and method for cropping an image 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5694491A/en">
              <span itemprop="publicationNumber">US5694491A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1996-03-29</td>
          <td itemprop="publicationDate">1997-12-02</td>
          <td><span itemprop="assigneeOriginal">David Sarnoff Research Center, Inc.</span></td>
          <td itemprop="title">Methods and apparatus for assessing the visibility of differences between two image sequences 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5719966A/en">
              <span itemprop="publicationNumber">US5719966A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1996-03-29</td>
          <td itemprop="publicationDate">1998-02-17</td>
          <td><span itemprop="assigneeOriginal">David Sarnoff Research Center, Inc.</span></td>
          <td itemprop="title">Apparatus for assessing the visiblity of differences between two image sequences 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5974159A/en">
              <span itemprop="publicationNumber">US5974159A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1996-03-29</td>
          <td itemprop="publicationDate">1999-10-26</td>
          <td><span itemprop="assigneeOriginal">Sarnoff Corporation</span></td>
          <td itemprop="title">Method and apparatus for assessing the visibility of differences between two image sequences 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6148117A/en">
              <span itemprop="publicationNumber">US6148117A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1996-12-27</td>
          <td itemprop="publicationDate">2000-11-14</td>
          <td><span itemprop="assigneeOriginal">Hewlett-Packard Company</span></td>
          <td itemprop="title">Image processing system with alterable local convolution kernel 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20020031277A1/en">
              <span itemprop="publicationNumber">US20020031277A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1997-04-04</td>
          <td itemprop="publicationDate">2002-03-14</td>
          <td><span itemprop="assigneeOriginal">Jeffrey Lubin</span></td>
          <td itemprop="title">Method and apparatus for assessing the visibility of differences between two signal sequences 
     </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20030197867A1/en">
              <span itemprop="publicationNumber">US20030197867A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1999-03-12</td>
          <td itemprop="publicationDate">2003-10-23</td>
          <td><span itemprop="assigneeOriginal">Kwon Taek Mu</span></td>
          <td itemprop="title">Video camera-based visibility measurement system 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6977664B1/en">
              <span itemprop="publicationNumber">US6977664B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">1999-09-24</td>
          <td itemprop="publicationDate">2005-12-20</td>
          <td><span itemprop="assigneeOriginal">Nippon Telegraph And Telephone Corporation</span></td>
          <td itemprop="title">Method for separating background sprite and foreground object and method for extracting segmentation mask and the apparatus 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2002006851A1/en">
              <span itemprop="publicationNumber">WO2002006851A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2000-07-15</td>
          <td itemprop="publicationDate">2002-01-24</td>
          <td><span itemprop="assigneeOriginal">Robert Bosch Gmbh</span></td>
          <td itemprop="title">Method for determining visibility 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20020145757A1/en">
              <span itemprop="publicationNumber">US20020145757A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2001-02-13</td>
          <td itemprop="publicationDate">2002-10-10</td>
          <td><span itemprop="assigneeOriginal">Eastman Kodak Company</span></td>
          <td itemprop="title">Image specific perceived overall contrast predition 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20020150304A1/en">
              <span itemprop="publicationNumber">US20020150304A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">2001-04-12</td>
          <td itemprop="publicationDate">2002-10-17</td>
          <td><span itemprop="assigneeOriginal">Norman Ockman</span></td>
          <td itemprop="title">System for morphological image fusion and change detection 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6799515B2/en">
              <span itemprop="publicationNumber">US6799515B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2002-03-11</td>
          <td itemprop="publicationDate">2004-10-05</td>
          <td><span itemprop="assigneeOriginal">Jerry K Lynn</span></td>
          <td itemprop="title">Luminous double faced picture display 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2004086751A2/en">
              <span itemprop="publicationNumber">WO2004086751A2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            
            
          </td>
          <td itemprop="priorityDate">2003-03-27</td>
          <td itemprop="publicationDate">2004-10-07</td>
          <td><span itemprop="assigneeOriginal">Sergei Startchik</span></td>
          <td itemprop="title">Method for estimating logo visibility and exposure in video 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Non-Patent Citations (9)</h2>
    <table>
      <caption>* Cited by examiner,  Cited by third party</caption>
      <thead>
        <tr>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Ahumada, Computational Image Quality Metrics: A Review, Society for Information Display International Symposium Digest of Technical Papers 24, 1993, 305-308.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Barten, The SQRI Method: A New Method for the Evaluation of Visible Resolution on a Display, Proceedings of the SID, 1987, 253-262, 28-3.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Chen, et al., Detection of Chromoluminance Patterns on Chromoluminance Pedestals I: Threshold Measurements, Vision Research 40, 2000. 773-778.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Chen, et al., Detection of Chromoluminance Patterns on Chromoluminance Pedestals II: Model, Vision Research 40, 2000, 789-803.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Lubin, A Human Vision System Model for Objective Picture Quality Measurements, International Broadcasting Convention, Sep. 12-16, 1997, 498-503, Conference publication No. 447.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Rohaly, et al., A Comparison of Image Quality Models and Metrics Predicting Object Detection, Society for Information display International Symposium Digest of Technical Papers 26, 1995, 45-48.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Watson, et al., A Standard Observer for Spatial Vision, Investigative Ophthalmology and Visual Science, 2000, S713, 41-4.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Watson, et al., Video Quality Measures Based on the Standard Spatial Observer, 2002 IEEE International Conference on Image Processing, Sep. 25, 2002, WA-L2.2.</span>
            
            
          </td>
        </tr><tr itemprop="detailedNonPatentLiterature" itemscope repeat>
          <td>
            <span itemprop="title">Watson, Visual Detection of Spatial Contrast Patterns: Evaluation of Five Simple Models, Optics Express, Jan. 3, 2000, 12-33, 6-1.</span>
            
            
          </td>
        </tr>
      </tbody>
    </table>
  </section>

  

  <section>
    <h2>Also Published As</h2>
    <table>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Publication date</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/TW200802134A/en">
              <span itemprop="publicationNumber">TW200802134A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2008-01-01</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US7783130B2/en">
              <span itemprop="publicationNumber">US7783130B2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2010-08-24</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2006079115A3/en">
              <span itemprop="publicationNumber">WO2006079115A3</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2009-05-07</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/WO2006079115A2/en">
              <span itemprop="publicationNumber">WO2006079115A2</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2006-07-27</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20060165311A1/en">
              <span itemprop="publicationNumber">US20060165311A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2006-07-27</td>
        </tr><tr itemprop="docdbFamily" itemscope repeat>
          <td>
            
            
            <a href="/patent/US20100329585A1/en">
              <span itemprop="publicationNumber">US20100329585A1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
          </td>
          <td itemprop="publicationDate">2010-12-30</td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="16290327230572813608">
              <a href="/scholar/16290327230572813608"><span itemprop="scholarAuthors">Aydin et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2008">2008</time>
            
          </td>
          <td itemprop="title">Dynamic range independent image quality assessment</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="2529501619102397765">
              <a href="/scholar/2529501619102397765"><span itemprop="scholarAuthors">Young et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="1998">1998</time>
            
          </td>
          <td itemprop="title">Fundamentals of image processing</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US7715657B2/en">
                <span itemprop="publicationNumber">US7715657B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2010-05-11">2010-05-11</time>
            
            
          </td>
          <td itemprop="title">Method, device and program for detecting perceptual features of a larger image and incorporating information of the detected perceptual features into a smaller preview image 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6771833B1/en">
                <span itemprop="publicationNumber">US6771833B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2004-08-03">2004-08-03</time>
            
            
          </td>
          <td itemprop="title">Method and system for enhancing digital images 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US8396315B2/en">
                <span itemprop="publicationNumber">US8396315B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2013-03-12">2013-03-12</time>
            
            
          </td>
          <td itemprop="title">Method for improving digital images and an image sensor for sensing the same 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US8224085B2/en">
                <span itemprop="publicationNumber">US8224085B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2012-07-17">2012-07-17</time>
            
            
          </td>
          <td itemprop="title">Noise reduced color image using panchromatic image 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/JP4571987B2/en">
                <span itemprop="publicationNumber">JP4571987B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2010-10-27">2010-10-27</time>
            
            
          </td>
          <td itemprop="title">System and method for detecting features from an image of a vehicle 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6650789B2/en">
                <span itemprop="publicationNumber">US6650789B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2003-11-18">2003-11-18</time>
            
            
          </td>
          <td itemprop="title">Method and system for altering defects in a digital image 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="11947670697659428157">
              <a href="/scholar/11947670697659428157"><span itemprop="scholarAuthors">Comer et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="1999">1999</time>
            
          </td>
          <td itemprop="title">Morphological operations for color image processing</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6233060B1/en">
                <span itemprop="publicationNumber">US6233060B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2001-05-15">2001-05-15</time>
            
            
          </td>
          <td itemprop="title">Reduction of moir in screened images using hierarchical edge detection and adaptive-length averaging filters 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="14462210176242632897">
              <a href="/scholar/14462210176242632897"><span itemprop="scholarAuthors">Umbaugh</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2005">2005</time>
            
          </td>
          <td itemprop="title">Computer imaging: digital image analysis and processing</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US7529425B2/en">
                <span itemprop="publicationNumber">US7529425B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2009-05-05">2009-05-05</time>
            
            
          </td>
          <td itemprop="title">Denoising method, apparatus, and program 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP0723364B1/en">
                <span itemprop="publicationNumber">EP0723364B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2000-04-19">2000-04-19</time>
            
            
          </td>
          <td itemprop="title">Real-time image enhancement techniques 
     </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP0747855B1/en">
                <span itemprop="publicationNumber">EP0747855B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2002-04-03">2002-04-03</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for enhancing a digital image 
     </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="16615551901881336410">
              <a href="/scholar/16615551901881336410"><span itemprop="scholarAuthors">Janssen</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2001">2001</time>
            
          </td>
          <td itemprop="title">Computational image quality</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP0971314A2/en">
                <span itemprop="publicationNumber">EP0971314A2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2000-01-12">2000-01-12</time>
            
            
          </td>
          <td itemprop="title">A method for preserving image detail when adjusting the contrast of a digital image 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20040136603A1/en">
                <span itemprop="publicationNumber">US20040136603A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2004-07-15">2004-07-15</time>
            
            
          </td>
          <td itemprop="title">Enhanced wide dynamic range in imaging 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6842543B2/en">
                <span itemprop="publicationNumber">US6842543B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2005-01-11">2005-01-11</time>
            
            
          </td>
          <td itemprop="title">Method of improving a digital image having white zones 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/JP4870779B2/en">
                <span itemprop="publicationNumber">JP4870779B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2012-02-08">2012-02-08</time>
            
            
          </td>
          <td itemprop="title">Digital image exposure and tone scale adjustment 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="8134019445425621157">
              <a href="/scholar/8134019445425621157"><span itemprop="scholarAuthors">Carasso</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2001">2001</time>
            
          </td>
          <td itemprop="title">Direct blind deconvolution</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="12018297964648747340">
              <a href="/scholar/12018297964648747340"><span itemprop="scholarAuthors">Nill et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="1992">1992</time>
            
          </td>
          <td itemprop="title">Objective image quality measure derived from digital image power spectra</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="2810118220133862283">
              <a href="/scholar/2810118220133862283"><span itemprop="scholarAuthors">Rangayyan et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="1998">1998</time>
            
          </td>
          <td itemprop="title">Adaptive-neighborhood filtering of images corrupted by signal-dependent noise</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6424730B1/en">
                <span itemprop="publicationNumber">US6424730B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2002-07-23">2002-07-23</time>
            
            
          </td>
          <td itemprop="title">Medical image enhancement method for hardcopy prints 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="18185348993008020432">
              <a href="/scholar/18185348993008020432"><span itemprop="scholarAuthors">Strickland et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="1987">1987</time>
            
          </td>
          <td itemprop="title">Digital color image enhancement based on the saturation component</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6421468B1/en">
                <span itemprop="publicationNumber">US6421468B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2002-07-16">2002-07-16</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for sharpening an image by scaling elements of a frequency-domain representation 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2012-02-29">2012-02-29</time></td>
          <td itemprop="code">STCF</td>
          <td itemprop="title">Information on status: patent grant</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PATENTED CASE</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2015-08-13">2015-08-13</time></td>
          <td itemprop="code">FPAY</td>
          <td itemprop="title">Fee payment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Year of fee payment</strong>:
              <span itemprop="value">4</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>
</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script async="" defer="" src="//www.google.com/insights/consumersurveys/async_survey?site=cxkjf7ipxgbnnjy6k35ezcvbbe"></script>
  </body>
</html>
