<!doctype html>
<html lang="en">
  <head>
    <title>US7595841B1 - Video image stabilization and registration—plus 
        - Google Patents</title>

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <meta name="referrer" content="origin-when-crossorigin">
    <link rel="canonical" href="https://patents.google.com/patent/US7595841B1/en">
    <meta name="description" content="
     A method of stabilizing a video image displayed in multiple video fields of a video sequence includes the steps of: subdividing a selected area of a first video field into nested pixel blocks; determining horizontal and vertical translation of each of the pixel blocks in each of the pixel block subdivision levels from the first video field to a second video field; and determining translation of the image from the first video field to the second video field by determining a change in magnification of the image from the first video field to the second video field in each of horizontal and vertical directions, and determining shear of the image from the first video field to the second video field in each of the horizontal and vertical directions. 
   
   ">
    
    <meta name="DC.type" content="patent">
    
    <meta name="DC.title" content="Video image stabilization and registration—plus 
       ">
    
    <meta name="DC.date" content="2005-07-01" scheme="dateSubmitted">
    
    <meta name="DC.description" content="
     A method of stabilizing a video image displayed in multiple video fields of a video sequence includes the steps of: subdividing a selected area of a first video field into nested pixel blocks; determining horizontal and vertical translation of each of the pixel blocks in each of the pixel block subdivision levels from the first video field to a second video field; and determining translation of the image from the first video field to the second video field by determining a change in magnification of the image from the first video field to the second video field in each of horizontal and vertical directions, and determining shear of the image from the first video field to the second video field in each of the horizontal and vertical directions. 
   
   ">
    
    <meta name="citation_patent_application_number" content="US:11/174,210">
    
    <meta name="citation_pdf_url" content="https://patentimages.storage.googleapis.com/d1/89/5c/f53d0942cdc33b/US7595841.pdf">
    
    <meta name="citation_patent_number" content="US:7595841">
    
    <meta name="DC.date" content="2009-09-29" scheme="issue">
    
    <meta name="DC.contributor" content="David H. Hathaway" scheme="inventor">
    
    <meta name="DC.contributor" content="National Aeronautics and Space Administration (NASA)" scheme="assignee">
    
    <meta name="DC.relation" content="US:5107293" scheme="references">
    
    <meta name="DC.relation" content="US:6459822" scheme="references">
    
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,400italic,500,500italic,700">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Product+Sans">
    <style>
      body { transition: none; }
    </style>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-27188110-4', 'auto');

      version = 'patent-search.search_20191120_RC00';

      function sendFeedback() {
        userfeedback.api.startFeedback({
          'productId': '713680',
          'bucket': 'patent-search-web',
          'productVersion': version,
        });
      }

      window.experiments = {};
      window.experiments.patentCountries = "ae,ag,al,am,ao,ap,ar,at,au,aw,az,ba,bb,bd,be,bf,bg,bh,bj,bn,bo,br,bw,bx,by,bz,ca,cf,cg,ch,ci,cl,cm,cn,co,cr,cs,cu,cy,cz,dd,de,dj,dk,dm,do,dz,ea,ec,ee,eg,em,ep,es,fi,fr,ga,gb,gc,gd,ge,gh,gm,gn,gq,gr,gt,gw,hk,hn,hr,hu,ib,id,ie,il,in,ir,is,it,jo,jp,ke,kg,kh,km,kn,kp,kr,kw,kz,la,lc,li,lk,lr,ls,lt,lu,lv,ly,ma,mc,md,me,mg,mk,ml,mn,mo,mr,mt,mw,mx,my,mz,na,ne,ng,ni,nl,no,nz,oa,om,pa,pe,pg,ph,pl,pt,py,qa,ro,rs,ru,rw,sa,sc,sd,se,sg,si,sk,sl,sm,sn,st,su,sv,sy,sz,td,tg,th,tj,tm,tn,tr,tt,tw,tz,ua,ug,us,uy,uz,vc,ve,vn,wo,yu,za,zm,zw";
      
      
      window.profilePicture = "";

      window.Polymer = {
        dom: 'shady',
        lazyRegister: true,
      };
    </script>

    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/webcomponentsjs/webcomponents-lite.min.js"></script>
    
    <link rel="import" href="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.html">
    
  </head>
  <body unresolved>
    
    <script src="//www.gstatic.com/patent-search/frontend/patent-search.search_20191120_RC00/scs/compiled_dir/search-app-vulcanized.js"></script>
    
    <search-app>
      
      

      <article class="result" itemscope itemtype="http://schema.org/ScholarlyArticle">
  <h1 itemprop="pageTitle">US7595841B1 - Video image stabilization and registration—plus 
        - Google Patents</h1>
  <span itemprop="title">Video image stabilization and registration—plus 
       </span>

  <meta itemprop="type" content="patent">
  <a href="https://patentimages.storage.googleapis.com/d1/89/5c/f53d0942cdc33b/US7595841.pdf" itemprop="pdfLink">Download PDF</a>
  <h2>Info</h2>

  <dl>
    <dt>Publication number</dt>
    <dd itemprop="publicationNumber">US7595841B1</dd>
    <meta itemprop="numberWithoutCodes" content="7595841">
    <meta itemprop="kindCode" content="B1">
    <meta itemprop="publicationDescription" content="Patent ( no pre-grant publication)">
    
    <span>US7595841B1</span>
    
    <span>US11/174,210</span>
    
    <span>US17421005A</span>
    
    <span>US7595841B1</span>
    
    <span>US 7595841 B1</span>
    
    <span>US7595841 B1</span>
    
    <span>US 7595841B1</span>
    
    <span>  </span>
    
    <span> </span>
    
    <span> </span>
    
    <span>US 17421005 A</span>
    
    <span>US17421005 A</span>
    
    <span>US 17421005A</span>
    
    <span>US 7595841 B1</span>
    
    <span>US7595841 B1</span>
    
    <span>US 7595841B1</span>
    

    <dt>Authority</dt>
    <dd itemprop="countryCode">US</dd>
    <dd itemprop="countryName">United States</dd>

    <dt>Prior art keywords</dt>
    
    <dd itemprop="priorArtKeywords" repeat>horizontal</dd>
    <dd itemprop="priorArtKeywords" repeat>pixel block</dd>
    <dd itemprop="priorArtKeywords" repeat>vertical</dd>
    <dd itemprop="priorArtKeywords" repeat>pixel</dd>
    <dd itemprop="priorArtKeywords" repeat>video</dd>

    <dt>Prior art date</dt>
    <dd><time itemprop="priorArtDate" datetime="2005-07-01">2005-07-01</time></dd>

    <dt>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</dt>
    <dd itemprop="legalStatusIfi" itemscope>
      <span itemprop="status">Active</span>, expires <time itemprop="expiration" datetime="2027-12-03">2027-12-03</time>
    </dd>
  </dl>

  <dt>Application number</dt>
  <dd itemprop="applicationNumber">US11/174,210</dd>

  

  

  <dt>Inventor</dt>
  <dd itemprop="inventor" repeat>David H. Hathaway</dd>
  <dt>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</dt>
  <dd itemprop="assigneeCurrent" repeat>
    National Aeronautics and Space Administration (NASA)
  </dd>

  <dt>Original Assignee</dt>
  <dd itemprop="assigneeOriginal" repeat>National Aeronautics and Space Administration (NASA)</dd>

  <dt>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</dt>
  <dd><time itemprop="priorityDate" datetime="2005-07-01">2005-07-01</time></dd>

  <dt>Filing date</dt>
  <dd><time itemprop="filingDate" datetime="2005-07-01">2005-07-01</time></dd>

  <dt>Publication date</dt>
  <dd><time itemprop="publicationDate" datetime="2009-09-29">2009-09-29</time></dd>

  

  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2005-07-01">2005-07-01</time>
    <span itemprop="title">Application filed by National Aeronautics and Space Administration (NASA)</span>
    <span itemprop="type">filed</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    <span itemprop="assigneeSearch">National Aeronautics and Space Administration (NASA)</span>
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2005-07-01">2005-07-01</time>
    <span itemprop="title">Priority to US11/174,210</span>
    <span itemprop="type">priority</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US7595841B1/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2005-07-01">2005-07-01</time>
    <span itemprop="title">Assigned to UNITED STATES OF AMERICA AS REPRESENTED BY THE NATIONAL AERONAUTICS AND SPACE ADMINISTRATION</span>
    <span itemprop="type">reassignment</span>
    
    
    
    
    <span itemprop="assigneeSearch">UNITED STATES OF AMERICA AS REPRESENTED BY THE NATIONAL AERONAUTICS AND SPACE ADMINISTRATION</span>
    
    
    <span itemprop="description" repeat>ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS).</span>
    
    <span itemprop="description" repeat>Assignors: HATHAWAY, DAVID H.</span>
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2009-09-29">2009-09-29</time>
    <span itemprop="title">Application granted</span>
    <span itemprop="type">granted</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2009-09-29">2009-09-29</time>
    <span itemprop="title">Publication of US7595841B1</span>
    <span itemprop="type">publication</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    <span itemprop="documentId">patent/US7595841B1/en</span>
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2019-11-25">2019-11-25</time>
    <span itemprop="title">Application status is Active</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  
  <dd itemprop="events" itemscope repeat>
    <time itemprop="date" datetime="2027-12-03">2027-12-03</time>
    <span itemprop="title">Adjusted expiration</span>
    <span itemprop="type">legal-status</span>
    
    <span itemprop="critical" content="true" bool>Critical</span>
    
    
    
    
    
  </dd>
  

  <h2>Links</h2>

  <ul>
    
          <li itemprop="links" itemscope repeat>
            <meta itemprop="id" content="usptoLink">
            <a href="http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO1&Sect2=HITOFF&p=1&u=/netahtml/PTO/srchnum.html&r=1&f=G&l=50&d=PALL&s1=7595841.PN." itemprop="url" target="_blank"><span itemprop="text">USPTO</span></a>
          </li>
        <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="usptoAssignmentLink">
          <a href="https://assignment.uspto.gov/patent/index.html#/patent/search/resultFilter?searchInput=7595841" itemprop="url" target="_blank"><span itemprop="text">USPTO Assignment</span></a>
        </li>

    <li itemprop="links" itemscope repeat>
        <meta itemprop="id" content="espacenetLink">
        <a href="http://worldwide.espacenet.com/publicationDetails/biblio?CC=US&amp;NR=7595841B1&amp;KC=B1&amp;FT=D" itemprop="url" target="_blank"><span itemprop="text">Espacenet</span></a>
      </li>
      

    

    
      <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="globalDossierLink">
          <a href="http://globaldossier.uspto.gov/#/result/patent/US/7595841/1" itemprop="url" target="_blank"><span itemprop="text">Global Dossier</span></a>
        </li>
      

      

      

      

      <li itemprop="links" itemscope repeat>
          <meta itemprop="id" content="stackexchangeLink">
          <a href="https://patents.stackexchange.com/questions/tagged/US7595841" itemprop="url"><span itemprop="text">Discuss</span></a>
        </li>
      
  </ul>

  
  <ul itemprop="concept" itemscope>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000087</span>
      <span itemprop="name">stabilizing</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>abstract</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">7</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000875</span>
      <span itemprop="name">corresponding</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">25</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000014616</span>
      <span itemprop="name">translation</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>claims</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">8</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000000034</span>
      <span itemprop="name">methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">22</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004364</span>
      <span itemprop="name">calculation methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">13</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006073</span>
      <span itemprop="name">displacement</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">13</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000007781</span>
      <span itemprop="name">pre-processing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">5</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000010008</span>
      <span itemprop="name">shearing</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">5</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001131</span>
      <span itemprop="name">transforming</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">5</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000873</span>
      <span itemprop="name">masking</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">3</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000000694</span>
      <span itemprop="name">effects</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006467</span>
      <span itemprop="name">substitution reaction</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">2</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000004458</span>
      <span itemprop="name">analytical methods</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002708</span>
      <span itemprop="name">enhancing</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">239000011519</span>
      <span itemprop="name">fill dirt</span>
      <span itemprop="domain">Substances</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001976</span>
      <span itemprop="name">improved</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000001965</span>
      <span itemprop="name">increased</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000004048</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">238000006011</span>
      <span itemprop="name">modification</span>
      <span itemprop="domain">Methods</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002250</span>
      <span itemprop="name">progressing</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
    <li itemprop="match" itemscope repeat>
      <span itemprop="id">230000002829</span>
      <span itemprop="name">reduced</span>
      <span itemprop="domain">Effects</span>
      <span itemprop="svg_large"></span>
      <span itemprop="svg_small"></span>
      <span itemprop="smiles"></span>
      <span itemprop="inchi_key"></span>
      <span itemprop="similarity">0</span>
      
      <span itemprop="sections" repeat>description</span>
      
      <span itemprop="count">1</span>
    </li>
  
  </ul>
  

  <section>
    <h2>Images</h2>
    <ul>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/thumbnails/US7595841B1/US07595841-20090929-D00000.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/US7595841B1/US07595841-20090929-D00000.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/thumbnails/US7595841B1/US07595841-20090929-D00001.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/US7595841B1/US07595841-20090929-D00001.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/thumbnails/US7595841B1/US07595841-20090929-D00002.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/US7595841B1/US07595841-20090929-D00002.png">
        <ul>
          
        </ul>
      </li>
      <li itemprop="images" itemscope repeat>
        <img itemprop="thumbnail" src="https://patentimages.storage.googleapis.com/thumbnails/US7595841B1/US07595841-20090929-D00003.png">
        <meta itemprop="full" content="https://patentimages.storage.googleapis.com/US7595841B1/US07595841-20090929-D00003.png">
        <ul>
          
        </ul>
      </li>
      </ul>
  </section>

  <section>
    <h2>Classifications</h2>
    
    <ul>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H</span>&mdash;<span itemprop="Description">ELECTRICITY</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04</span>&mdash;<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N</span>&mdash;<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/00</span>&mdash;<span itemprop="Description">Details of television systems</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/222</span>&mdash;<span itemprop="Description">Studio circuitry; Studio devices; Studio equipment ; Cameras comprising an electronic image sensor, e.g. digital cameras, video cameras, TV cameras, video cameras, camcorders, webcams, camera modules for embedding in other devices, e.g. mobile phones, computers or vehicles</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/225</span>&mdash;<span itemprop="Description">Television cameras ; Cameras comprising an electronic image sensor, e.g. digital cameras, video cameras, camcorders, webcams, camera modules specially adapted for being embedded in other devices, e.g. mobile phones, computers or vehicles</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/232</span>&mdash;<span itemprop="Description">Devices for controlling television cameras, e.g. remote control ; Control of cameras comprising an electronic image sensor</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/23248</span>&mdash;<span itemprop="Description">Devices for controlling television cameras, e.g. remote control ; Control of cameras comprising an electronic image sensor for stable pick-up of the scene in spite of camera body vibration</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/23264</span>&mdash;<span itemprop="Description">Vibration or motion blur correction</span>
            <meta itemprop="Leaf" content="true">
            
            <meta itemprop="FirstCode" content="true">
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/00</span>&mdash;<span itemprop="Description">Image analysis</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/20</span>&mdash;<span itemprop="Description">Analysis of motion</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T7/223</span>&mdash;<span itemprop="Description">Analysis of motion using block-matching</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H</span>&mdash;<span itemprop="Description">ELECTRICITY</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04</span>&mdash;<span itemprop="Description">ELECTRIC COMMUNICATION TECHNIQUE</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N</span>&mdash;<span itemprop="Description">PICTORIAL COMMUNICATION, e.g. TELEVISION</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/00</span>&mdash;<span itemprop="Description">Details of television systems</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/222</span>&mdash;<span itemprop="Description">Studio circuitry; Studio devices; Studio equipment ; Cameras comprising an electronic image sensor, e.g. digital cameras, video cameras, TV cameras, video cameras, camcorders, webcams, camera modules for embedding in other devices, e.g. mobile phones, computers or vehicles</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/225</span>&mdash;<span itemprop="Description">Television cameras ; Cameras comprising an electronic image sensor, e.g. digital cameras, video cameras, camcorders, webcams, camera modules specially adapted for being embedded in other devices, e.g. mobile phones, computers or vehicles</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/232</span>&mdash;<span itemprop="Description">Devices for controlling television cameras, e.g. remote control ; Control of cameras comprising an electronic image sensor</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/23248</span>&mdash;<span itemprop="Description">Devices for controlling television cameras, e.g. remote control ; Control of cameras comprising an electronic image sensor for stable pick-up of the scene in spite of camera body vibration</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/23251</span>&mdash;<span itemprop="Description">Motion detection</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">H04N5/23254</span>&mdash;<span itemprop="Description">Motion detection based on the image signal</span>
            <meta itemprop="Leaf" content="true">
            
            
          </li>
          </ul>
      </li>
      <li>
        <ul itemprop="cpcs" itemscope repeat>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G</span>&mdash;<span itemprop="Description">PHYSICS</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06</span>&mdash;<span itemprop="Description">COMPUTING; CALCULATING; COUNTING</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T</span>&mdash;<span itemprop="Description">IMAGE DATA PROCESSING OR GENERATION, IN GENERAL</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/00</span>&mdash;<span itemprop="Description">Indexing scheme for image analysis or image enhancement</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10</span>&mdash;<span itemprop="Description">Image acquisition modality</span>
            
            
            
          </li>
          <li itemprop="cpcs" itemscope repeat>
            <span itemprop="Code">G06T2207/10016</span>&mdash;<span itemprop="Description">Video; Image sequence</span>
            <meta itemprop="Leaf" content="true">
            <meta itemprop="Additional" content="true">
            
          </li>
          </ul>
      </li>
      </ul>
  </section>

  <section itemprop="abstract" itemscope>
    <h2>Abstract</h2>
    
    <div itemprop="content" html><abstract mxw-id="PA62620741" lang="EN" load-source="patent-office">
    <div num="p-0001" class="abstract">A method of stabilizing a video image displayed in multiple video fields of a video sequence includes the steps of: subdividing a selected area of a first video field into nested pixel blocks; determining horizontal and vertical translation of each of the pixel blocks in each of the pixel block subdivision levels from the first video field to a second video field; and determining translation of the image from the first video field to the second video field by determining a change in magnification of the image from the first video field to the second video field in each of horizontal and vertical directions, and determining shear of the image from the first video field to the second video field in each of the horizontal and vertical directions.</div>
  </abstract>
  </div>
  </section>

  <section itemprop="description" itemscope>
    <h2>Description</h2>
    
    <div itemprop="content" html><div mxw-id="PDES28070530" lang="EN" load-source="patent-office" class="description">

  <heading>ORIGIN OF THE INVENTION</heading>
  <p num="p-0002">This invention was made by an employee of the United States Government and may be manufactured and used by or for the Government for Governmental purposes without the payment of royalties.</p>


  <heading>BACKGROUND OF THE INVENTION</heading>
  <p num="p-0003">1. Field of the Invention</p>
  <p num="p-0004">The present invention relates generally to video image processing methods and, in an embodiment described herein, more particularly provides a method of stabilizing and registering video images.</p>
  <p num="p-0005">2. Description of Related Art</p>
  <p num="p-0006">Techniques presently exist for stabilizing video images. These techniques typically function to reduce or eliminate image translation (i.e., displacement) horizontally and vertically in a video sequence. In general, these techniques are very limited in effectiveness, since they are not able to compensate for image rotation or dilation. In addition, these techniques are sensitive to the effects of parallax in which objects in the foreground and background are moving at different rates and/or directions. Furthermore, these techniques are typically able to determine image motion only to the nearest pixel.</p>
  <p num="p-0007">Video image stabilization and other image enhancing techniques are also described in the following U.S. published applications: 2002/0064382 2003/0090593 2003/0099410; and U.S. Pat. Nos. 5,784,175 5,453,800 5,327,232 5,210,605 4,924,306 5,815,670 5,742,710 5,734,737 5,686,973 5,535,288 5,528,703 5,778,100 5,748,784 5,748,761 5,745,605 5,737,447 5,734,753 5,729,302 5,703,966 5,684,898 5,581,308 5,555,033 5,488,675 5,488,674 5,473,364 5,325,449 5,259,040 5,067,014 4,797,942 4,675,532 4,937,666 4,979,738 5,144,423 5,263,135 5,276,513 5,278,915 5,321,748 5,518,497 5,534,925 5,566,674 5,627,915 5,629,988 5,635,994 5,657,402 5,717,793 5,909,657 5,920,657 5,963,675 6,037,988 6,173,089 6,571,021 6,640,018 6,373,970 6,650,792 5,943,450 5,204,944 5,050,225 4,908,874 4,893,258 4,759,076 4,672,680 6,459,822 and 6,560,375.</p>
  <p num="p-0008">The last two of these (U.S. Pat. Nos. 6,459,822 and 6,560,375), having the present inventor as a coinventor thereof, provide an advanced video image stabilization and registration technique which is very accurate and is capable of compensating for image rotation and dilation, and is capable of compensating for the effects of parallax. Unfortunately, however, this technique does not compensate for other forms of distortion, including different magnifications in different directions (as seen, for example, when an object is rotated toward or away from the camera and thus foreshortened in one direction) and shearing of the image (as seen in more complex object motion). This technique also uses prior knowledge of the shape (width-to-height ratio) of the image elements (pixels) to both determine the changes in the image using its limited image transformation, and to then correct for those changes.</p>
  <p num="p-0009">Therefore, it can be seen that it would be quite desirable to provide an improved video image stabilization and enhancement technique which can compensate for additional forms of image distortion, and which does not require advance knowledge of a pixel width-to-height ratio of the image. It is accordingly among the objects of the present invention to provide such a technique.</p>
  <heading>SUMMARY OF THE INVENTION</heading>
  <p num="p-0010">In carrying out the principles of the present invention, in accordance with an embodiment thereof, a method is provided for stabilizing and registering video images. The method compensates for more generalized forms of image distortion, and does not require advance knowledge of a pixel width-to-height ratio of an image.</p>
  <p num="p-0011">In one aspect of the invention, displacement and dilation of an image from one video field to another in a video sequence are determined by choosing a key video field and selecting a key area of pixels within the key video field which contains the image. The key area is then subdivided into multiple levels of nested pixel blocks. Translation of the key area from the key field to a new video field is approximated by searching for an area in the new video field having a maximum correlation to the key area. The key area translation approximation is used as a starting point for determination of the translation of each of the pixel blocks in the largest pixel block subdivision from the key video field to the new video field. The translation of each of the pixel blocks in the largest pixel block subdivision is then used as a starting point for determination of the translation of each of the respective associated pixel blocks in the next smaller pixel block subdivision. This process is repeated until a determination of the translation of each of the pixel blocks in the smallest pixel block subdivision is made. Certain of the pixel blocks may be masked, for example, if a maximum correlation coefficient between one of the smallest pixel blocks and pixel blocks in the new video field is less than a predetermined value, in which case they are not considered in any subsequent calculations.</p>
  <p num="p-0012">Translation of the image from the key video field to the new video field is found by determining a change in magnification of the image from the key video field to the new video field in each of horizontal and vertical directions, determining shear of the image from the key video field to the new video field in each of the horizontal and vertical directions, and correcting the horizontal and vertical translations of each of the pixel blocks in the smallest pixel block subdivision for the change in magnification and shear of the image from the key video field to the new video field. The corrected horizontal and vertical pixel block translations are then averaged to produce respective horizontal and vertical translations of the image from the key video field to the new video field.</p>
  <p num="p-0013">These and other features, advantages, benefits and objects of the present invention will become apparent to one of ordinary skill in the art upon careful consideration of the detailed description of a representative embodiment of the invention hereinbelow and the accompanying drawings.</p>


  <description-of-drawings>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="p-0014"> <figref idrefs="DRAWINGS">FIG. 1</figref> is a flow chart representing a method embodying principles of the present invention;</p>
    <p num="p-0015"> <figref idrefs="DRAWINGS">FIG. 2</figref> is a flow chart representing substeps in a video frame pre-processing step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0016"> <figref idrefs="DRAWINGS">FIG. 3</figref> is a flow chart representing substeps in a key area subdividing step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0017"> <figref idrefs="DRAWINGS">FIG. 4</figref> is a flow chart representing substeps in a key area masking step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0018"> <figref idrefs="DRAWINGS">FIG. 5</figref> is a flow chart representing substeps in an image translation approximating step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0019"> <figref idrefs="DRAWINGS">FIG. 6</figref> is a flow chart representing substeps in a pixel block translation determining step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0020"> <figref idrefs="DRAWINGS">FIG. 7</figref> is a flow chart representing substeps in a magnification change determining step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0021"> <figref idrefs="DRAWINGS">FIG. 8</figref> is a flow chart representing substeps in an image shear determining step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>;</p>
    <p num="p-0022"> <figref idrefs="DRAWINGS">FIG. 9</figref> is a flow chart representing substeps in an image translation determining step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>; and</p>
    <p num="p-0023"> <figref idrefs="DRAWINGS">FIG. 10</figref> is a flow chart representing substeps in a subsequent video field pre-processing step of the method of <figref idrefs="DRAWINGS">FIG. 1</figref>.</p>
  </description-of-drawings>


  <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
  <p num="p-0024">It is to be understood that the various embodiments of the present invention described herein may be utilized in various orientations, such as inclined, inverted, horizontal, vertical, etc., and in various configurations, without departing from the principles of the present invention. The embodiments are described merely as examples of useful applications of the principles of the invention, which is not limited to any specific details of these embodiments.</p>
  <p num="p-0025">Representatively illustrated in <figref idrefs="DRAWINGS">FIG. 1</figref> is a method <b>10</b> which embodies principles of the present invention. In the following description of the method <b>10</b>, reference is made to a standard video format well known to those skilled in the art, in which a video sequence includes multiple sequentially displayed video frames, with each video frame comprising two interlaced video fields, each of which presents an image as an arrangement of pixels having red, green and blue brightness levels, etc. However, it is to be clearly understood that the principles of the present invention are not limited to use with the standard video format, and that other formats, and other types of formats may be utilized, without departing from the principles of the present invention.</p>
  <p num="p-0026">The method <b>10</b> includes steps <b>20</b>, <b>30</b>, <b>40</b>, <b>50</b>, <b>60</b>, <b>70</b>, <b>80</b>, <b>90</b> and <b>100</b>, and each of these steps includes substeps representatively depicted in the accompanying <figref idrefs="DRAWINGS">FIGS. 2</figref>, <b>3</b>, <b>4</b>, <b>5</b>, <b>6</b>, <b>7</b>, <b>8</b>, <b>9</b> and <b>10</b>, respectively. Note that steps <b>50</b>-<b>100</b> are repeated, with these steps being performed for each video field in a video sequence, as described in further detail below.</p>
  <p num="p-0027">Step <b>20</b> is a video frame pre-processing step. Due to the fact that the standard video format video frame includes two interlaced video fields, one video field following the other in time, it is preferred to separate these video fields before beginning to analyze the motion of an image of interest therein.</p>
  <p num="p-0028">In step <b>22</b>, the video fields are extracted from each video frame of a video sequence. In the standard video format, one video field consists of even-numbered horizontal lines, and the other video field consists of odd-numbered horizontal lines, of each video frame, with the video fields being separated by 1/60th of a second in time. These horizontal lines are rows of pixels making up the image shown in the video frame.</p>
  <p num="p-0029">When the video fields are separated out, each will have alternating blank lines therein, due to the absence of the corresponding other video field from its video frame. Therefore, in step <b>24</b>, interpolation is used to fill in the missing lines in each video field. Video interpolation techniques are well known to those skilled in the art and will not be described further herein. Any such interpolation techniques may be utilized in keeping with the principles of the present invention.</p>
  <p num="p-0030">In step <b>26</b>, each video field image is transformed into a gray-scale image by averaging together the red, green and blue brightness values of each pixel of the video field. Of course, step <b>20</b> could begin with a gray-scale (i.e., black and white in common parlance) video sequence, in which case step <b>26</b> would be unnecessary.</p>
  <p num="p-0031">Step <b>30</b> is a key area subdividing step. This step produces groupings of pixels on multiple levels, such that each pixel group or block (other than the smallest size of pixel block) includes multiple smaller pixel blocks. In this sense, the pixel blocks are “nested” with respect to each other.</p>
  <p num="p-0032">In step <b>32</b>, a key field is selected. The key field is one of the video fields extracted in step <b>22</b>. Preferably, the key field contains an image of interest, and at least a portion of that image displays an object, person, etc. which the objective is to stabilize in the video sequence. For example, if the video sequence shows an image of a moving car and it is desired to stabilize the video sequence so that the image of the car is relatively motionless, the key field will preferably be selected as one of the video fields which contains a relatively clear centralized image of the car. The key field may be any one of the video fields in the video sequence, e.g., at the beginning, middle or end of the video sequence.</p>
  <p num="p-0033">In step <b>34</b>, a key area within the key field is selected. Preferably, the key area is a rectangular array of pixels and contains the specific image of interest about which it is desired to stabilize the video sequence, with a minimum of background, foreground, extraneous images, etc. Using the above example, the key area would preferably contain the image of the car and little else. The key area may be any group of pixels in the key field. For use as an example in the following further description of the method <b>10</b>, the key area may be a rectangular group of pixels which is 358 pixels wide by 242 pixels high.</p>
  <p num="p-0034">In step <b>36</b>, the key area is preferably adjusted so that it contains a convenient whole number multiple of the smallest pixel block size into which the key area is to be subdivided. Thus, the key area is adjusted so that it can be conveniently subdivided into progressively smaller blocks of pixels. Using the above example, and assuming that the smallest desired pixel block size is a 15×15 block of pixels, the next larger pixel block size is a 30×30 block of pixels and the largest pixel block size is a 60×60 block of pixels, the key area may be adjusted to a size of 360×240 pixels. It will be readily appreciated that an array of 360×240 pixels may be conveniently subdivided into 60×60 pixel blocks, further subdivided into 30×30 pixel blocks, and still further subdivided into 15×15 pixel blocks.</p>
  <p num="p-0035">In step <b>38</b>, the adjusted key area is subdivided into nested pixel blocks, that is, larger pixel blocks having smaller pixel blocks therein. Using the above example, there will be 24 of the 60×60 pixel blocks in the 360×240 adjusted key area, there will be 96 of the 30×30 pixel blocks (four 30×30 pixel blocks in each 60×60 pixel block) and there will be 384 of the 15×15 pixel blocks (four 15×15 pixel blocks in each 30×30 pixel block).</p>
  <p num="p-0036">In this example, the pixel block subdivisions have been selected to be 15×15 as the smallest, 30×30 as the next larger, and 60×60 as the largest, the pixel blocks therein are square, there are three levels of pixel blocks, and each pixel block subdivision has four times the number of pixel blocks as the next larger pixel block subdivision. However, it is to be clearly understood that other pixel block sizes, other pixel block shapes, other numbers of pixel block levels and other relationships between pixel block subdivisions may be used, without departing from the principles of the present invention. For instance, the smallest pixel block size could be 12×12, pixel blocks could be rectangular, but not square, there could be four levels of nested pixel blocks and one level could have nine times the number of pixel blocks as the next larger pixel block subdivision, while another level could have twelve times the number of pixel blocks as the next larger pixel block subdivision.</p>
  <p num="p-0037">Step <b>40</b> is a data masking step in which selected pixel blocks are excluded from further consideration in the method <b>10</b>. A data mask is constructed by producing an array of numbers in which each element of the array corresponds to one of the smallest pixel blocks of the key area. Using the above example of a 360×240 pixel key area and 15×15 smallest pixel blocks, the data mask would be a 24×16 array. An element of the array is set to 1 if the corresponding pixel block is to be included in further calculations, and the element is set to 0 if the corresponding pixel block is to be excluded from further calculations.</p>
  <p num="p-0038">In step <b>42</b>, an operator is permitted to manually exclude pixel blocks which are not of interest. Using the above example of a key area containing an image of a car, the key area may also include images of other objects, such as objects in the foreground, background, etc., which are not germane to the analysis. Computational economy and accuracy are enhanced when the pixel blocks containing these extraneous images are masked by changing the corresponding elements in the data mask array to 0.</p>
  <p num="p-0039">In step <b>44</b>, featureless pixel blocks are masked. This masking is done automatically and results when the scale of the variations in a pixel block are smaller than a predetermined value. The scale of the variations in a pixel block is given by the standard deviation of the average brightness level of each individual pixel in the pixel block. Recall that the average brightness level of each pixel was determined in step <b>26</b> above.</p>
  <p num="p-0040">Step <b>50</b> provides an approximation of the translation (horizontal and vertical shift or displacement) of the key area from the key field to a new field in the video sequence. This approximation is used to aid in the search for translation of the progressively smaller pixel blocks, as described below.</p>
  <p num="p-0041">In step <b>52</b>, a correlation coefficient between the key area and a corresponding area in the new video field is calculated by a process known as cross-correlation. Such calculation of correlation coefficient between arrays of pixels is well known to those skilled in the art and results in a number which is related to the degree to which one array “matches” another array. Thus, the key area is cross-correlated with a corresponding area in the new video field, the corresponding area having the same shape and size as the key area and being located in the new field as the key area is located in the key field.</p>
  <p num="p-0042">In step <b>54</b>, the key area is cross-correlated with other areas in the new video field, with the centers of the other areas being displaced relative to the center of the corresponding area used in step <b>52</b>. For example, correlation coefficients may be calculated for areas 10 pixels to the right, 10 pixels to the left, 10 pixels up and 10 pixels down relative to the corresponding area used in step <b>52</b>. If a correlation coefficient between the key area and one of these other areas is greater than the correlation coefficient between the key area and the corresponding area found in step <b>52</b>, then there is an indication that the image has translated in the direction of the area having the increased correlation coefficient. If the correlation coefficient between the key area and the corresponding area found in step <b>52</b> is greater than the correlation coefficient of each of the other areas, but one of the other areas has a correlation coefficient greater than the remainder of the other areas, then there is an indication that the image has translated in the direction of the other area having the maximum correlation coefficient, but is between the corresponding area and the other area having the maximum correlation coefficient.</p>
  <p num="p-0043">In step <b>56</b>, the search is refined based on the indications given by steps <b>52</b> and <b>54</b>. Thus, the correlation coefficients calculated in steps <b>52</b> and <b>54</b> are used as a basis on which the search is refined. In general, the objective is to determine the area in the new field having the maximum correlation coefficient.</p>
  <p num="p-0044">As depicted in <figref idrefs="DRAWINGS">FIG. 5</figref>, steps <b>54</b> and <b>56</b> are repeated, with correlation coefficients being calculated, the search refined, correlation coefficients calculated again, the search refined again, etc., until no further increase in correlation coefficient is achieved.</p>
  <p num="p-0045">In step <b>58</b>, the area in the new field having the maximum correlation to the key area is selected. This area is considered to be a rough approximation of the actual location of the image contained in the key area, as translated between the key field and the new field.</p>
  <p num="p-0046">Step <b>60</b> is in large part a repeat of step <b>50</b>, except that it is performed for each pixel block in each pixel block subdivision, beginning with the largest pixel block subdivision. As step <b>50</b> began with a calculation of correlation coefficient between the key area and the corresponding area in the new video field, step <b>60</b> begins with a calculation of correlation coefficient between one of the largest pixel blocks and a corresponding pixel block in the area selected in step <b>58</b>. Using the above example, a 60×60 pixel block of the key area is first cross-correlated with a corresponding 60×60 pixel block in the area selected in step <b>58</b>. The 60×60 pixel block of the key area is then cross-correlated with other 60×60 pixel blocks having respective centers which are displaced relative to the center of the corresponding 60×60 pixel block. The results of these calculations are then used to indicate the direction of translation of the 60×60 key area pixel block. The search is then refined and the process repeated to determine the translation of the 60×60 pixel block from the key area to the area selected in step <b>58</b> by finding the 60×60 pixel block having maximum correlation to the 60×60 key area pixel block. This process is then repeated for each of the other 60×60 pixel blocks in the key area, so that the translation of each 60×60 pixel block from the key field to the new field is determined.</p>
  <p num="p-0047">Using the translation of its associated 60×60 pixel block as a first approximation, the translation of each 30×30 pixel block is determined. Then, using the translation of its associated 30×30 pixel block as a first approximation, the translation of each 15×15 pixel block is determined. Thus, step <b>60</b> of the method <b>10</b> progresses from the largest pixel block subdivision to the smallest pixel block subdivision, determining the translation of each pixel block within each subdivision, using the previously determined translation of the next larger associated pixel block as a starting point for determining the translation of each pixel block. Specific details of substeps <b>61</b>-<b>66</b> of step <b>60</b> are described in further detail below.</p>
  <p num="p-0048">In step <b>61</b>, the determination of each key field pixel block&#39;s translation begins with the largest pixel block subdivision. Using the example given above, wherein the 360×240 pixel key area is first subdivided into 60×60 pixel blocks, further subdivided into 30×30 pixel blocks, and then further subdivided into 15×15 pixel blocks, the process of step <b>60</b> begins with the 60×60 pixel blocks. Of course, if other pixel block subdivisions are made, then the process of step <b>60</b> might begin with pixel blocks of another size. For instance, the key area could be initially subdivided into 40×40 pixel blocks, in which case step <b>61</b> would begin with 40×40 pixel blocks, instead of 60×60 pixel blocks.</p>
  <p num="p-0049">In step <b>62</b>, the correlation coefficient between a pixel block and the corresponding pixel block in the new field is calculated. For the largest pixel block subdivision, the corresponding pixel block in the new field is the pixel block of the key field translated the same as the key area translated from the key field to the new field. In this manner, the translation of the key area from the key field to the new field, as determined in step <b>50</b>, is used as a first approximation of the translation of each of the largest pixel block subdivision pixel blocks. Using the above example, the correlation coefficient would be calculated for a 60×60 pixel block of the key area and a 60×60 pixel block of the new field translated the same relative to the 60×60 pixel block of the key area as the key area translated from the key field to the new field.</p>
  <p num="p-0050">In step <b>63</b>, a search is performed for the pixel block in the new field having maximum correlation to the pixel block in the key area. This step is similar to steps <b>54</b>, <b>56</b> and <b>58</b> described above, in which an area in the new field having maximum correlation to the key area is selected. In other words, step <b>63</b> is steps <b>54</b>, <b>56</b> and <b>58</b> performed for an individual pixel block, rather than for the entire key area. Thus, correlation coefficients between the individual pixel block of the key area and pixel blocks displaced relative to the corresponding pixel block of the new field are calculated, the search is refined based on the results of these calculations, further correlation coefficients are calculated, etc., until the pixel block of the new field having the maximum correlation to the pixel block of the key area is determined.</p>
  <p num="p-0051">In step <b>64</b>, the translation of each pixel block is determined. Steps <b>62</b> and <b>63</b> have been described above as having been performed for a single pixel block of a pixel block subdivision. However, step <b>64</b> signifies that the translation of each pixel block in the pixel block subdivision is determined. This determination is made by performing steps <b>62</b> and <b>63</b> for each pixel block in the pixel block subdivision. Using the example given above, the key area contains 24 of the 60×60 pixel blocks. Thus, steps <b>62</b> and <b>63</b> would be performed 24 times for the largest pixel block subdivision, thereby permitting the translation of each of the 60×60 pixel blocks to be determined independently.</p>
  <p num="p-0052">Note that it cannot be assumed that the pixel blocks are translated from the key field to the new field the same as the key area is translated from the key field to the new field, since rotation and change of magnification of the image from the key field to the new field may change the relative positionings of the pixel blocks. This is the reason the approximate translation of the key area from the key field to the new field as found in step <b>50</b> is used only as a starting point for determination of the translation of each pixel block of the largest pixel block subdivision.</p>
  <p num="p-0053">In step <b>65</b>, the process is advanced to the next smaller pixel block subdivision. Thus, after the translation of each pixel block in the largest pixel block subdivision is determined, the next smaller pixel block subdivision is evaluated to determine the translation of each pixel block therein. <figref idrefs="DRAWINGS">FIG. 6</figref> shows that steps <b>62</b>-<b>65</b> are repeated, so that the translation of each pixel block in each pixel block subdivision is determined, progressing from the largest pixel block subdivision to the smallest pixel block subdivision.</p>
  <p num="p-0054">Note that in step <b>62</b>, when a correlation coefficient for a pixel block in a pixel block subdivision other than the largest pixel block subdivision is calculated, the corresponding pixel block in the new field is the pixel block of the key field translated the same as the associated pixel block of the next larger pixel block subdivision translated from the key field to the new field. In this manner, the translation of the associated next larger pixel block from the key field to the new field, as previously determined in step <b>64</b>, is used as a first approximation of the translation of each of the pixel block subdivision pixel blocks. Using the above example, the correlation coefficient would be calculated for a 30×30 pixel block of the key area and a 30×30 pixel block of the new field translated the same relative to the 30×30 pixel block of the key area as its associated 60×60 pixel block translated from the key field to the new field.</p>
  <p num="p-0055">After steps <b>62</b>-<b>65</b> have been performed for each pixel block subdivision (except that step <b>65</b> cannot be performed after the smallest pixel block subdivision has been evaluated), the result is that the translation of each pixel block in each pixel block subdivision has been determined. This result is very beneficial, since the translations of the smallest pixel blocks may now be used to more precisely determine the translation of the key area from the key field to the new field, and may further be used to determine rotation, dilation, and shearing of the image between the key field and the new field.</p>
  <p num="p-0056">However, it is recognized that the correlation between a pixel block of the key field and a pixel block of the new field may only be very low, due to a variety of reasons. For example, a particular pixel block of the new field which is a translated pixel block of the key area may be obscured due to the presence of an object in the image foreground. Thus, in step <b>66</b>, a pixel block in the smallest pixel block subdivision is masked when its maximum correlation to pixel blocks in the new field, as determined in step <b>63</b>, is below a predetermined value. For example, if the maximum calculated correlation coefficient for a pixel block in the smallest pixel block subdivision is less than 0.7, the pixel block may be excluded in the data mask described in step <b>40</b> above. If a pixel block is masked, it is not considered in any further calculations in the method <b>10</b>.</p>
  <p num="p-0057">Since step <b>60</b> provides a measure of the translation of each pixel block in the smallest pixel block subdivision from the key field to the new field, this information may be used to determine whether the pixel blocks have spread apart or contracted relative to each other, whether the pixel blocks have rotated relative to each other, and whether there is shearing of the image in the vertical or horizontal directions. In general, a two-dimensional image transformation is described by an “affine transformation” that involves six quantities (A-F) such that:
<br/>
<i>x</i> <sub>new</sub> <i>=A+Bx</i> <sub>old</sub> <i>+Cy</i> <sub>old </sub>
<br/>
<i>y</i> <sub>new</sub> <i>=D+Ex</i> <sub>old</sub> <i>+Fy</i> <sub>old</sub>  (1)
<br/>
where x<sub>old</sub>, y<sub>old </sub>are the coordinates of a pixel block in a previous or key field, and x<sub>new</sub>, y<sub>new </sub>are the coordinates of the pixel block in a new field.
</p>
  <p num="p-0058">In the method <b>10</b>, the image transformation is described by the following:
<br/>
<i>x</i> <sub>new</sub> <i>=M</i> <sub>x</sub>[(<i>x</i> <sub>old</sub> <i>+Δx</i>)+(<i>y</i> <sub>old</sub> <i>+Δy</i>)<i>S</i> <sub>x</sub>]
<br/>
<i>y</i> <sub>new</sub> <i>=M</i> <sub>y</sub>[(<i>y</i> <sub>old</sub> <i>+Δy</i>)+(<i>x</i> <sub>old</sub> <i>+Δx</i>)<i>S</i> <sub>y</sub>]  (2)
<br/>
where Δx is the horizontal translation, Δy is the vertical translation, M<sub>x </sub>is the magnification in the horizontal direction, M<sub>y </sub>is the magnification in the vertical direction, S<sub>x </sub>is the shear in the horizontal flow, and S<sub>y </sub>is the shear in the vertical flow. This can be rewritten in the form of equation (1) above using the following substitutions:
<br/>
<i>A=M</i> <sub>x</sub> <i>[Δx+ΔyS</i> <sub>x</sub>]
<br/>
B=M<sub>x </sub>
<br/>
C=M<sub>x</sub>S<sub>x </sub>
<br/>
<i>D=M</i> <sub>y</sub> <i>[Δy+ΔxS</i> <sub>y</sub>)
<br/>
E=M<sub>y</sub>S<sub>y </sub>
<br/>
F=M<sub>y</sub>  (3)
</p>
  <p num="p-0059">Knowledge of the shape of the pixels in the image (number of pixels in the width and height of the image) is not required, in part because the shear is determined separately for the horizontal and vertical directions. In the method <b>10</b>, pixel counts are used for the coordinates and displacements of the pixels, rather than using physical units related to the shape of the pixels in the image. The displacements of the pixel blocks within the area of interest in the image produces a flow map with displacements in the horizontal and vertical directions (∂x, ∂y) defined by:
<br/>
∂<i>x</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>)=<i>x</i> <sub>new</sub>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>)−<i>x</i> <sub>old </sub>
<br/>
∂<i>y</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>)=<i>y</i> <sub>new</sub>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>)−<i>y</i> <sub>old</sub>  (4)
</p>
  <p num="p-0060">Step <b>70</b> is a magnification determination step in which the change in magnification of the image from the key field to the new field is determined. In step <b>72</b>, the difference in horizontal translation is calculated for each pixel block row pair in the smallest pixel block subdivision. Using the example above, for the 360×240 pixel key area and 15×15 pixel blocks in the smallest pixel block subdivision, there are twenty-four 15×15 pixel blocks in each row of the key area. The change in horizontal translation for each pair of pixel blocks, divided by the distance between the pixel block centers, is calculated for each row of the key area. This calculation gives the horizontal change in magnification for each pixel block pair.</p>
  <p num="p-0061">For example, if a pixel block on a row moves to the left 10 pixels from the key field to the new field, while a pixel block 300 pixels away moves to the left 13 pixels from the key field to the new field, the horizontal change in magnification is 1% (a 3 pixel difference in horizontal translation over a 300 pixel distance). As described above, masked pixel blocks are excluded from these calculations.</p>
  <p num="p-0062">Thus, a single pair of pixel blocks at horizontal positions x<sub>1 </sub>and x<sub>2 </sub>on a row of pixels at vertical position y<sub>old </sub>will contribute an estimate of M<sub>x </sub>as follows:
<br/>
<i>M</i> <sub>x</sub>=1+[θ<i>x</i>(<i>x</i> <sub>1</sub> <i>,y</i> <sub>old</sub>)−∂<i>x</i>(<i>x</i> <sub>2</sub> <i>,y</i> <sub>old</sub>)]/(<i>x</i> <sub>1</sub> <i>−x</i> <sub>2</sub>)  (5)
</p>
  <p num="p-0063">The magnification in the horizontal direction (M<sub>x</sub>) is determined by dividing the relative horizontal displacement between pairs of pixel blocks in each of the rows of pixel blocks by the distance between the respective centers of the pair of pixel blocks, and by averaging together the results, giving greater weight to those pixel block pairs with larger distances between them and more consistent results. The magnification changes for more widely spaced apart pixel block pairs are weighted more than those for relatively closely spaced pixel block pairs, since widely spaced apart pixel blocks are more sensitive to changes in magnification. Additionally, individual pixel block pair magnification changes may be excluded from the weighted average if their values are significantly different from the average, for example, a pixel block pair magnification change value may be excluded from the weighted average calculation if it is more than one standard deviation from the average of the magnification changes. In this manner, erroneous magnification change calculations do not affect the weighted average.</p>
  <p num="p-0064">In step <b>74</b>, the difference in vertical translation is calculated for each pixel block column pair in the smallest pixel block subdivision. Using the example given above, for the 360×240 pixel key area and 15×15 pixel blocks in the smallest pixel block subdivision, there are sixteen 15×15 pixel blocks in each column of the key area. The difference in vertical translation for each pair of pixel blocks, divided by the distance between the pixel block centers, is calculated for each column of the key area. This calculation gives the vertical change in magnification for each pixel block pair, similar to the manner in which the horizontal change in magnification for pixel block pairs in the key area rows are calculated in step <b>72</b>.</p>
  <p num="p-0065">Thus, the magnification in the vertical direction (M<sub>y</sub>) is determined by dividing the relative vertical displacement between each pair of the pixel blocks in each of the columns of pixel blocks by the distance between the respective centers of the pair of pixel blocks, and by averaging together the results, giving greater weight to those blocks with larger distances and more consistent results. A single pair of pixel blocks at vertical positions y<sub>1 </sub>and y<sub>2 </sub>on a column of pixels at horizontal position x<sub>old </sub>will contribute an estimate of M<sub>y </sub>as follows:
<br/>
<i>M</i> <sub>y</sub>=1+[∂<i>y</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>1</sub>)−∂<i>y</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>2</sub>)]/(<i>y</i> <sub>1</sub> <i>−y</i> <sub>2</sub>)  (6)
</p>
  <p num="p-0066">The magnification changes for more widely spaced apart pixel block pairs are weighted more than those for relatively closely spaced pixel block pairs, and individual pixel block pair magnification changes may be excluded from the weighted average if their values are significantly different from the average. For example, a pixel block pair magnification change value may be excluded from the weighted average calculation if it is more than one standard deviation from the average of the magnification changes.</p>
  <p num="p-0067">Note that, in contrast to prior image stabilization and registration methods, a weighted average of the individual horizontal and vertical magnification changes is not used. Instead, separate magnification changes are used for the horizontal and vertical directions. This provides for situations where an object in the image is rotated relative to the camera, and thus appears foreshortened in one direction, but not the other direction.</p>
  <p num="p-0068">Step <b>76</b> in <figref idrefs="DRAWINGS">FIG. 7</figref> represents the individual horizontal and vertical magnification change calculations described above.</p>
  <p num="p-0069">Step <b>80</b> is a shear determination step. This step is somewhat similar to step <b>70</b> in that changes in translation of pixel block pairs from the key field to the new field are used to calculate shear in the horizontal and vertical flows (S<sub>x</sub>, S<sub>y</sub>).</p>
  <p num="p-0070">In step <b>82</b>, the difference in horizontal translation is calculated for each pixel block pair in each of the smallest pixel block subdivision columns. The difference in horizontal translation for each pair of pixel blocks, divided by the distance between the pixel block centers, is calculated for each column of the key area. This calculation gives the horizontal shear for each pixel block pair in each column. For example, if a pixel block in a column moved to the right 1 pixel while another pixel block 300 pixels away in the column moved to the left 2 pixels from the key field to the new field, the difference in horizontal translation would be 3 pixels and the horizontal shear of the pixel block pair would be 1/100 (a 3 pixel difference in displacement over a 300 pixel distance gives a tangent of 3/300, equivalent to an angle of 0.57°).</p>
  <p num="p-0071">Thus, the shear in the horizontal flow (Sx) is determined by dividing the relative horizontal displacement between each pair of the pixel blocks in each of the columns of pixel blocks by the distance between the respective centers of the pair of pixel blocks, and by averaging together the results, giving greater weight to those pixel block pairs with larger distances between them and more consistent results. The calculated shear values for more widely spaced apart pixel block pairs are weighted more than those for relatively closely spaced pixel block pairs, since widely spaced apart pixel blocks are more sensitive to shear. Additionally, individual pixel block pair shear calculations may be excluded from the weighted average if their values are significantly different from the average, for example, a pixel block pair shear calculation may be excluded from the weighted average calculation if it is more than one standard deviation from the average of the shear calculations. In this manner, erroneous shear calculations do not affect the weighted average.</p>
  <p num="p-0072">A single pair of pixel blocks at vertical positions y<sub>1 </sub>and y<sub>2 </sub>on a column of pixel blocks at horizontal position x<sub>old </sub>will contribute an estimate of S<sub>x </sub>as follows:
<br/>
<i>S</i> <sub>x</sub> <i>=[∂x</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>1</sub>)−∂<i>x</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>2</sub>)]/[<i>M</i> <sub>x</sub>(<i>y</i> <sub>1</sub> <i>−y</i> <sub>2</sub>)]  (7)
</p>
  <p num="p-0073">In step <b>84</b>, the difference in vertical translation is calculated for each pixel block pair in each of the smallest pixel block subdivision rows. The difference in vertical translation for each pair of pixel blocks, divided by the distance between the pixel block centers, is calculated for each row of the key area. This calculation gives the shear in the vertical flow (S<sub>y</sub>) for each pixel block pair in each row.</p>
  <p num="p-0074">Thus, the shear in the vertical flow is determined by dividing the relative vertical displacement between each pair of the pixel blocks in each of the rows of pixel blocks by the distance between the respective centers of the pair of pixel blocks, and by averaging together the results, giving greater weight to those pixel block pairs with larger distances between them and more consistent results. The calculated shear values for more widely spaced apart pixel block pairs are weighted more than those for relatively closely spaced pixel block pairs, and individual pixel block pair shear calculations may be excluded from the weighted average if their values are significantly different from the average. For example, a pixel block pair shear calculation may be excluded from the weighted average calculation if it is more than one standard deviation from the average of the shear calculations.</p>
  <p num="p-0075">A single pair of pixel blocks at horizontal positions x<sub>1 </sub>and x<sub>2 </sub>on a row of pixel blocks at vertical position y<sub>old </sub>will contribute an estimate of S<sub>y </sub>as follows:
<br/>
<i>S</i> <sub>y</sub> <i>==[∂y</i>(<i>x</i> <sub>1</sub> <i>,y</i> <sub>old</sub>)−∂<i>y</i>(<i>x</i> <sub>2</sub> <i>,y</i> <sub>old</sub>)]/[<i>M</i> <sub>y</sub>(<i>x</i> <sub>1</sub> <i>−x</i> <sub>2</sub>)]  (8)
</p>
  <p num="p-0076">Note that, in contrast to prior video image stabilization and registration methods, the overall rotation of the image from the key field to the new field is not calculated. Instead, separate shears are obtained for the horizontal and vertical directions. This provides for situations in which an object in the image is rotated toward or away from the camera and appears foreshortened in a particular direction. This also provides for pixel shapes with arbitrary or unknown width-to-height ratios. A simple rotation of the image in physical coordinates will produce different shears (S<sub>x </sub>and S<sub>y</sub>) that will automatically account for the unknown pixel shape.</p>
  <p num="p-0077">Step <b>86</b> in <figref idrefs="DRAWINGS">FIG. 8</figref> represents the individual horizontal and vertical shear calculations described above.</p>
  <p num="p-0078">Step <b>90</b> is an image translation determination step. Recall that an approximation of the image translation from the key field to the new field was determined in step <b>50</b>. However, since steps <b>60</b>, <b>70</b> and <b>80</b> above have provided determinations of the individual translations of the smallest pixel block subdivision pixel blocks, the change in magnification in the horizontal and vertical directions and the shear in the horizontal and vertical directions in the key area from the key field to the new field, a precise determination of the key area translation may now be made.</p>
  <p num="p-0079">In step <b>92</b>, the horizontal translation (Δx) is determined by correcting the translation determined in step <b>60</b> for each of the smallest pixel block subdivision pixel blocks for the magnifications and shears determined in steps <b>70</b> and <b>80</b>, and by taking a weighted average of the corrected displacements. A single pixel block at position x<sub>old</sub>, y<sub>old </sub>will contribute an estimate of Δx as follows:
<br/>
Δ<i>x</i>=[(<i>x</i> <sub>old</sub> <i>+∂x</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>))/<i>M</i> <sub>x</sub> <i>−S</i> <sub>x</sub>(<i>y</i> <sub>old</sub> <i>+∂y</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>))/<i>M</i> <sub>y</sub>]/(1−<i>S</i> <sub>x</sub> <i>S</i> <sub>y</sub>)−<i>x</i> <sub>old</sub>  (9)
</p>
  <p num="p-0080">In step <b>94</b>, the vertical translation (Δy) is determined by correcting the translation determined in step <b>60</b> for each of the smallest pixel block subdivision pixel blocks for the magnifications and shears determined in steps <b>70</b> and <b>80</b>, and by taking a weighted average of the corrected displacements. A single pixel block at position x<sub>old</sub>, y<sub>old </sub>will contribute an estimate of Δy as follows:
<br/>
Δ<i>y</i>=[(<i>y</i> <sub>old</sub> <i>+∂y</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>))/<i>M</i> <sub>y</sub> <i>−S</i> <sub>y</sub>(<i>x</i> <sub>old</sub> <i>+∂x</i>(<i>x</i> <sub>old</sub> <i>,y</i> <sub>old</sub>))/<i>M</i> <sub>x</sub>]/(1−<i>S</i> <sub>x</sub> <i>S</i> <sub>y</sub>)−<i>y</i> <sub>old</sub>  (10)
</p>
  <p num="p-0081">In step <b>96</b>, the overall horizontal and vertical translation for the center of the key area is calculated using the values for M<sub>x</sub>, M<sub>y</sub>, S<sub>x</sub>, S<sub>y</sub>, Δx and Δy determined above through the inverse affine transformation as follows:
<br/>
<i>x</i> <sub>old</sub> <i>=x</i> <sub>new</sub> <i>/[M</i> <sub>x</sub>(1−<i>S</i> <sub>x</sub> <i>S</i> <sub>y</sub>)]−<i>y</i> <sub>new</sub> <i>S</i> <sub>x</sub> <i>/[M</i> <sub>y</sub>(1−<i>S</i> <sub>x</sub> <i>S</i> <sub>y</sub>)]−Δ<i>x </i>
<br/>
<i>y</i> <sub>old</sub> <i>=y</i> <sub>new</sub> <i>/[M</i> <sub>y</sub>(1−<i>S</i> <sub>x</sub> <i>S</i> <sub>y</sub>)]−<i>x</i> <sub>new</sub> <i>S</i> <sub>x</sub> <i>/[M</i> <sub>x</sub>(1−<i>S</i> <sub>x</sub> <i>S</i> <sub>y</sub>)]−Δ<i>y</i>  (11)
</p>
  <p num="p-0082">Step <b>100</b> is a pre-processing step in which the results of steps <b>70</b>, <b>80</b> and <b>90</b> are used to pre-process a subsequent field in the video sequence. In this manner, the subsequent field is placed in a condition in which it should more closely match the key field. The determinations of translation, shear and magnification change of the key area from the key field to the new field are used to perform an initial de-translation, de-shearing and de-magnification of the subsequent field.</p>
  <p num="p-0083">It is to be clearly understood that use of the term “subsequent” herein to describe a video field does not necessarily signify that the video field is positioned later in the video sequence, but is used to signify that the video field is processed subsequently in the method <b>10</b>. For example, a “subsequent” video field may actually be positioned earlier in time in a video sequence, since a video sequence may be processed from back to front (later to earlier in time), from the middle to either end, etc.</p>
  <p num="p-0084">In step <b>102</b>, the image contained in the subsequent field is de-translated, that is, it is translated horizontally and vertically opposite to the respective distances and directions the key area translated from the key field to the new field as determined in step <b>90</b>.</p>
  <p num="p-0085">In step <b>104</b>, the image contained in the subsequent field is de-sheared, that is, it is sheared in the horizontal and vertical directions opposite to the angle and direction the key area was sheared from the key field to the new field as determined in step <b>80</b>.</p>
  <p num="p-0086">In step <b>106</b>, the image contained in the subsequent video field is de-magnified, that is, it is magnified (or reduced in magnification) in the horizontal and vertical directions opposite to the change in magnification of the key area from the key field to the new field as determined in step <b>70</b>.</p>
  <p num="p-0087">Note that <figref idrefs="DRAWINGS">FIG. 1</figref> indicates that steps <b>50</b>-<b>100</b> are repeated. These steps are performed for each video field in the video sequence. Thus, a change in magnification, shear and translation are determined for the subsequent video field. These determinations of change in magnification, shear and translation are then added to the pre-processing change in magnification, shear and translation applied to the subsequent video field in steps <b>102</b>, <b>104</b> and <b>106</b> to yield a total change in magnification, rotation and translation of the key area from the key field to the subsequent video field. In a similar manner, the total change in magnification, shear and translation determined for the subsequent video field is used to pre-process the next subsequent video field in the video sequence, etc.</p>
  <p num="p-0088">The result of these steps is that, for each video field in the video sequence, a change in magnification, shear and translation of the key area is determined. The video sequence may then be modified by de-magnifying, de-shearing and de-translating each video field in the video sequence, other than the key field, so that the image contained in the key area appears motionless and at the same magnification and orientation through the entire video sequence.</p>
  <p num="p-0089">Of course, a person of ordinary skill in the art, upon a careful consideration of the above description of the method <b>10</b>, would readily appreciate that modifications, additions, substitutions, deletions and other changes may be made to the method as described above and depicted in the accompanying drawings, which is but a single embodiment of the invention, and these changes are contemplated by the principles of the present invention. Accordingly, the foregoing detailed description is to be clearly understood as being given by way of illustration and example only, the spirit and scope of the present invention being limited solely by the appended claims.</p>

</div>
  </div>
  </section>

  <section itemprop="claims" itemscope>
    <h2>Claims (<span itemprop="count">15</span>)</h2>
    
    <div itemprop="content" html><div mxw-id="PCLM23091798" lang="EN" load-source="patent-office" class="claims">
  <div class="claim"> <div id="CLM-00001" num="00001" class="claim">
    <div class="claim-text">1. A method of stabilizing a video image of interest displayed in multiple video fields of a video sequence, the method comprising the steps of:
<div class="claim-text">subdividing a selected area of a first video field into nested pixel blocks including multiple levels of progressively smaller pixel block subdivisions, the area containing the video image;</div>
<div class="claim-text">determining horizontal and vertical translation of each of the pixel blocks in each of the pixel block subdivision levels from the first video field to a second video field; and</div>
<div class="claim-text">determining translation of the image from the first video field to the second video field by determining a change in magnification of the image from the first video field to the second video field in each of horizontal and vertical directions, determining shear of the image from the first video field to the second video field in each of the horizontal and vertical directions, and correcting from the first video field to the second video field the horizontal and vertical translations of each of the pixel blocks in the smallest pixel block subdivision for the chance in magnification and shear of the image due to an object being rotated toward or away from a camera, and averaging the corrected horizontal and vertical pixel block translations.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00002" num="00002" class="claim">
    <div class="claim-text">2. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the change in magnification determining step is performed by:
<div class="claim-text">a) for the horizontal direction, by dividing a relative horizontal translation of each pair of the pixel blocks in each row of the smallest pixel block subdivision by a respective distance between centers of the pixel blocks in the row pair, to thereby determine a horizontal magnification for each pixel block row pair; and</div>
<div class="claim-text">b) for the vertical direction, by dividing a relative vertical translation of each pair of the pixel blocks in each column of the smallest pixel block subdivision by a respective distance between centers of the pixel blocks in the column pair, to thereby determine a vertical magnification for each pixel block column pair.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00003" num="00003" class="claim">
    <div class="claim-text">3. The method of <claim-ref idref="CLM-00002">claim 2</claim-ref>, wherein the change in magnification determining step is further performed as follows:
<div class="claim-text">a) for the horizontal direction, by calculating an average of the horizontal magnifications for the pixel block row pairs; and</div>
<div class="claim-text">b) for the vertical direction, by calculating an average of the vertical magnifications for the pixel block column pairs.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00004" num="00004" class="claim">
    <div class="claim-text">4. The method of <claim-ref idref="CLM-00003">claim 3</claim-ref>, wherein each of the horizontal and vertical magnification averages is a weighted average, with greater weight being given to horizontal and vertical magnifications resulting from corresponding pixel block row and column pairs having greater distances between centers of the respective pixel blocks.</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00005" num="00005" class="claim">
    <div class="claim-text">5. The method of <claim-ref idref="CLM-00001">claim 1</claim-ref>, wherein the shear determining step is performed as follows:
<div class="claim-text">a) for the horizontal direction, by dividing a relative horizontal translation of each pair of the pixel blocks in each column of the smallest pixel block subdivision by a respective distance between centers of the pixel blocks in the column pair, to thereby determine a horizontal shear for each pixel block column pair; and</div>
<div class="claim-text">b) for the vertical direction, by dividing a relative vertical translation of each pair of the pixel blocks in each row of the smallest pixel block subdivision by a respective distance between centers of the pixel blocks in the row pair, to thereby determine a vertical shear for each pixel block row pair.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00006" num="00006" class="claim">
    <div class="claim-text">6. The method of <claim-ref idref="CLM-00005">claim 5</claim-ref>, wherein the shear determining step is further performed as follows:
<div class="claim-text">a) for the horizontal direction, by calculating an average of the horizontal shears for the pixel block column pairs; and</div>
<div class="claim-text">b) for the vertical direction, by calculating an average of the vertical shears for the pixel block row pairs.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00007" num="00007" class="claim">
    <div class="claim-text">7. The method of <claim-ref idref="CLM-00006">claim 6</claim-ref>, wherein each of the horizontal and vertical shear averages is a weighted average, with greater weight being given to horizontal and vertical shears resulting from corresponding pixel block column and row pairs having greater distances between centers of the respective pixel blocks.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00008" num="00008" class="claim">
    <div class="claim-text">8. A method of stabilizing a video image of interest displayed in multiple video fields of a video sequence, the method comprising the steps of:
<div class="claim-text">dividing an area of first video field of the video sequence into rows and columns of pixel blocks, the area containing the image;</div>
<div class="claim-text">determining a horizontal and vertical translation of each of the pixel blocks from the first video field to a second video field; and</div>
<div class="claim-text">calculating a change in magnification of the image in each of horizontal and vertical directions from the first video field to the second video field, wherein the horizontal chance in magnification and the vertical change in magnification are used separately to determine corresponding horizontal and vertical translations of the video image.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00009" num="00009" class="claim">
    <div class="claim-text">9. The method of <claim-ref idref="CLM-00008">claim 8</claim-ref>, wherein the calculating step is performed by:
<div class="claim-text">a) for the horizontal direction, by dividing a relative horizontal translation of each pair of the pixel blocks in each row by a respective distance between centers of the pixel blocks in the row pair, to thereby determine a horizontal magnification for each pixel block row pair; and</div>
<div class="claim-text">b) for the vertical direction, by dividing a relative vertical translation of each pair of the pixel blocks in each column by a respective distance between centers of the pixel blocks in the column pair, to thereby determine a vertical magnification for each pixel block column pair.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00010" num="00010" class="claim">
    <div class="claim-text">10. The method of <claim-ref idref="CLM-00009">claim 9</claim-ref>, wherein the change in magnification determining step is further performed as follows:
<div class="claim-text">a) for the horizontal direction, by calculating an average of the horizontal magnifications for the pixel block row pairs; and</div>
<div class="claim-text">b) for the vertical direction, by calculating an average of the vertical magnifications for the pixel block column pairs.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00011" num="00011" class="claim">
    <div class="claim-text">11. The method of claim it, wherein each of the horizontal and vertical magnification averages is a weighted average, with greater weight being given to horizontal and vertical magnifications resulting from corresponding pixel block row and column pairs having greater distances between centers of the respective pixel blocks.</div>
  </div>
  </div> <div class="claim"> <div id="CLM-00012" num="00012" class="claim">
    <div class="claim-text">12. A method of stabilizing a video image of interest displayed in multiple video fields of a video sequence, the method comprising the steps of:
<div class="claim-text">dividing an area of a first video field of the video sequence into rows and columns of pixel blocks, the area containing the image;</div>
<div class="claim-text">determining a horizontal and vertical translation of each of the pixel blocks from the first video field to a second video field; and</div>
<div class="claim-text">calculating shear of the image in each of horizontal and vertical directions from the first video field to the second video field, wherein the shear is due to rotation of an object toward or away from a camera.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00013" num="00013" class="claim">
    <div class="claim-text">13. The method of <claim-ref idref="CLM-00012">claim 12</claim-ref>, wherein the shear determining step is performed as follows:
<div class="claim-text">a) for the horizontal direction, by dividing a relative horizontal translation of each pair of the pixel blocks in each column by a respective distance between centers of the pixel blocks in the column pair, to thereby determine a horizontal shear for each pixel block column pair; and</div>
<div class="claim-text">b) for the vertical direction, by dividing a relative vertical translation of each pair of the pixel blocks in each row by a respective distance between centers of the pixel blocks in the row pair, to thereby determine a vertical shear for each pixel block row pair.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00014" num="00014" class="claim">
    <div class="claim-text">14. The method of <claim-ref idref="CLM-00013">claim 13</claim-ref>, wherein the shear determining step is further performed as follows:
<div class="claim-text">a) for the horizontal direction, by calculating an average of the horizontal shears for the pixel block column pairs; and</div>
<div class="claim-text">b) for the vertical direction, by calculating an average of the vertical shears for the pixel block row pairs.</div>
</div>
  </div>
  </div> <div class="claim-dependent"> <div id="CLM-00015" num="00015" class="claim">
    <div class="claim-text">15. The method of <claim-ref idref="CLM-00014">claim 14</claim-ref>, wherein each of the horizontal and vertical shear averages is a weighted average, with greater weight being given to horizontal and vertical shears resulting from corresponding pixel block column and row pairs having greater distances between centers Of the respective pixel blocks.</div>
  </div>
</div> </div>
  </div>
  </section>

  <section itemprop="application" itemscope>

    <section itemprop="metadata" itemscope>
        <span itemprop="applicationNumber">US11/174,210</span>
        <span itemprop="priorityDate">2005-07-01</span>
        <span itemprop="filingDate">2005-07-01</span>
        <span itemprop="title">Video image stabilization and registration—plus 
       </span>
        <span itemprop="ifiStatus">Active</span>
        <span itemprop="ifiExpiration">2027-12-03</span>
        <a href="/patent/US7595841B1/en">
            <span itemprop="representativePublication">US7595841B1</span>
            (<span itemprop="primaryLanguage">en</span>)
        </a>
    </section>

    <h2>Priority Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="priorityApps" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US11/174,210</span>
                   
                   <a href="/patent/US7595841B1/en">
                        <span itemprop="representativePublication">US7595841B1</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2005-07-01</td>
                <td itemprop="filingDate">2005-07-01</td>
                <td itemprop="title">Video image stabilization and registration—plus 
       </td>
              </tr>
           </tbody>
       </table>

    <h2>Applications Claiming Priority (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                    <th>Title</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="appsClaimingPriority" itemscope repeat>
                <td>
                   <span itemprop="applicationNumber">US11/174,210</span>
                   <a href="/patent/US7595841B1/en">
                        <span itemprop="representativePublication">US7595841B1</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                <td itemprop="priorityDate">2005-07-01</td>
                <td itemprop="filingDate">2005-07-01</td>
                <td itemprop="title">Video image stabilization and registration—plus 
       </td>
              </tr>
           </tbody>
       </table>

    

    

    <h2>Publications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Publication Number</th>
                    <th>Publication Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="pubs" itemscope repeat>
                <td>
                   <span itemprop="publicationNumber">US7595841B1</span>
                   
                   <span itemprop="thisPatent">true</span>
                   <a href="/patent/US7595841B1/en">US7595841B1
                       (<span itemprop="primaryLanguage">en</span>)
                   </a>
                </td>
                <td itemprop="publicationDate">2009-09-29</td>
              </tr>
           </tbody>
        </table>

  </section>

  <section itemprop="family" itemscope>
    <h1>Family</h1>
    <h2>ID=41109829</h2>

    <h2>Family Applications (1)</h2>
        <table>
            <thead>
                <tr>
                    <th>Application Number</th>
                    <th>Title</th>
                    <th>Priority Date</th>
                    <th>Filing Date</th>
                </tr>
            </thead>
            <tbody>
            <tr itemprop="applications" itemscope repeat>
                <td>
                    <span itemprop="applicationNumber">US11/174,210</span>
                    <span itemprop="ifiStatus">Active</span>
                    <span itemprop="ifiExpiration">2027-12-03</span>
                    <a href="/patent/US7595841B1/en">
                        <span itemprop="representativePublication">US7595841B1</span>
                          (<span itemprop="primaryLanguage">en</span>)
                      </a>
                </td>
                <td itemprop="priorityDate">2005-07-01</td>
                <td itemprop="filingDate">2005-07-01</td>
                <td itemprop="title">Video image stabilization and registration—plus 
       </td>
              </tr>
           </tbody>
        </table>

    

    

    <h2>Country Status (1)</h2>
      <table>
        <thead>
          <tr>
            <th>Country</th>
            <th>Link</th>
          </tr>
        </thead>
        <tbody>
        <tr itemprop="countryStatus" itemscope repeat>
            <td>
              <span itemprop="countryCode">US</span>
                (<span itemprop="num">1</span>)
              <meta itemprop="thisCountry" content="true">
            </td>
            <td>
              <a href="/patent/US7595841B1/en">
                <span itemprop="representativePublication">US7595841B1</span>
                  (<span itemprop="primaryLanguage">en</span>)
              </a>
            </td>
          </tr>
      </tbody>
    </table>

    

    

    <h2>Citations (2)</h2>
    <table>
      <caption>* Cited by examiner, † Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5107293A/en">
              <span itemprop="publicationNumber">US5107293A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1988-09-09</td>
          <td itemprop="publicationDate">1992-04-21</td>
          <td><span itemprop="assigneeOriginal">Canon Kabushiki Kaisha</span></td>
          <td itemprop="title">Automatic image stabilization device 
       </td>
        </tr><tr itemprop="backwardReferencesOrig" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6459822B1/en">
              <span itemprop="publicationNumber">US6459822B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1998-08-26</td>
          <td itemprop="publicationDate">2002-10-01</td>
          <td><span itemprop="assigneeOriginal">The United States Of America As Represented By The Administrator Of The National Aeronautics And Space Administration</span></td>
          <td itemprop="title">Video image stabilization and registration 
       </td>
        </tr>
      </tbody>
    </table>

    

    
    <ul>
      
      <li itemprop="applicationsByYear" itemscope repeat>
        <span itemprop="year">2005</span>
        <ul>
          
          <li itemprop="application" itemscope repeat>
            <span itemprop="filingDate">2005-07-01</span>
            <span itemprop="countryCode">US</span>
            <span itemprop="applicationNumber">US11/174,210</span>
            <a href="/patent/US7595841B1/en"><span itemprop="documentId">patent/US7595841B1/en</span></a>
            <span itemprop="legalStatusCat">active</span>
            <span itemprop="legalStatus">Active</span>
            
            <span itemprop="thisApp" content="true" bool></span>
            
          </li>
          
        </ul>
      </li>
      
    </ul>
    

    </section>

  <section>
    <h2>Patent Citations (2)</h2>
    <table>
      <caption>* Cited by examiner, † Cited by third party</caption>
      <thead>
        <tr>
          <th>Publication number</th>
          <th>Priority date</th>
          <th>Publication date</th>
          <th>Assignee</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US5107293A/en">
              <span itemprop="publicationNumber">US5107293A</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1988-09-09</td>
          <td itemprop="publicationDate">1992-04-21</td>
          <td><span itemprop="assigneeOriginal">Canon Kabushiki Kaisha</span></td>
          <td itemprop="title">Automatic image stabilization device 
       </td>
        </tr><tr itemprop="backwardReferences" itemscope repeat>
          <td>
            
            
            <a href="/patent/US6459822B1/en">
              <span itemprop="publicationNumber">US6459822B1</span>
              (<span itemprop="primaryLanguage">en</span>)
            </a>
            <span itemprop="examinerCited">*</span>
            
          </td>
          <td itemprop="priorityDate">1998-08-26</td>
          <td itemprop="publicationDate">2002-10-01</td>
          <td><span itemprop="assigneeOriginal">The United States Of America As Represented By The Administrator Of The National Aeronautics And Space Administration</span></td>
          <td itemprop="title">Video image stabilization and registration 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  

  

  

  <section>
    <h2>Similar Documents</h2>
    <table>
      <thead>
        <tr>
          <th>Publication</th>
          <th>Publication Date</th>
          <th>Title</th>
        </tr>
      </thead>
      <tbody>
        <tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US7352388B2/en">
                <span itemprop="publicationNumber">US7352388B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2008-04-01">2008-04-01</time>
            
            
          </td>
          <td itemprop="title">Camera calibrating apparatus 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/USRE37610E1/en">
                <span itemprop="publicationNumber">USRE37610E1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2002-03-26">2002-03-26</time>
            
            
          </td>
          <td itemprop="title">Running guide apparatus for vehicle capable of keeping safety at passing through narrow path and the method thereof 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP0918439B1/en">
                <span itemprop="publicationNumber">EP0918439B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2008-12-24">2008-12-24</time>
            
            
          </td>
          <td itemprop="title">Device for converting two-dimensional video into three-dimensional video 
     </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US6922234B2/en">
                <span itemprop="publicationNumber">US6922234B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2005-07-26">2005-07-26</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for generating structural data from laser reflectance images 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20060195858A1/en">
                <span itemprop="publicationNumber">US20060195858A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2006-08-31">2006-08-31</time>
            
            
          </td>
          <td itemprop="title">Video object recognition device and recognition method, video annotation giving device and giving method, and program 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="17716740132361069903">
              <a href="/scholar/17716740132361069903"><span itemprop="scholarAuthors">Zielke et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="1993">1993</time>
            
          </td>
          <td itemprop="title">Intensity and edge-based symmetry detection with an application to car-following</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20010048757A1/en">
                <span itemprop="publicationNumber">US20010048757A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2001-12-06">2001-12-06</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for matching positions of images 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP0634873A2/en">
                <span itemprop="publicationNumber">EP0634873A2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="1995-01-18">1995-01-18</time>
            
            
          </td>
          <td itemprop="title">Method to determine the motion vectors in small picture segments of a television picture 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20030152271A1/en">
                <span itemprop="publicationNumber">US20030152271A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2003-08-14">2003-08-14</time>
            
            
          </td>
          <td itemprop="title">Apparatus, program and method for detecting both stationary objects and moving objects in an image 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US7742634B2/en">
                <span itemprop="publicationNumber">US7742634B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2010-06-22">2010-06-22</time>
            
            
          </td>
          <td itemprop="title">Image processing method, three-dimensional position measuring method and image processing apparatus 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP1640912A2/en">
                <span itemprop="publicationNumber">EP1640912A2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2006-03-29">2006-03-29</time>
            
            
          </td>
          <td itemprop="title">Moving-object height determining apparatus 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/JP2006127241A/en">
                <span itemprop="publicationNumber">JP2006127241A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2006-05-18">2006-05-18</time>
            
            
          </td>
          <td itemprop="title">Method for accelerating super-resolution processing 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20150178900A1/en">
                <span itemprop="publicationNumber">US20150178900A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2015-06-25">2015-06-25</time>
            
            
          </td>
          <td itemprop="title">Depth image processing apparatus and method based on camera pose conversion 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/FR2752969A1/en">
                <span itemprop="publicationNumber">FR2752969A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="1998-03-06">1998-03-06</time>
            
            
          </td>
          <td itemprop="title">Method for detecting an object from stereoscopic images 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            
            <meta itemprop="isScholar" content="true">
              <meta itemprop="scholarID" content="13309699251574192912">
              <a href="/scholar/13309699251574192912"><span itemprop="scholarAuthors">Nieto et al.</span></a>
            
          </td>
          <td>
            
            <time itemprop="publicationDate" datetime="2007">2007</time>
            
          </td>
          <td itemprop="title">Stabilization of inverse perspective mapping images based on robust vanishing point estimation</td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20020051058A1/en">
                <span itemprop="publicationNumber">US20020051058A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2002-05-02">2002-05-02</time>
            
            
          </td>
          <td itemprop="title">Intruding object detecting method and intruding object monitoring apparatus employing the method 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20020012459A1/en">
                <span itemprop="publicationNumber">US20020012459A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2002-01-31">2002-01-31</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for detecting stereo disparity in sequential parallel processing mode 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US20080025403A1/en">
                <span itemprop="publicationNumber">US20080025403A1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2008-01-31">2008-01-31</time>
            
            
          </td>
          <td itemprop="title">Interpolation frame generating method and interpolation frame forming apparatus 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/JP2006053890A/en">
                <span itemprop="publicationNumber">JP2006053890A</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2006-02-23">2006-02-23</time>
            
            
          </td>
          <td itemprop="title">Obstacle detection apparatus and method therefor 
     </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP1993070B1/en">
                <span itemprop="publicationNumber">EP1993070B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2013-09-18">2013-09-18</time>
            
            
          </td>
          <td itemprop="title">Image processing device for image-analyzing magnification color aberration, image processing program, electronic camera, and image processing method for image analysis of chromatic aberration of magnification 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US8922623B2/en">
                <span itemprop="publicationNumber">US8922623B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2014-12-30">2014-12-30</time>
            
            
          </td>
          <td itemprop="title">Stereo image processor and stereo image processing method 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/CN104541302B/en">
                <span itemprop="publicationNumber">CN104541302B</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2017-11-24">2017-11-24</time>
            
            
          </td>
          <td itemprop="title">Distance prompt Object Segmentation System and method 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP1918877B1/en">
                <span itemprop="publicationNumber">EP1918877B1</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2011-10-05">2011-10-05</time>
            
            
          </td>
          <td itemprop="title">Correlation peak finding method for image correlation displacement sensing 
     </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/EP1072147A2/en">
                <span itemprop="publicationNumber">EP1072147A2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2001-01-31">2001-01-31</time>
            
            
          </td>
          <td itemprop="title">Method and apparatus for measuring similarity using matching pixel count 
       </td>
        </tr><tr itemprop="similarDocuments" itemscope repeat>
          <td>
            <meta itemprop="isPatent" content="true">
              
              
              <a href="/patent/US7742657B2/en">
                <span itemprop="publicationNumber">US7742657B2</span>
                (<span itemprop="primaryLanguage">en</span>)
              </a>
            
            
          </td>
          <td>
            <time itemprop="publicationDate" datetime="2010-06-22">2010-06-22</time>
            
            
          </td>
          <td itemprop="title">Method for synthesizing intermediate image using mesh based on multi-view square camera structure and device using the same and computer-readable medium having thereon program performing function embodying the same 
       </td>
        </tr>
      </tbody>
    </table>
  </section>

  <section>
    <h2>Legal Events</h2>
    <table>
      <thead>
        <tr>
          <th>Date</th>
          <th>Code</th>
          <th>Title</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
        
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2005-07-01">2005-07-01</time></td>
          <td itemprop="code">AS</td>
          <td itemprop="title">Assignment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Owner name</strong>:
              <span itemprop="value">UNITED STATES OF AMERICA AS REPRESENTED BY THE NAT</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">ASSIGNMENT OF ASSIGNORS INTEREST;ASSIGNOR:HATHAWAY, DAVID H.;REEL/FRAME:016760/0402</span>
            </p>
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Effective date</strong>:
              <span itemprop="value">20050701</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2009-09-09">2009-09-09</time></td>
          <td itemprop="code">STCF</td>
          <td itemprop="title">Information on status: patent grant</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Free format text</strong>:
              <span itemprop="value">PATENTED CASE</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2013-01-09">2013-01-09</time></td>
          <td itemprop="code">FPAY</td>
          <td itemprop="title">Fee payment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Year of fee payment</strong>:
              <span itemprop="value">4</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2017-04-11">2017-04-11</time></td>
          <td itemprop="code">FPAY</td>
          <td itemprop="title">Fee payment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Year of fee payment</strong>:
              <span itemprop="value">8</span>
            </p>
          </td>
        </tr>
        <tr itemprop="legalEvents" itemscope repeat>
          <td><time itemprop="date" datetime="2017-04-11">2017-04-11</time></td>
          <td itemprop="code">SULP</td>
          <td itemprop="title">Surcharge for late payment</td>
          <td>
            
            <p itemprop="attributes" itemscope repeat>
              <strong itemprop="label">Year of fee payment</strong>:
              <span itemprop="value">7</span>
            </p>
          </td>
        </tr>
      </tbody>
    </table>
  </section>
</article>

    </search-app>
    <script type="text/javascript" src="//www.gstatic.com/feedback/api.js"></script>
    <script async="" defer="" src="//www.google.com/insights/consumersurveys/async_survey?site=cxkjf7ipxgbnnjy6k35ezcvbbe"></script>
  </body>
</html>
